"""
EPR Legal Chatbot - Core Module
Vietnamese EPR (Extended Producer Responsibility) Legal Question-Answering System
"""

import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Set environment variables
os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2', 'true')
os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT', 'https://api.smith.langchain.com')
os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY', '')
os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY', '')
os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', '')


# Updated imports - ChromaTranslator is now in a different location
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# Storage and vectorstore
from langchain_core.stores import InMemoryByteStore
from langchain_chroma import Chroma

# Retrievers
from langchain.retrievers.multi_vector import MultiVectorRetriever

# Self-query imports
from langchain.chains.query_constructor.schema import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain.chains.query_constructor.base import (
    StructuredQueryOutputParser,
    get_query_constructor_prompt,
)

# FIXED: ChromaTranslator import
try:
    from langchain.retrievers.self_query.chroma import ChromaTranslator
except:
    from langchain_community.query_constructors.chroma import ChromaTranslator

import uuid
import tiktoken

print("âœ“ All imports successful!")

from langchain.schema import Document
from langchain_openai import OpenAIEmbeddings
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
import uuid

# ========== TOKEN COUNTING UTILITIES ==========

def count_tokens(text: str, model: str = "gpt-3.5-turbo") -> int:
    """Count the number of tokens in a text string"""
    try:
        encoding = tiktoken.encoding_for_model(model)
        return len(encoding.encode(text))
    except Exception as e:
        print(f"  âš ï¸ Error counting tokens: {e}")
        # Rough estimation: ~4 characters per token
        return len(text) // 4

def truncate_text(text: str, max_tokens: int = 1000, model: str = "gpt-3.5-turbo") -> str:
    """Truncate text to fit within max_tokens"""
    try:
        encoding = tiktoken.encoding_for_model(model)
        tokens = encoding.encode(text)

        if len(tokens) <= max_tokens:
            return text

        # Truncate and decode back to text
        truncated_tokens = tokens[:max_tokens]
        return encoding.decode(truncated_tokens) + "..."
    except Exception as e:
        print(f"  âš ï¸ Error truncating text: {e}")
        # Rough fallback: character-based truncation
        max_chars = max_tokens * 4
        if len(text) <= max_chars:
            return text
        return text[:max_chars] + "..."

print("âœ“ Token counting utilities loaded")

# ========== CONFIGURATION ==========

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# Initialize Qdrant client - Cloud or Local
USE_QDRANT_CLOUD = os.getenv('USE_QDRANT_CLOUD', 'false').lower() == 'true'
QDRANT_CLOUD_URL = os.getenv('QDRANT_CLOUD_URL')
QDRANT_API_KEY = os.getenv('QDRANT_API_KEY')

if USE_QDRANT_CLOUD and QDRANT_CLOUD_URL and QDRANT_API_KEY:
    # Use Qdrant Cloud
    try:
        client = QdrantClient(
            url=QDRANT_CLOUD_URL,
            api_key=QDRANT_API_KEY,
        )
        print("âœ… Connected to Qdrant Cloud")
        print(f"   URL: {QDRANT_CLOUD_URL}")
    except Exception as e:
        print(f"âŒ Failed to connect to Qdrant Cloud: {e}")
        print("âš ï¸  Falling back to local storage...")
        try:
            client = QdrantClient(path="./qdrant_faq_db")
            print("âœ… Using persistent Qdrant database at ./qdrant_faq_db")
        except Exception as e2:
            print(f"âš ï¸  Could not use file-based database: {e2}")
            print("ğŸ“ Using in-memory Qdrant database instead")
            client = QdrantClient(":memory:")
else:
    # Use local Qdrant
    print("ğŸ“ Using local Qdrant storage")
    try:
        client = QdrantClient(path="./qdrant_faq_db")
        print("âœ… Using persistent Qdrant database at ./qdrant_faq_db")
    except Exception as e:
        print(f"âš ï¸  Could not use file-based database: {e}")
        print("ğŸ“ Using in-memory Qdrant database instead")
        client = QdrantClient(":memory:")

collection_name = "faq_collection"

# ========== FAQ DATA ==========

faq = {
    "meta": [
        {
            "CÃ¢u há»i": "Kiáº¿n thá»©c cá»§a báº¡n bao gá»“m nhá»¯ng gÃ¬?",
            "Tráº£ lá»i": "Kiáº¿n thá»©c cá»§a tÃ´i bao gá»“m cÃ¡c Ä‘iá»u luáº­t cá»§a vÄƒn báº£n phÃ¡p luáº­t vá» EPR cá»§a Viá»‡t Nam"
        },
        {
            "CÃ¢u há»i": "CÃ¡c Ä‘á»‘i tÆ°á»£ng nÃ o pháº£i thá»±c hiá»‡n trÃ¡ch nhiá»‡m tÃ¡i cháº¿?",
            "Tráº£ lá»i": "Theo Äiá»u 77 vÃ  Phá»¥ lá»¥c XXII Nghá»‹ Ä‘á»‹nh sá»‘ 08/2022/NÄ-CP quy Ä‘á»‹nh chi tiáº¿t má»™t sá»‘ Ä‘iá»u cá»§a Luáº­t Báº£o vá»‡ mÃ´i trÆ°á»ng, cÃ¡c tá»• chá»©c sáº£n xuáº¥t, nháº­p kháº©u sáº£n pháº©m, bao bÃ¬ pháº£i thá»±c hiá»‡n trÃ¡ch nhiá»‡m tÃ¡i cháº¿."
        },
        {
            "CÃ¢u há»i": "Bao bÃ¬ thÆ°Æ¡ng pháº©m Ä‘Æ°á»£c hiá»ƒu nhÆ° tháº¿ nÃ o?",
            "Tráº£ lá»i": "Theo Äiá»u 3 Nghá»‹ Ä‘á»‹nh sá»‘ 43/2017/NÄ-CP cá»§a ChÃ­nh phá»§ vá» nhÃ£n hÃ ng hÃ³a, bao bÃ¬ thÆ°Æ¡ng pháº©m lÃ ..."
        },
        {
            "CÃ¢u há»i": "Khi nÃ o nhÃ  sáº£n xuáº¥t, nháº­p kháº©u sáº£n pháº©m, bao bÃ¬ pháº£i thá»±c hiá»‡n trÃ¡ch nhiá»‡m tÃ¡i cháº¿?",
            "Tráº£ lá»i": "Theo khoáº£n 4 Äiá»u 77 Nghá»‹ Ä‘á»‹nh sá»‘ 08/2022/NÄ-CP thÃ¬ nhÃ  sáº£n xuáº¥t, nháº­p kháº©u sáº£n pháº©m pháº£i thá»±c hiá»‡n..."
        }
    ]
}

# ========== RECREATE COLLECTION FUNCTION ==========

def recreate_faq_collection(force=False):
    """
    Recreate FAQ collection with fresh embeddings

    Args:
        force: If True, delete existing collection and recreate
    """
    print("="*80)
    print("ğŸ”„ FAQ COLLECTION SETUP")
    print("="*80)

    try:
        # Check if collection exists
        existing_collections = client.get_collections().collections
        collection_exists = any(col.name == collection_name for col in existing_collections)

        if collection_exists:
            if force:
                print(f"ğŸ—‘ï¸  Deleting existing collection '{collection_name}'...")
                client.delete_collection(collection_name)
                print(f"âœ… Deleted old collection")
            else:
                print(f"âœ… Collection '{collection_name}' already exists")
                count = client.get_collection(collection_name).points_count
                print(f"   Points in collection: {count}")
                print("ğŸ’¡ Set force=True to recreate with fresh embeddings")
                return True

        # Create collection
        print(f"ğŸ“ Creating collection '{collection_name}'...")
        sample_emb = embeddings.embed_query("test")
        dim = len(sample_emb)

        client.create_collection(
            collection_name=collection_name,
            vectors_config=VectorParams(size=dim, distance=Distance.COSINE)
        )
        print(f"âœ… Created collection (dimension: {dim})")

        # Add FAQ documents with fresh embeddings
        print(f"ğŸ“„ Adding {len(faq['meta'])} FAQ documents...")
        points = []

        for idx, item in enumerate(faq["meta"], 1):
            question = item["CÃ¢u há»i"]
            answer = item["Tráº£ lá»i"]

            print(f"   {idx}. Embedding: {question[:50]}...")
            vector = embeddings.embed_query(question)

            point = PointStruct(
                id=str(uuid.uuid4()),
                vector=vector,
                payload={
                    "CÃ¢u_há»i": question,
                    "Tráº£_lá»i": answer
                }
            )
            points.append(point)

        # Upload all at once
        client.upsert(collection_name=collection_name, points=points)
        print(f"âœ… Added {len(points)} documents to collection")

        # Verify
        count = client.get_collection(collection_name).points_count
        print(f"âœ… Verified: Collection has {count} points")
        print("="*80)

        return True

    except Exception as e:
        print(f"âŒ Error: {e}")
        print("="*80)
        return False

# ========== RETRIEVAL FUNCTION ==========

# def retrieve_faq_top1(query: str, score_threshold: float = 0.6):
#     """Retrieve top 1 FAQ with detailed scoring info"""
#     print(f"\n{'='*80}")
#     print(f"ğŸ” FAQ RETRIEVAL")
#     print(f"{'='*80}")
#     print(f"Query: {query}")
#     print(f"Threshold: {score_threshold}")
#     print(f"{'-'*80}")

#     # Get query embedding
#     query_vector = embeddings.embed_query(query)

#     # Search
#     results = client.query_points(
#         collection_name=collection_name,
#         query=query_vector,
#         limit=3  # Get top 3 to see scores
#     )

#     if not results or not results.points:
#         print("  âŒ No results found")
#         print(f"{'='*80}\n")
#         return []

#     # Show all top matches
#     print(f"  ğŸ“Š Top matches:")
#     for i, point in enumerate(results.points, 1):
#         score = point.score
#         question = point.payload['CÃ¢u_há»i']
#         status = "âœ… PASS" if score >= score_threshold else "âŒ FAIL"
#         print(f"     {i}. {status} Score: {score:.4f} - {question[:50]}...")

#     # Get best match
#     best_point = results.points[0]
#     best_score = best_point.score

#     print(f"{'-'*80}")

#     if best_score >= score_threshold:
#         doc = Document(
#             page_content=best_point.payload["Tráº£_lá»i"],
#             metadata={
#                 "CÃ¢u_há»i": best_point.payload["CÃ¢u_há»i"],
#                 "score": best_score
#             }
#         )
#         print(f"  âœ… Returning match (score: {best_score:.4f} >= {score_threshold})")
#         print(f"{'='*80}\n")
#         return [doc]
#     else:
#         print(f"  âš ï¸  Best score {best_score:.4f} < threshold {score_threshold}")
#         print(f"  ğŸ’¡ Try threshold={best_score:.2f} or lower")
#         print(f"{'='*80}\n")
#         return []
def retrieve_faq_top1(query: str, score_threshold: float = 0.6, keyword_boost: float = 0.3):
    """
    Retrieve top 1 FAQ using hybrid approach: semantic + keyword matching
    
    Args:
        query: User's question
        score_threshold: Minimum combined score to accept a match
        keyword_boost: Weight for keyword matching (0.0 - 1.0)
        
    Returns:
        List containing the best matching Document, or empty list if no match
    """
    print(f"\n{'='*80}")
    print(f"ğŸ” FAQ RETRIEVAL (HYBRID: Semantic + Keyword)")
    print(f"{'='*80}")
    print(f"Query: {query}")
    print(f"Threshold: {score_threshold} | Keyword Boost: {keyword_boost}")
    print(f"{'-'*80}")

    # Get query embedding for semantic search
    query_vector = embeddings.embed_query(query)

    # Search with more candidates for re-ranking
    results = client.query_points(
        collection_name=collection_name,
        query=query_vector,
        limit=5  # Get more candidates to re-rank
    )

    if not results or not results.points:
        print("  âŒ No results found")
        print(f"{'='*80}\n")
        return []

    # Tokenize query for keyword matching
    query_tokens = _tokenize_vietnamese(query)
    print(f"  ğŸ”¤ Query tokens: {query_tokens}")
    print(f"{'-'*80}")

    # Calculate hybrid scores for all candidates
    scored_results = []
    for point in results.points:
        semantic_score = point.score
        question = point.payload['CÃ¢u_há»i']
        question_tokens = _tokenize_vietnamese(question)
        
        # Calculate keyword overlap (Jaccard-like similarity)
        if query_tokens:
            overlap_count = len(query_tokens & question_tokens)
            keyword_score = overlap_count / len(query_tokens)
        else:
            keyword_score = 0.0
        
        # Combined score: semantic + keyword boost
        final_score = semantic_score + (keyword_boost * keyword_score)
        
        scored_results.append({
            'point': point,
            'semantic_score': semantic_score,
            'keyword_score': keyword_score,
            'keyword_matches': query_tokens & question_tokens,
            'final_score': final_score
        })

    # Re-rank by final combined score
    scored_results.sort(key=lambda x: x['final_score'], reverse=True)

    # Display top matches with detailed scoring
    print(f"  ğŸ“Š Top matches (re-ranked by hybrid score):")
    for i, r in enumerate(scored_results[:5], 1):
        status = "âœ… PASS" if r['final_score'] >= score_threshold else "âŒ FAIL"
        print(f"     {i}. {status}")
        print(f"        Semantic: {r['semantic_score']:.4f} | Keyword: {r['keyword_score']:.4f} | Final: {r['final_score']:.4f}")
        print(f"        Matched words: {r['keyword_matches'] if r['keyword_matches'] else 'None'}")
        print(f"        Q: {r['point'].payload['CÃ¢u_há»i'][:70]}...")
        print()

    print(f"{'-'*80}")

    # Get best match after re-ranking
    best = scored_results[0]
    best_point = best['point']
    best_score = best['final_score']

    if best_score >= score_threshold:
        doc = Document(
            page_content=best_point.payload["Tráº£_lá»i"],
            metadata={
                "CÃ¢u_há»i": best_point.payload["CÃ¢u_há»i"],
                "score": best_score,
                "semantic_score": best['semantic_score'],
                "keyword_score": best['keyword_score']
            }
        )
        print(f"  âœ… Returning match (final_score: {best_score:.4f} >= {score_threshold})")
        print(f"     Semantic: {best['semantic_score']:.4f} + Keyword boost: {keyword_boost * best['keyword_score']:.4f}")
        print(f"{'='*80}\n")
        return [doc]
    else:
        print(f"  âš ï¸  Best score {best_score:.4f} < threshold {score_threshold}")
        print(f"  ğŸ’¡ Suggestions:")
        print(f"     - Try threshold={best_score:.2f} or lower")
        print(f"     - Increase keyword_boost if query has specific terms")
        print(f"{'='*80}\n")
        return []


def _tokenize_vietnamese(text: str) -> set:
    """
    Tokenize Vietnamese text for keyword matching
    
    Args:
        text: Input text
        
    Returns:
        Set of lowercase tokens (words)
    """
    # Convert to lowercase
    text = text.lower()
    
    # Remove punctuation but keep Vietnamese characters
    text = re.sub(r'[^\w\s]', ' ', text)
    
    # Split into words
    words = text.split()
    
    # Remove common stopwords (expand this list as needed)
    stopwords = {
        'lÃ ', 'vÃ ', 'cá»§a', 'cÃ³', 'Ä‘Æ°á»£c', 'trong', 'cho', 'vá»›i', 'cÃ¡c',
        'nÃ y', 'Ä‘Ã³', 'nhá»¯ng', 'Ä‘á»ƒ', 'khi', 'tá»«', 'theo', 'vá»', 'nhÆ°',
        'thÃ¬', 'mÃ ', 'nhÆ°ng', 'hoáº·c', 'náº¿u', 'vÃ¬', 'do', 'bá»Ÿi', 'táº¡i',
        'Ä‘Ã£', 'Ä‘ang', 'sáº½', 'cÃ²n', 'cÅ©ng', 'ráº¥t', 'láº¡i', 'nÃªn', 'pháº£i',
        'báº¡n', 'tÃ´i', 'chÃºng', 'há»', 'nÃ³', 'gÃ¬', 'nÃ o', 'sao', 'bao'}
    
    # Filter out stopwords and very short words
    tokens = {w for w in words if w not in stopwords and len(w) > 1}
    
    return tokens
# ========== RUN SETUP ==========

print("ğŸš€ Initializing FAQ system...")
print()

# Only recreate if doesn't exist (force=False for faster loading)
recreate_faq_collection(force=False)  # Set to False to skip if already exists

print("âœ… FAQ system ready!")

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# ========== INITIALIZE LLM FOR ANSWER GENERATION ==========

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

print("âœ… LLM initialized for answer generation")

# ========== ANSWER GENERATION FUNCTION ==========

def generate_answer_from_faq(query: str, documents: list):
    """
    Generate answer based on retrieved FAQ documents

    Args:
        query: User's original question
        documents: List of Document objects from retrieve_faq_top1

    Returns:
        str: Generated answer
    """
    print(f"\n{'='*80}")
    print(f"ğŸ’¬ GENERATING ANSWER FROM FAQ")
    print(f"{'='*80}")
    print(f"Query: {query}")
    print(f"Documents: {len(documents)}")
    print(f"{'-'*80}")

    # If no documents, return default message
    if not documents:
        print("  âš ï¸  No FAQ documents found, returning default message")
        print(f"{'='*80}\n")
        return "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p trong FAQ. Báº¡n cÃ³ thá»ƒ há»i cÃ¢u há»i khÃ¡c hoáº·c cung cáº¥p thÃªm chi tiáº¿t khÃ´ng?"

    # Get the FAQ document
    doc = documents[0]
    faq_question = doc.metadata.get("CÃ¢u_há»i", "")
    faq_answer = doc.page_content

    print(f"  ğŸ“‹ FAQ matched: {faq_question[:60]}...")
    print(f"{'-'*80}")

    # Create prompt for answer generation
    prompt = ChatPromptTemplate.from_messages([
        ("system", """Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» luáº­t EPR Viá»‡t Nam.

Nhiá»‡m vá»¥ cá»§a báº¡n:
1. Dá»±a vÃ o cÃ¢u há»i FAQ vÃ  cÃ¢u tráº£ lá»i cÃ³ sáºµn
2. Tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch tá»± nhiÃªn, thÃ¢n thiá»‡n
3. Giá»¯ nguyÃªn thÃ´ng tin chÃ­nh xÃ¡c tá»« FAQ
4. CÃ³ thá»ƒ Ä‘iá»u chá»‰nh cÃ¡ch diá»…n Ä‘áº¡t cho phÃ¹ há»£p vá»›i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng

Quy táº¯c:
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
- Giá»¯ thÃ´ng tin chÃ­nh xÃ¡c tá»« FAQ
- Náº¿u cÃ¢u há»i ngÆ°á»i dÃ¹ng khÃ¡c má»™t chÃºt so vá»›i FAQ, hÃ£y Ä‘iá»u chá»‰nh cÃ¢u tráº£ lá»i cho phÃ¹ há»£p
Náº¿u cÃ¢u há»i KHÃ”NG liÃªn quan (vÃ­ dá»¥: náº¥u Äƒn, du lá»‹ch, thá»ƒ thao, etc):"TÃ´i chá»‰ há»— trá»£ cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n luáº­t EPR cá»§a Viá»‡t Nam"
- Tráº£ lá»i ngáº¯n gá»n, rÃµ rÃ ng"""),

        ("""

CÃ¢u há»i FAQ tÆ°Æ¡ng tá»±: {faq_question}
CÃ¢u tráº£ lá»i FAQ: {faq_answer}

CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {user_question}

HÃ£y tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng dá»±a trÃªn thÃ´ng tin FAQ trÃªn:""")
    ])

    # Generate answer
    chain = prompt | llm

    result = chain.invoke({
        "faq_question": faq_question,
        "faq_answer": faq_answer,
        "user_question": query
    })

    answer = result.content

    print(f"  âœ… Answer generated")
    print(f"{'='*80}\n")

    return answer


# ========== COMPLETE FAQ RAG PIPELINE ==========

def faq_rag_pipeline(query: str, score_threshold: float = 0.6):
    """
    Complete FAQ RAG pipeline: Retrieve + Generate

    Args:
        query: User question
        score_threshold: Minimum similarity score for retrieval
        chat_history: Optional chat history

    Returns:
        dict: {
            "answer": str,
            "documents": list[Document],
            "source": str ("faq" or "not_found")
        }
    """
    print(f"\n{'#'*80}")
    print(f"ğŸ¤– FAQ RAG PIPELINE")
    print(f"{'#'*80}")
    print(f"Query: {query}")
    print(f"{'#'*80}\n")

    # Step 1: Retrieve FAQ documents
    documents = retrieve_faq_top1(query, score_threshold=score_threshold)

    # Step 2: Generate answer
    answer = generate_answer_from_faq(query, documents)

    # Step 3: Return result
    result = {
        "answer": answer,
        "documents": documents,
    }

    print(f"{'#'*80}")
    print(f"âœ… PIPELINE COMPLETE")
    print(f"{'#'*80}\n")

    return result



llm_rewrite_legal = ChatOpenAI(model="gpt-4o-mini", temperature=0)

rewrite_prompt_legal_improved = ChatPromptTemplate.from_messages([
    ("system", """Báº¡n lÃ  chuyÃªn gia viáº¿t láº¡i cÃ¢u há»i phÃ¡p luáº­t.

**NHIá»†M Vá»¤:**
1. Náº¿u cÃ¢u há»i cÃ³ Äáº I Tá»ª tham chiáº¿u (Ä‘Ã³, nÃ y, nÃ³) â†’ Thay tháº¿ báº±ng thÃ´ng tin cá»¥ thá»ƒ tá»« lá»‹ch sá»­
2. Náº¿u cÃ¢u há»i ÄÃƒ RÃ• RÃ€NG (khÃ´ng cÃ³ Ä‘áº¡i tá»« mÆ¡ há»“) â†’ GIá»® NGUYÃŠN
3. Náº¿u cÃ¢u há»i KHÃ”NG liÃªn quan Ä‘áº¿n phÃ¡p luáº­t â†’ GIá»® NGUYÃŠN

**CÃC Dáº NG THAM CHIáº¾U Cáº¦N Xá»¬ LÃ:**
- "nÃ³", "Ä‘Ã³", "nÃ y", "Ä‘iá»u Ä‘Ã³", "luáº­t Ä‘Ã³", "á»Ÿ trÃªn", "vá»«a rá»“i", "Ä‘iá»u vá»«a Ä‘á» cáº­p" â†’ Thay báº±ng Äiá»u/Luáº­t/ChÆ°Æ¡ng cá»¥ thá»ƒ
- "cÃ¡c Ä‘iá»u á»Ÿ trÃªn", "nhá»¯ng Ä‘iá»u Ä‘Ã£ nÃ³i", "cÃ¡c luáº­t á»Ÿ trÃªn" â†’ Liá»‡t kÃª cÃ¡c Äiá»u cá»¥ thá»ƒ tá»« lá»‹ch sá»­
- "tá»« cÃ¡c Ä‘iá»u trÃªn", "dá»±a vÃ o cÃ¡c Ä‘iá»u Ä‘Ã£ nÃ³i" â†’ XÃ¡c Ä‘á»‹nh cÃ¡c Äiá»u tá»« lá»‹ch sá»­

**âš ï¸ Cá»°C Ká»² QUAN TRá»ŒNG:**
- CHá»ˆ thay tháº¿ Ä‘áº¡i tá»«, KHÃ”NG thay Ä‘á»•i sá»‘ Ä‘iá»u cá»¥ thá»ƒ
- Náº¿u cÃ¢u há»i Ä‘Ã£ cÃ³ Sá» ÄIá»€U Cá»¤ THá»‚ (vÃ­ dá»¥: "Ä‘iá»u 2", "Äiá»u 77") â†’ GIá»® NGUYÃŠN HOÃ€N TOÃ€N
- TUYá»†T Äá»I KHÃ”NG thay Ä‘á»•i sá»‘ Ä‘iá»u trong cÃ¢u há»i gá»‘c
- KHÃ”NG thÃªm tá»« khÃ³a tá»« lá»‹ch sá»­ vÃ o cÃ¢u há»i Ä‘Ã£ rÃµ rÃ ng

**QUY Táº®C QUAN TRá»ŒNG:**
âœ… CHá»ˆ thay tháº¿ khi cÃ³ Ä‘áº¡i tá»« mÆ¡ há»“
âœ… KHÃ”NG thÃªm ngá»¯ cáº£nh vÃ o cÃ¢u há»i Ä‘Ã£ rÃµ rÃ ng
âœ… KHÃ”NG thÃªm "theo Äiá»u X" vÃ o cÃ¢u há»i má»›i vá» chá»§ Ä‘á» khÃ¡c
âœ… Äá»ŒC Ká»¸ lá»‹ch sá»­ Ä‘á»ƒ tÃ¬m Äiá»u/ChÆ°Æ¡ng/Luáº­t Ä‘Æ°á»£c nháº¯c Ä‘áº¿n
âœ… CHá»ˆ tráº£ vá» cÃ¢u há»i ngáº¯n gá»n (10-20 tá»«)
âœ… LUÃ”N giá»¯ dáº¡ng cÃ¢u há»i vá»›i dáº¥u "?"

âŒ TUYá»†T Äá»I KHÃ”NG tráº£ lá»i cÃ¢u há»i
âŒ TUYá»†T Äá»I KHÃ”NG giáº£i thÃ­ch ná»™i dung luáº­t
âŒ TUYá»†T Äá»I KHÃ”NG thÃªm ngá»¯ cáº£nh khi cÃ¢u há»i Ä‘Ã£ rÃµ rÃ ng

**PHÃ‚N BIá»†T CÃ‚U Há»I Má»šI vs CÃ‚U Há»I TIáº¾P THEO:**

CÃ¢u há»i Má»šI (chá»§ Ä‘á» khÃ¡c) â†’ GIá»® NGUYÃŠN:
- "Ai chá»‹u trÃ¡ch nhiá»‡m tÃ¡i cháº¿?" (Ä‘Ã£ rÃµ rÃ ng, khÃ´ng cáº§n thÃªm "theo Äiá»u 7")
- "EPR lÃ  gÃ¬?" (cÃ¢u há»i má»›i, Ä‘áº§y Ä‘á»§)
- "Quy Ä‘á»‹nh vá» bao bÃ¬?" (cÃ¢u há»i má»›i)

CÃ¢u há»i TIáº¾P THEO (cÃ³ Ä‘áº¡i tá»«) â†’ THAY THáº¾:
- "Äiá»u Ä‘Ã³ cÃ³ nÃ³i vá» X khÃ´ng?" â†’ "Äiá»u 7 cÃ³ nÃ³i vá» X khÃ´ng?"
- "NÃ³ quy Ä‘á»‹nh gÃ¬?" â†’ "Äiá»u 7 quy Ä‘á»‹nh gÃ¬?"
- "CÃ¡i nÃ y liÃªn quan gÃ¬?" â†’ "Äiá»u 7 liÃªn quan gÃ¬?"
"""),

    # Few-shot examples - Legal questions with pronouns (NEED TRANSFORMATION)
    ("human", """Lá»‹ch sá»­: User: Cho tÃ´i biáº¿t vá» Ä‘iá»u 1? Assistant: Theo Äiá»u 1...
User: Cho tÃ´i biáº¿t vá» Ä‘iá»u 3? Assistant: Theo Äiá»u 3...

CÃ¢u há»i: Tá»« cÃ¡c Ä‘iá»u á»Ÿ trÃªn hÃ£y cho tÃ´i biáº¿t Ã¡p dá»¥ng Ä‘Æ°á»£c gÃ¬ khÃ´ng?"""),
    ("assistant", "Äiá»u 1 vÃ  Äiá»u 3 cÃ³ thá»ƒ Ã¡p dá»¥ng Ä‘Æ°á»£c gÃ¬"),

    ("human", """Lá»‹ch sá»­: User: Cho tÃ´i há»i vá» Ä‘iá»u luáº­t sá»‘ 7? Assistant: Theo Äiá»u 7...

CÃ¢u há»i: Äiá»u luáº­t Ä‘Ã³ cÃ³ nÃ³i vá» khÃ´ng khÃ­ hay khÃ´ng?"""),
    ("assistant", "Äiá»u 7 cÃ³ nÃ³i vá» khÃ´ng khÃ­ khÃ´ng"),

    # Few-shot examples - Clear legal questions (KEEP ORIGINAL)
    ("human", """Lá»‹ch sá»­: User: Cho tÃ´i há»i vá» Äiá»u 7? Assistant: Theo Äiá»u 7... nÃ³i vá» quáº£n lÃ½ khÃ´ng khÃ­

CÃ¢u há»i: Ai chá»‹u trÃ¡ch nhiá»‡m tÃ¡i cháº¿?"""),
    ("assistant", "Ai chá»‹u trÃ¡ch nhiá»‡m tÃ¡i cháº¿?"),

    ("human", """Lá»‹ch sá»­: User: Äiá»u 77 lÃ  gÃ¬? Assistant: Äiá»u 77 vá» tÃ¡i cháº¿...

CÃ¢u há»i: Quy Ä‘á»‹nh vá» bao bÃ¬ lÃ  gÃ¬?"""),
    ("assistant", "Quy Ä‘á»‹nh vá» bao bÃ¬ lÃ  gÃ¬?"),

    # IMPORTANT: Questions with specific article numbers - NEVER CHANGE THEM
    ("human", """Lá»‹ch sá»­: User: Cho tÃ´i há»i vá» Äiá»u 5? Assistant: Theo Äiá»u 5...
User: Äiá»u 6 quy Ä‘á»‹nh gÃ¬? Assistant: Theo Äiá»u 6...

CÃ¢u há»i: Cho tÃ´i há»i chi tiáº¿t vá» Ä‘iá»u 2 vÃ  Ä‘iá»u 3?"""),
    ("assistant", "Cho tÃ´i há»i chi tiáº¿t vá» Ä‘iá»u 2 vÃ  Ä‘iá»u 3?"),

    ("human", """Lá»‹ch sá»­: User: Äiá»u 10 lÃ  gÃ¬? Assistant: Äiá»u 10 vá»...

CÃ¢u há»i: Äiá»u 1 quy Ä‘á»‹nh gÃ¬?"""),
    ("assistant", "Äiá»u 1 quy Ä‘á»‹nh gÃ¬?"),

    ("human", """Lá»‹ch sá»­: (trá»‘ng)

CÃ¢u há»i: Cho tÃ´i há»i vá» Ä‘iá»u luáº­t sá»‘ 1?"""),
    ("assistant", "Äiá»u 1 quy Ä‘á»‹nh gÃ¬"),

    # Few-shot examples - Non-legal questions (KEEP ORIGINAL)
    ("human", """Lá»‹ch sá»­: (trá»‘ng)

CÃ¢u há»i: Xin chÃ o!"""),
    ("assistant", "Xin chÃ o!"),

    ("human", """Lá»‹ch sá»­: (trá»‘ng)

CÃ¢u há»i: Cáº£m Æ¡n báº¡n"""),
    ("assistant", "Cáº£m Æ¡n báº¡n"),

    ("human", """Lá»‹ch sá»­: (trá»‘ng)

CÃ¢u há»i: LÃ m tháº¿ nÃ o Ä‘á»ƒ náº¥u phá»Ÿ?"""),
    ("assistant", "LÃ m tháº¿ nÃ o Ä‘á»ƒ náº¥u phá»Ÿ?"),

    # Actual query
    ("human", """Lá»‹ch sá»­: {chat_history}

CÃ¢u há»i: {question}

**HÆ¯á»šNG DáºªN PHÃ‚N TÃCH:**
1. CÃ¢u há»i cÃ³ Sá» ÄIá»€U Cá»¤ THá»‚ khÃ´ng? (Ä‘iá»u 1, Äiá»u 77, Ä‘iá»u 2 vÃ  Ä‘iá»u 3)
   - CÃ“ Sá» Cá»¤ THá»‚ â†’ GIá»® NGUYÃŠN HOÃ€N TOÃ€N (Ä‘á»«ng thay Ä‘á»•i sá»‘ Ä‘iá»u!)
   - KHÃ”NG CÃ“ Sá» â†’ Chuyá»ƒn sang bÆ°á»›c 2

2. CÃ¢u há»i cÃ³ chá»©a Ä‘áº¡i tá»« mÆ¡ há»“ khÃ´ng? (Ä‘Ã³, nÃ y, nÃ³, á»Ÿ trÃªn, vá»«a rá»“i)
   - CÃ“ â†’ Thay tháº¿ báº±ng thÃ´ng tin tá»« lá»‹ch sá»­
   - KHÃ”NG â†’ Chuyá»ƒn sang bÆ°á»›c 3

3. CÃ¢u há»i Ä‘Ã£ Ä‘áº§y Ä‘á»§ vÃ  rÃµ rÃ ng chÆ°a?
   - ÄÃƒ RÃ• RÃ€NG â†’ GIá»® NGUYÃŠN (khÃ´ng thÃªm gÃ¬)
   - CHÆ¯A RÃ• â†’ LÃ m rÃµ tá»« lá»‹ch sá»­

**LÆ¯U Ã:**
- âš ï¸ TUYá»†T Äá»I GIá»® NGUYÃŠN sá»‘ Ä‘iá»u trong cÃ¢u há»i gá»‘c (Ä‘iá»u 2 pháº£i váº«n lÃ  Ä‘iá»u 2, KHÃ”NG thay thÃ nh sá»‘ khÃ¡c!)
- Náº¿u cÃ³ "cÃ¡c Ä‘iá»u á»Ÿ trÃªn", "nhá»¯ng Ä‘iá»u Ä‘Ã£ nÃ³i" â†’ TÃŒM Táº¤T Cáº¢ Äiá»u trong lá»‹ch sá»­ vÃ  liá»‡t kÃª
- Náº¿u cÃ³ "Ä‘iá»u Ä‘Ã³", "nÃ³" â†’ TÃŒM Äiá»u Gáº¦N NHáº¤T trong lá»‹ch sá»­
- LUÃ”N LUÃ”N giá»¯ dáº¡ng cÃ¢u há»i vá»›i dáº¥u "?"
- TUYá»†T Äá»I KHÃ”NG thÃªm "theo Äiá»u X" vÃ o cÃ¢u há»i Ä‘Ã£ rÃµ rÃ ng
- Náº¿u cÃ¢u há»i KHÃ”NG liÃªn quan phÃ¡p luáº­t â†’ GIá»® NGUYÃŠN

**VÃ Dá»¤ QUAN TRá»ŒNG:**

âŒ SAI:
Lá»‹ch sá»­: "User: cÃ³ Ä‘iá»u nÃ o vá» tÃ¡i cháº¿?\nAssistant: Äiá»u 3 vá» tÃ¡i cháº¿..."
CÃ¢u gá»‘c: "nÃ³i rÃµ cÃ¡c Ä‘iá»u Ä‘Ã³ ra"
Chuyá»ƒn thÃ nh: "NÃ³i rÃµ Äiá»u 3 vá» tÃ¡i cháº¿ ra?"  âŒ THÃŠM "vá» tÃ¡i cháº¿" khÃ´ng cáº§n thiáº¿t!

âœ… ÄÃšNG:
Lá»‹ch sá»­: "User: cÃ³ Ä‘iá»u nÃ o vá» tÃ¡i cháº¿?\nAssistant: Äiá»u 3 vá» tÃ¡i cháº¿..."
CÃ¢u gá»‘c: "nÃ³i rÃµ cÃ¡c Ä‘iá»u Ä‘Ã³ ra"
Chuyá»ƒn thÃ nh: "NÃ³i rÃµ Äiá»u 3 ra?"  âœ… CHá»ˆ thay "Ä‘iá»u Ä‘Ã³" â†’ "Äiá»u 3"

âŒ SAI:
Lá»‹ch sá»­: "User: Äiá»u 77 lÃ  gÃ¬?\nAssistant: Äiá»u 77 vá» trÃ¡ch nhiá»‡m..."
CÃ¢u gá»‘c: "Äiá»u Ä‘Ã³ cÃ³ nÃ³i vá» bao bÃ¬ khÃ´ng?"
Chuyá»ƒn thÃ nh: "Äiá»u 77 cÃ³ nÃ³i vá» bao bÃ¬ vÃ  trÃ¡ch nhiá»‡m khÃ´ng?"  âŒ THÃŠM "trÃ¡ch nhiá»‡m"!

âœ… ÄÃšNG:
Lá»‹ch sá»­: "User: Äiá»u 77 lÃ  gÃ¬?\nAssistant: Äiá»u 77 vá» trÃ¡ch nhiá»‡m..."
CÃ¢u gá»‘c: "Äiá»u Ä‘Ã³ cÃ³ nÃ³i vá» bao bÃ¬ khÃ´ng?"
Chuyá»ƒn thÃ nh: "Äiá»u 77 cÃ³ nÃ³i vá» bao bÃ¬ khÃ´ng?"  âœ… CHá»ˆ thay "Ä‘Ã³" â†’ "77"

âŒ SAI - THAY Äá»”I Sá» ÄIá»€U:
Lá»‹ch sá»­: "User: Äiá»u 5 lÃ  gÃ¬?\nAssistant: Äiá»u 5...\nUser: Äiá»u 6?\nAssistant: Äiá»u 6..."
CÃ¢u gá»‘c: "Cho tÃ´i há»i chi tiáº¿t vá» Ä‘iá»u 2 vÃ  Ä‘iá»u 3?"
Chuyá»ƒn thÃ nh: "Cho tÃ´i há»i chi tiáº¿t vá» Äiá»u 6 vÃ  Äiá»u 7?"  âŒ SAI! ÄÃ£ thay Ä‘á»•i sá»‘ Ä‘iá»u!

âœ… ÄÃšNG - GIá»® NGUYÃŠN Sá» ÄIá»€U:
Lá»‹ch sá»­: "User: Äiá»u 5 lÃ  gÃ¬?\nAssistant: Äiá»u 5...\nUser: Äiá»u 6?\nAssistant: Äiá»u 6..."
CÃ¢u gá»‘c: "Cho tÃ´i há»i chi tiáº¿t vá» Ä‘iá»u 2 vÃ  Ä‘iá»u 3?"
Chuyá»ƒn thÃ nh: "Cho tÃ´i há»i chi tiáº¿t vá» Ä‘iá»u 2 vÃ  Ä‘iá»u 3?"  âœ… ÄÃšNG! Giá»¯ nguyÃªn sá»‘ Ä‘iá»u gá»‘c!

CÃ¢u há»i viáº¿t láº¡i (CHá»ˆ cÃ¢u há»i ngáº¯n, hoáº·c giá»¯ nguyÃªn náº¿u Ä‘Ã£ rÃµ):"""),
])

question_rewriter_legal = rewrite_prompt_legal_improved | llm_rewrite_legal | StrOutputParser()

print("âœ… Question rewriter vá»›i xá»­ lÃ½ reference context vÃ  ngÄƒn over-adding")


def transform_query(state):
    print("---CHUYá»‚N HÃ“A CÃ‚U Há»I---")

    question = state.get("question", "")
    documents = state.get("documents", [])
    chat_history = state.get("chat_history", "")

    # âœ… LÆ°u cÃ¢u há»i gá»‘c náº¿u chÆ°a cÃ³
    original_question = state.get("original_question", question)

    print(f"  CÃ¢u há»i gá»‘c: {question}")

    better_question = question_rewriter_legal.invoke({
        "question": question,
        "chat_history": chat_history
    })

    print(f"  CÃ¢u há»i Ä‘Ã£ chuyá»ƒn hÃ³a: {better_question}")

    retries = state.get("retries", 0) + 1
    return {
        "question": better_question,
        "original_question": original_question,  # âœ… LÆ°u cÃ¢u há»i gá»‘c
        "documents": documents,
        "chat_history": chat_history,
        "generation": state.get("generation", ""),
        "retries": retries,
    }

print("âœ“ HÃ m transform_query sáºµn sÃ ng")


from langchain.memory import ConversationBufferMemory

# Create conversation memory
conversation_memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    input_key="input",
    output_key="generation"
)

def chitchat(state):
    """TrÃ² chuyá»‡n thÃ¢n thiá»‡n vá»›i trá»£ lÃ½ phÃ¡p luáº­t, cÃ³ truy cáº­p Ä‘áº§y Ä‘á»§ lá»‹ch sá»­"""
    print("---TRÃ’ CHUYá»†N PHÃP LUáº¬T THÃ‚N THIá»†N---")

    question = state["question"]
    chat_history = state.get("chat_history", "")

    # Náº¿u chat_history quÃ¡ ngáº¯n, load tá»« memory
    if not chat_history or len(chat_history) < 200:
        try:
            memory_vars = conversation_memory.load_memory_variables({})
            if "chat_history" in memory_vars:
                messages = memory_vars["chat_history"]
                if messages:
                    formatted = []
                    for msg in messages:
                        if hasattr(msg, 'type'):
                            role = "NgÆ°á»i dÃ¹ng" if msg.type == "human" else "Trá»£ lÃ½ phÃ¡p luáº­t EPR"
                            content = msg.content
                        else:
                            role = "NgÆ°á»i dÃ¹ng"
                            content = str(msg)
                        formatted.append(f"{role}: {content}")
                    chat_history = "\n".join(formatted)
        except Exception as e:
            print(f"  âš ï¸ KhÃ´ng thá»ƒ load full history: {e}")

    print(f"  Äá»™ dÃ i lá»‹ch sá»­: {len(chat_history)} kÃ½ tá»±")

    llm_chat = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

    chitchat_prompt = ChatPromptTemplate.from_messages([
        ("system", """Báº¡n lÃ  **trá»£ lÃ½ phÃ¡p lÃ½ thÃ´ng minh** há»— trá»£ ngÆ°á»i dÃ¹ng tra cá»©u vÃ  giáº£i thÃ­ch vÄƒn báº£n phÃ¡p luáº­t Viá»‡t Nam.

**QUY Táº®C QUAN TRá»ŒNG Vá»€ Bá»˜ NHá»š:**
1. **LUÃ”N Äá»ŒC Ká»¸ lá»‹ch sá»­ há»™i thoáº¡i** trÆ°á»›c khi tráº£ lá»i
2. **Sá»¬ Dá»¤NG thÃ´ng tin** mÃ  ngÆ°á»i dÃ¹ng Ä‘Ã£ cung cáº¥p trong lá»‹ch sá»­ (tÃªn, cÃ´ng ty, hoÃ n cáº£nh, etc.)
3. **GHI NHá»š context** tá»« cÃ¡c cÃ¢u há»i vÃ  tráº£ lá»i trÆ°á»›c Ä‘Ã³
4. Náº¿u ngÆ°á»i dÃ¹ng há»i vá» thÃ´ng tin há» Ä‘Ã£ cung cáº¥p â†’ **TRáº¢ Lá»œI dá»±a trÃªn lá»‹ch sá»­**, KHÃ”NG nÃ³i "khÃ´ng biáº¿t"

**VÃ Dá»¤:**
- Náº¿u lá»‹ch sá»­ cÃ³: "User: TÃ´i tÃªn lÃ  Danh Thuáº­n"
  â†’ Khi user há»i "TÃªn tÃ´i lÃ  gÃ¬?" â†’ Tráº£ lá»i: "TÃªn cá»§a báº¡n lÃ  Danh Thuáº­n"

- Náº¿u lá»‹ch sá»­ cÃ³: "User: TÃ´i lÃ m viá»‡c táº¡i cÃ´ng ty ABC"
  â†’ Khi user há»i "TÃ´i lÃ m á»Ÿ Ä‘Ã¢u?" â†’ Tráº£ lá»i: "Báº¡n lÃ m viá»‡c táº¡i cÃ´ng ty ABC"

**HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:**
- Giáº£i thÃ­ch luáº­t má»™t cÃ¡ch rÃµ rÃ ng, trung láº­p, dá»… hiá»ƒu
- Náº¿u cÃ¢u tráº£ lá»i dá»±a trÃªn vÄƒn báº£n phÃ¡p luáº­t â†’ nÃªu rÃµ tÃªn vÄƒn báº£n vÃ  Äiá»u/Má»¥c/ChÆ°Æ¡ng
- Náº¿u thÃ´ng tin tá»« web â†’ nÃ³i rÃµ lÃ  tham kháº£o
- Giá»¯ giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p
- **Náº¿u cÃ¢u há»i khÃ´ng rÃµ rÃ ng hoáº·c vÃ´ nghÄ©a** (VD: chuá»—i kÃ½ tá»± ngáº«u nhiÃªn), hÃ£y lá»‹ch sá»± yÃªu cáº§u ngÆ°á»i dÃ¹ng lÃ m rÃµ cÃ¢u há»i cá»§a há»

ğŸ“‹ Lá»‹ch sá»­ há»™i thoáº¡i (Äá»ŒC Ká»¸):
{chat_history}"""),
        ("human", "{question}"),
    ])

    chitchat_chain = chitchat_prompt | llm_chat | StrOutputParser()

    generation = chitchat_chain.invoke({
        "question": question,
        "chat_history": chat_history if chat_history else "(khÃ´ng cÃ³ há»™i thoáº¡i trÆ°á»›c)"
    })

    state["generation"] = generation
    state["history"] = chat_history

    return {
        "question": question,
        "documents": [],
        "chat_history": chat_history,
        "generation": generation,
        "retries": state.get("retries", 0)
    }

print("âœ“ HÃ m chitchat vá»›i memory emphasis")

from typing import Literal
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
class FaqRouteQuery(BaseModel):
    """PhÃ¢n loáº¡i cÃ¢u há»i ngÆ°á»i dÃ¹ng tá»›i FAQ, web search hoáº·c chitchat"""
    datasource: Literal["vectorstore_faq", "chitchat"] = Field(
        ...,
        description=(
            "vectorstore_faq (FAQ), "
            "chitchat (giao tiáº¿p thÃ¢n thiá»‡n)"
        )
    )

# ========== KHá»I Táº O LLM ROUTER ==========
llm_router_faq = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
structured_llm_router_faq = llm_router_faq.with_structured_output(FaqRouteQuery)

# ========== SYSTEM PROMPT ==========
router_system_faq = """Báº¡n lÃ  chuyÃªn gia phÃ¢n loáº¡i cÃ¢u há»i ngÆ°á»i dÃ¹ng tá»›i nguá»“n dá»¯ liá»‡u phÃ¹ há»£p.

Báº¡n cÃ³ quyá»n truy cáº­p cÃ¡c nguá»“n:
1. **vectorstore_faq** - FAQ phÃ¡p luáº­t Ä‘Ã£ Ä‘Æ°á»£c biÃªn soáº¡n
2. **chitchat** - Giao tiáº¿p thÃ¢n thiá»‡n, há»i thÄƒm, cáº£m Æ¡n, chÃ o há»i

Quy táº¯c Æ°u tiÃªn:
- Náº¿u cÃ¢u há»i mang tÃ­nh chÃ o há»i,trÃ² chuyá»‡n, cáº£m Æ¡n, giá»›i thiá»‡u báº£n thÃ¢n â†’ **chitchat**
- Náº¿u cÃ¢u há»i lÃ  chuá»—i kÃ½ tá»± vÃ´ nghÄ©a, ngáº«u nhiÃªn, hoáº·c khÃ´ng cÃ³ Ã½ nghÄ©a rÃµ rÃ ng (VD: "E, P, A, L, A, Z", "asdfgh", "123 abc xyz") â†’ **chitchat**
- Náº¿u cÃ¢u há»i quÃ¡ ngáº¯n hoáº·c khÃ´ng rÃµ rÃ ng vÃ  khÃ´ng liÃªn quan Ä‘áº¿n phÃ¡p luáº­t â†’ **chitchat**
- CHá»ˆ náº¿u cÃ¢u há»i cÃ³ Ã½ nghÄ©a rÃµ rÃ ng vÃ  liÃªn quan Ä‘áº¿n ná»™i dung phÃ¡p luáº­t EPR â†’ **vectorstore_faq**

CÃ¢u há»i hiá»‡n táº¡i: {question}"""

# ========== Táº O PROMPT ==========
route_prompt_faq = ChatPromptTemplate.from_messages([
    ("system", router_system_faq),
    ("human", "{question}")
])

# ========== COMBINE PROMPT Vá»šI STRUCTURED LLM ==========
question_router_faq = route_prompt_faq | structured_llm_router_faq

print("âœ“ FAQ question router created successfully!")

def route_question_faq(state):
    """Route cÃ¢u há»i ban Ä‘áº§u vÃ  lÆ°u snapshot cá»§a chat_history"""
    print("---PHÃ‚N LUá»’NG CÃ‚U Há»I (Vá»šI NGá»® Cáº¢NH)---")

    question = state["question"]
    chat_history = get_full_chat_history()  # Load from memory

    # âœ… LÆ°u cÃ¢u há»i gá»‘c
    if "original_question" not in state or not state.get("original_question"):
        print(f"  ğŸ’¾ LÆ°u cÃ¢u há»i gá»‘c: {question}")
        state["original_question"] = question

    # âœ… LÆ°u snapshot cá»§a chat_history TRÆ¯á»šC KHI vÃ o FAQ path
    if "original_chat_history" not in state or not state.get("original_chat_history"):
        print(f"  ğŸ’¾ LÆ°u snapshot chat_history ({len(chat_history)} kÃ½ tá»±)")
        state["original_chat_history"] = chat_history

    print(f"Lá»‹ch sá»­ há»™i thoáº¡i:\n{chat_history}\n")
    print(f"CÃ¢u há»i hiá»‡n táº¡i: {question}")

    # Gá»i LLM router
    source = question_router_faq.invoke({
        "question": question,
        "chat_history": chat_history
    })

    datasource = source.get("datasource") if isinstance(source, dict) else getattr(source, "datasource", None)

    print(f"---PHÃ‚N LUá»’NG Tá»šI: {datasource.upper() if datasource else 'UNKNOWN'}---")

    if datasource == 'vectorstore_faq':
        return "vectorstore_faq"
    elif datasource == 'chitchat':
        return "chitchat"


print("âœ… route_question_faq vá»›i chat_history snapshot")


from typing import List, TypedDict
from langgraph.graph import StateGraph, END


print("âœ“ State defined")

# ========== NODE FUNCTIONS ==========

def retrieve_faq_node(state):
    """Retrieve FAQ documents"""
    print("\n" + "="*80)
    print("ğŸ“š RETRIEVE FAQ")
    print("="*80)

    question = state["question"]
    print(f"  Question: {question}")

    # Use your existing retrieve_faq_top1 function
    documents = retrieve_faq_top1(question, score_threshold=0.6)

    print(f"  Documents found: {len(documents)}")
    print("="*80 + "\n")

    state["documents"] = documents
    return state




def generate_faq_node(state):
    """Generate answer from FAQ documents"""
    print("\n" + "="*80)
    print("ğŸ’¬ GENERATE FAQ ANSWER")
    print("="*80)

    question = state["question"]
    documents = state["documents"]

    if not documents:
        print("  âš ï¸  No documents")
        state["generation"] = "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin trong FAQ."
        return state

    doc = documents[0]
    faq_question = doc.metadata.get("CÃ¢u_há»i", "")
    faq_answer = doc.page_content

    print(f"  FAQ: {faq_question[:60]}...")

    prompt = ChatPromptTemplate.from_messages([
        ("system", """Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» luáº­t EPR.
Dá»±a vÃ o FAQ Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i."""),
        ("human", """FAQ: {faq_question}
Tráº£ lá»i: {faq_answer}

CÃ¢u há»i: {user_question}

Tráº£ lá»i:""")
    ])

    chain = prompt | llm | StrOutputParser()

    generation = chain.invoke({
        "faq_question": faq_question,
        "faq_answer": faq_answer,
        "user_question": question
    })

    print(f"  Answer: {generation[:80]}...")
    print("="*80 + "\n")

    state["generation"] = generation
    return state


def new_round_router(state):
    """
    Reset state and restore chat_history from snapshot
    """
    print("\n" + "="*80)
    print("ğŸ” NEW ROUND: RESETTING STATE")
    print("="*80)

    # âœ… Restore chat_history from snapshot
    original_chat_history = state.get("original_chat_history", "")
    current_chat_history = state.get("chat_history", "")

    # Prefer original snapshot
    chat_history_to_use = original_chat_history if original_chat_history else current_chat_history

    # Restore original question
    original_question = state.get("original_question", state.get("question", ""))

    print(f"  ğŸ“Œ Restoring original question: {original_question}")

    if original_chat_history:
        print(f"  ğŸ’¬ Restoring chat history from snapshot ({len(original_chat_history)} chars)")
        print(f"     (Ignoring modified chat history from FAQ path)")
    elif current_chat_history:
        print(f"  ğŸ’¬ Using current chat history ({len(current_chat_history)} chars)")
    else:
        print(f"  âš ï¸  No chat history")

    print("="*80 + "\n")

    return {
        **state,
        "question": original_question,
        "original_question": original_question,
        "chat_history": chat_history_to_use,  # âœ… Use clean snapshot
        "original_chat_history": original_chat_history,  # âœ… Keep snapshot
        "retries": 0,
        "generation_retries": 0,
        "documents": [],
        "generation": "",
    }

print("âœ… new_round_router ready")



# ========== DECISION FUNCTIONS ==========

def decide_after_retrieve_faq(state):
    """
    Decision function after retrieve_faq_node

    Check if documents were retrieved:
    - If yes (has docs) â†’ go to "generate_faq"
    - If no (no docs) â†’ go to "new_round_router"

    Returns:
        str: "generate_faq" or "new_round_router"
    """
    documents = state.get("documents", [])

    print(f"\nğŸ”€ DECISION AFTER RETRIEVE FAQ")
    print(f"   Documents: {len(documents)}")

    if documents:
        print(f"   â¡ï¸  HAS DOCS â†’ generate_faq")
        return "generate_faq"
    else:
        print(f"   â¡ï¸  NO DOCS â†’ new_round_router")
        return "new_round_router"






data={"meta":[
{
  "Äiá»u": "Äiá»u 1. Pháº¡m vi Ä‘iá»u chá»‰nh",
  "ChÆ°Æ¡ng": "ChÆ°Æ¡ng I. NHá»®NG QUY Äá»ŠNH CHUNG",
  "Má»¥c": "",
  "Pages": "2",
  "Text": "Nghá»‹ Ä‘á»‹nh nÃ y quy Ä‘á»‹nh chi tiáº¿t khoáº£n 4 Äiá»u 9; khoáº£n 5 Äiá»u 13; khoáº£n 4 Äiá»u 14; khoáº£n 4 Äiá»u 15; khoáº£n 3 Äiá»u 20; khoáº£n 4 Äiá»u 21; khoáº£n 4 Äiá»u 23; khoáº£n 2 Äiá»u 24; khoáº£n 3 Äiá»u 25; khoáº£n 7 Äiá»u 28; khoáº£n 7 Äiá»u 33; khoáº£n 7 Äiá»u 37; khoáº£n 6 Äiá»u 43; khoáº£n 6 Äiá»u 44; khoáº£n 5 Äiá»u 46; khoáº£n 8 Äiá»u 49; khoáº£n 6 Äiá»u 51; khoáº£n 4 Äiá»u 52; khoáº£n 4 Äiá»u 53; khoáº£n 5 Äiá»u 54; khoáº£n 5 Äiá»u 55; khoáº£n 7 Äiá»u 56; khoáº£n 3 Äiá»u 59; khoáº£n 5 Äiá»u 61; khoáº£n 1 Äiá»u 63; khoáº£n 7 Äiá»u 65; khoáº£n 7 Äiá»u 67; Ä‘iá»ƒm d khoáº£n 2 Äiá»u 69; khoáº£n 2 Äiá»u 70; khoáº£n 3 Äiá»u 71; khoáº£n 8 Äiá»u 72; khoáº£n 7 Äiá»u 73; khoáº£n 4 Äiá»u 78; khoáº£n 3, khoáº£n 4 Äiá»u 79; khoáº£n 3 Äiá»u 80; khoáº£n 5 Äiá»u 85; khoáº£n 1 Äiá»u 86; khoáº£n 1 Äiá»u 105; khoáº£n 4 Äiá»u 110; khoáº£n 7 Äiá»u 111; khoáº£n 7 Äiá»u 112; khoáº£n 4 Äiá»u 114; khoáº£n 3 Äiá»u 115; Ä‘iá»ƒm a khoáº£n 2 Äiá»u 116; khoáº£n 7 Äiá»u 121; khoáº£n 4 Äiá»u 131; khoáº£n 4 Äiá»u 132; khoáº£n 4 Äiá»u 135; khoáº£n 5 Äiá»u 137; khoáº£n 5 Äiá»u 138; khoáº£n 2 Äiá»u 140; khoáº£n 5 Äiá»u 141; khoáº£n 4 Äiá»u 142; khoáº£n 3 Äiá»u 143; khoáº£n 5 Äiá»u 144; khoáº£n 4 Äiá»u 145; khoáº£n 2 Äiá»u 146; khoáº£n 7 Äiá»u 148; khoáº£n 5 Äiá»u 149; khoáº£n 5 Äiá»u 150; khoáº£n 3 Äiá»u 151; khoáº£n 4 Äiá»u 158; khoáº£n 6 Äiá»u 160; khoáº£n 4 Äiá»u 167; khoáº£n 6 Äiá»u 171 Luáº­t Báº£o vá»‡ mÃ´i trÆ°á»ng vá» báº£o vá»‡ cÃ¡c thÃ nh pháº§n mÃ´i trÆ°á»ng; phÃ¢n vÃ¹ng mÃ´i trÆ°á»ng, Ä‘Ã¡nh giÃ¡ mÃ´i trÆ°á»ng chiáº¿n lÆ°á»£c, Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng mÃ´i trÆ°á»ng; giáº¥y phÃ©p mÃ´i trÆ°á»ng, Ä‘Äƒng kÃ½ mÃ´i trÆ°á»ng; báº£o vá»‡ mÃ´i trÆ°á»ng trong hoáº¡t Ä‘á»™ng sáº£n xuáº¥t, kinh doanh, dá»‹ch vá»¥, Ä‘Ã´ thá»‹, nÃ´ng thÃ´n vÃ  má»™t sá»‘ lÄ©nh vá»±c; quáº£n lÃ½ cháº¥t tháº£i; trÃ¡ch nhiá»‡m tÃ i cháº¿, xá»­ lÃ½ sáº£n pháº©m, bao bÃ¬ cá»§a tá»• chá»©c, cÃ¡ nhÃ¢n sáº£n xuáº¥t, nháº­p kháº©u; quan tráº¯c mÃ´i trÆ°á»ng; há»‡ thá»‘ng thÃ´ng tin, cÆ¡ sá»Ÿ dá»¯ liá»‡u vá» mÃ´i trÆ°á»ng; phÃ²ng ngá»«a, á»©ng phÃ³ sá»± cá»‘ mÃ´i trÆ°á»ng, bá»“i thÆ°á»ng thiá»‡t háº¡i vá» mÃ´i trÆ°á»ng; cÃ´ng cá»¥ kinh táº¿ vÃ  nguá»“n lá»±c báº£o vá»‡ mÃ´i trÆ°á»ng; quáº£n lÃ½ nhÃ  nÆ°á»›c, kiá»ƒm tra, thanh tra vÃ  cung cáº¥p dá»‹ch vá»¥ cÃ´ng trá»±c tuyáº¿n vá» báº£o vá»‡ mÃ´i trÆ°á»ng."
},
{
  "Äiá»u": "Äiá»u 2. Äá»‘i tÆ°á»£ng Ã¡p dá»¥ng",
  "ChÆ°Æ¡ng": "ChÆ°Æ¡ng I. NHá»®NG QUY Äá»ŠNH CHUNG",
  "Má»¥c": "",
  "Pages": "2",
  "Text": "Nghá»‹ Ä‘á»‹nh nÃ y Ã¡p dá»¥ng Ä‘á»‘i vá»›i cÆ¡ quan, tá»• chá»©c, cá»™ng Ä‘á»“ng dÃ¢n cÆ°, há»™ gia Ä‘Ã¬nh vÃ  cÃ¡ nhÃ¢n cÃ³ hoáº¡t Ä‘á»™ng liÃªn quan Ä‘áº¿n cÃ¡c ná»™i dung quy Ä‘á»‹nh táº¡i Äiá»u 1 Nghá»‹ Ä‘á»‹nh nÃ y trÃªn lÃ£nh thá»• nÆ°á»›c Cá»™ng hÃ²a xÃ£ há»™i chá»§ nghÄ©a Viá»‡t Nam, bao gá»“m Ä‘áº¥t liá»n, háº£i Ä‘áº£o, vÃ¹ng biá»ƒn, lÃ²ng Ä‘áº¥t vÃ  vÃ¹ng trá»i."
},
{
  "Äiá»u": "Äiá»u 3. Giáº£i thÃ­ch tá»« ngá»¯",
  "ChÆ°Æ¡ng": "ChÆ°Æ¡ng I. NHá»®NG QUY Äá»ŠNH CHUNG",
  "Má»¥c": "",
  "Pages": "2,3,4,5,6",
  "Text": """Trong Nghá»‹ Ä‘á»‹nh nÃ y, cÃ¡c tá»« ngá»¯ dÆ°á»›i Ä‘Ã¢y Ä‘Æ°á»£c hiá»ƒu nhÆ° sau:
  1. Há»‡ thá»‘ng thu gom, thoÃ¡t nÆ°á»›c mÆ°a cá»§a cÆ¡ sá»Ÿ sáº£n xuáº¥t, kinh doanh, dá»‹ch vá»¥ gá»“m máº¡ng lÆ°á»›i thu gom, thoÃ¡t nÆ°á»›c (Ä‘Æ°á»ng á»‘ng, há»‘ ga, cá»‘ng, kÃªnh, mÆ°Æ¡ng, há»“ Ä‘iá»u hÃ²a), cÃ¡c tráº¡m bÆ¡m thoÃ¡t nÆ°á»›c mÆ°a vÃ  cÃ¡c cÃ´ng trÃ¬nh phá»¥ trá»£ khÃ¡c nháº±m má»¥c Ä‘Ã­ch thu gom, chuyá»ƒn táº£i, tiÃªu thoÃ¡t nÆ°á»›c mÆ°a, chá»‘ng ngáº­p Ãºng.
  2. Há»‡ thá»‘ng thu gom, xá»­ lÃ½, thoÃ¡t nÆ°á»›c tháº£i cá»§a cÆ¡ sá»Ÿ sáº£n xuáº¥t, kinh doanh, dá»‹ch vá»¥ gá»“m máº¡ng lÆ°á»›i thu gom nÆ°á»›c tháº£i (Ä‘Æ°á»ng á»‘ng, há»‘ ga, cá»‘ng),cÃ¡c tráº¡m bÆ¡m nÆ°á»›c tháº£i, cÃ¡c cÃ´ng trÃ¬nh xá»­ lÃ½ nÆ°á»›c tháº£i vÃ  cÃ¡c cÃ´ng trÃ¬nh phá»¥ trá»£ nháº±m má»¥c Ä‘Ã­ch thu gom,xá»­ lÃ½ nÆ°á»›c tháº£i vÃ  thoÃ¡t nÆ°á»›c tháº£i sau xá»­ lÃ½ vÃ o mÃ´i trÆ°á»ng tiáº¿p nháº­n.
  3. CÃ´ng trÃ¬nh, thiáº¿t bá»‹ xá»­ lÃ½ cháº¥t tháº£i táº¡i chá»— lÃ  cÃ¡c cÃ´ng trÃ¬nh, thiáº¿t bá»‹ Ä‘Æ°á»£c sáº£n xuáº¥t, láº¯p rÃ¡p sáºµn hoáº·c Ä‘Æ°á»£c xÃ¢y dá»±ng táº¡i chá»— Ä‘á»ƒ xá»­ lÃ½ nÆ°á»›c tháº£i, khÃ­ tháº£i cá»§a cÆ¡ sá»Ÿ sáº£n xuáº¥t, kinh doanh, dá»‹ch vá»¥ quy mÃ´ há»™ gia Ä‘Ã¬nh; cÃ´ng viÃªn,
      khu vui chÆ¡i, giáº£i trÃ­, khu kinh doanh, dá»‹ch vá»¥ táº­p trung, chá»£, nhÃ  ga, báº¿n xe, báº¿n tÃ u, báº¿n cáº£ng, báº¿n phÃ  vÃ  khu vá»±c cÃ´ng cá»™ng khÃ¡c; há»™ gia Ä‘Ã¬nh, cÃ¡ nhÃ¢n cÃ³ phÃ¡t sinh nÆ°á»›c tháº£i, khÃ­ tháº£i pháº£i xá»­ lÃ½ theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» báº£o vá»‡ mÃ´i trÆ°á»ng.
  4. NÆ°á»›c trao Ä‘á»•i nhiá»‡t lÃ  nÆ°á»›c phá»¥c vá»¥ má»¥c Ä‘Ã­ch giáº£i nhiá»‡t (nÆ°á»›c lÃ m mÃ¡t) hoáº·c gia nhiá»‡t cho thiáº¿t bá»‹, mÃ¡y mÃ³c trong quÃ¡ trÃ¬nh sáº£n xuáº¥t, khÃ´ng tiáº¿p xÃºc trá»±c tiáº¿p vá»›i nguyÃªn liá»‡u, váº­t liá»‡u, nhiÃªn liá»‡u, hÃ³a cháº¥t sá»­ dá»¥ng trong cÃ¡c cÃ´ng Ä‘oáº¡n sáº£n xuáº¥t.
  5. Tá»± xá»­ lÃ½ cháº¥t tháº£i lÃ  hoáº¡t Ä‘á»™ng xá»­ lÃ½ cháº¥t tháº£i do chá»§ nguá»“n tháº£i thá»±c hiá»‡n trong khuÃ´n viÃªn cÆ¡ sá»Ÿ phÃ¡t sinh cháº¥t tháº£i báº±ng cÃ¡c háº¡ng má»¥c,
  dÃ¢y chuyá»n sáº£n xuáº¥t hoáº·c cÃ´ng trÃ¬nh báº£o vá»‡ mÃ´i trÆ°á»ng Ä‘Ã¡p á»©ng yÃªu cáº§u vá» báº£o vá»‡ mÃ´i trÆ°á»ng.
  6. TÃ¡i sá»­ dá»¥ng cháº¥t tháº£i lÃ  viá»‡c sá»­ dá»¥ng láº¡i cháº¥t tháº£i má»™t cÃ¡ch trá»±c tiáº¿p hoáº·c sá»­ dá»¥ng sau khi Ä‘Ã£ sÆ¡ cháº¿. SÆ¡ cháº¿ cháº¥t tháº£i lÃ  viá»‡c sá»­ dá»¥ng cÃ¡c biá»‡n phÃ¡p
  ká»¹ thuáº­t cÆ¡ - lÃ½ Ä‘Æ¡n thuáº§n nháº±m thay Ä‘á»•i tÃ­nh cháº¥t váº­t lÃ½ nhÆ° kÃ­ch thÆ°á»›c, Ä‘á»™ áº©m, nhiá»‡t Ä‘á»™ Ä‘á»ƒ táº¡o Ä‘iá»u kiá»‡n thuáº­n lá»£i cho viá»‡c phÃ¢n loáº¡i, lÆ°u giá»¯, váº­n chuyá»ƒn, tÃ¡i sá»­ dá»¥ng, tÃ¡i cháº¿, Ä‘á»“ng xá»­ lÃ½, xá»­ lÃ½ nháº±m phá»‘i trá»™n hoáº·c tÃ¡ch riÃªng cÃ¡c thÃ nh pháº§n cá»§a cháº¥t tháº£i cho phÃ¹ há»£p vá»›i cÃ¡c quy trÃ¬nh quáº£n lÃ½ khÃ¡c nhau.
  7. TÃ¡i cháº¿ cháº¥t tháº£i lÃ  quÃ¡ trÃ¬nh sá»­ dá»¥ng cÃ¡c giáº£i phÃ¡p cÃ´ng nghá»‡, ká»¹ thuáº­t Ä‘á»ƒ thu láº¡i cÃ¡c thÃ nh pháº§n cÃ³ giÃ¡ trá»‹ tá»« cháº¥t tháº£i.
  8. Xá»­ lÃ½ cháº¥t tháº£i lÃ  quÃ¡ trÃ¬nh sá»­ dá»¥ng cÃ¡c giáº£i phÃ¡p cÃ´ng nghá»‡, ká»¹ thuáº­t (khÃ¡c vá»›i sÆ¡ cháº¿) Ä‘á»ƒ lÃ m giáº£m, loáº¡i bá», cÃ´ láº­p, cÃ¡ch ly, thiÃªu Ä‘á»‘t, tiÃªu há»§y, chÃ´n láº¥p cháº¥t tháº£i vÃ  cÃ¡c yáº¿u tá»‘ cÃ³ háº¡i trong cháº¥t tháº£i.
  9. NÆ°á»›c tháº£i lÃ  nÆ°á»›c Ä‘Ã£ bá»‹ thay Ä‘á»•i Ä‘áº·c Ä‘iá»ƒm, tÃ­nh cháº¥t Ä‘Æ°á»£c tháº£i ra tá»« hoáº¡t Ä‘á»™ng sáº£n xuáº¥t, kinh doanh, dá»‹ch vá»¥, sinh hoáº¡t hoáº·c hoáº¡t Ä‘á»™ng khÃ¡c.
  10. Cháº¥t tháº£i ráº¯n thÃ´ng thÆ°á»ng lÃ  cháº¥t tháº£i ráº¯n khÃ´ng thuá»™c danh má»¥c cháº¥t tháº£i nguy háº¡i vÃ  khÃ´ng thuá»™c danh má»¥c cháº¥t tháº£i cÃ´ng nghiá»‡p pháº£i kiá»ƒm soÃ¡t cÃ³ yáº¿u tá»‘ nguy háº¡i vÆ°á»£t ngÆ°á»¡ng cháº¥t tháº£i nguy háº¡i.
  11. Cháº¥t tháº£i ráº¯n sinh hoáº¡t (cÃ²n gá»i lÃ  rÃ¡c tháº£i sinh hoáº¡t) lÃ  cháº¥t tháº£i ráº¯n
  phÃ¡t sinh trong sinh hoáº¡t thÆ°á»ng ngÃ y cá»§a con ngÆ°á»i.
  12. Cháº¥t tháº£i cÃ´ng nghiá»‡p lÃ  cháº¥t tháº£i phÃ¡t sinh tá»« hoáº¡t Ä‘á»™ng sáº£n xuáº¥t,
  kinh doanh, dá»‹ch vá»¥, trong Ä‘Ã³ bao gá»“m cháº¥t tháº£i nguy háº¡i, cháº¥t tháº£i cÃ´ng
  nghiá»‡p pháº£i kiá»ƒm soÃ¡t vÃ  cháº¥t tháº£i ráº¯n cÃ´ng nghiá»‡p thÃ´ng thÆ°á»ng.
  13. Vi nhá»±a trong sáº£n pháº©m, hÃ ng hÃ³a lÃ  cÃ¡c háº¡t nhá»±a ráº¯n, khÃ´ng tan
  trong nÆ°á»›c cÃ³ Ä‘Æ°á»ng kÃ­nh nhá» hÆ¡n 05 mm vá»›i thÃ nh pháº§n chÃ­nh lÃ  polyme
  tá»•ng há»£p hoáº·c bÃ¡n tá»•ng há»£p, Ä‘Æ°á»£c phá»‘i trá»™n cÃ³ chá»§ Ä‘Ã­ch trong cÃ¡c sáº£n pháº©m,
  hÃ ng hÃ³a bao gá»“m: kem Ä‘Ã¡nh rÄƒng, bá»™t giáº·t, xÃ  phÃ²ng, má»¹ pháº©m, dáº§u gá»™i Ä‘áº§u,
  sá»¯a táº¯m, sá»¯a rá»­a máº·t vÃ  cÃ¡c sáº£n pháº©m táº©y da khÃ¡c.
  14. Sáº£n pháº©m nhá»±a sá»­ dá»¥ng má»™t láº§n lÃ  cÃ¡c sáº£n pháº©m (trá»« sáº£n pháº©m gáº¯n
  kÃ¨m khÃ´ng thá»ƒ thay tháº¿) bao gá»“m khay, há»™p chá»©a Ä‘á»±ng thá»±c pháº©m, bÃ¡t, Ä‘Å©a,
  ly, cá»‘c, dao, thÃ¬a, dÄ©a, á»‘ng hÃºt, dá»¥ng cá»¥ Äƒn uá»‘ng khÃ¡c cÃ³ thÃ nh pháº§n nhá»±a
  Ä‘Æ°á»£c thiáº¿t káº¿ vÃ  Ä‘Æ°a ra thá»‹ trÆ°á»ng vá»›i chá»§ Ä‘Ã­ch Ä‘á»ƒ sá»­ dá»¥ng má»™t láº§n trÆ°á»›c khi
  tháº£i bá» ra mÃ´i trÆ°á»ng.
  15. Bao bÃ¬ nhá»±a khÃ³ phÃ¢n há»§y sinh há»c lÃ  bao bÃ¬ cÃ³ thÃ nh pháº§n chÃ­nh lÃ 
  polyme cÃ³ nguá»“n gá»‘c tá»« dáº§u má» nhÆ° nhá»±a Polyme Etylen (PE), Polypropylen
  (PP), Polyme Styren (PS), Polyme Vinyl Clorua (PVC), Polyethylene
  Terephthalate (PET) vÃ  thÆ°á»ng khÃ³ phÃ¢n há»§y, lÃ¢u phÃ¢n há»§y trong mÃ´i trÆ°á»ng
  tháº£i bá» (mÃ´i trÆ°á»ng nÆ°á»›c, mÃ´i trÆ°á»ng Ä‘áº¥t hoáº·c táº¡i bÃ£i chÃ´n láº¥p cháº¥t tháº£i ráº¯n).
  16. Khu báº£o tá»“n thiÃªn nhiÃªn bao gá»“m vÆ°á»n quá»‘c gia, khu dá»± trá»¯ thiÃªn
  nhiÃªn, khu báº£o tá»“n loÃ i - sinh cáº£nh vÃ  khu báº£o vá»‡ cáº£nh quan Ä‘Æ°á»£c xÃ¡c láº­p theo
  quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» Ä‘a dáº¡ng sinh há»c, lÃ¢m nghiá»‡p vÃ  thá»§y sáº£n.
  17. HÃ ng hoÃ¡ mÃ´i trÆ°á»ng lÃ  cÃ´ng nghá»‡, thiáº¿t bá»‹, sáº£n pháº©m Ä‘Æ°á»£c sá»­ dá»¥ng
  Ä‘á»ƒ báº£o vá»‡ mÃ´i trÆ°á»ng.
  18. Há»‡ thá»‘ng thÃ´ng tin mÃ´i trÆ°á»ng lÃ  má»™t há»‡ thá»‘ng Ä‘á»“ng bá»™ theo má»™t
  kiáº¿n trÃºc tá»•ng thá»ƒ bao gá»“m con ngÆ°á»i, mÃ¡y mÃ³c thiáº¿t bá»‹, ká»¹ thuáº­t, dá»¯ liá»‡u vÃ 
  cÃ¡c chÆ°Æ¡ng trÃ¬nh lÃ m nhiá»‡m vá»¥ thu nháº­n, xá»­ lÃ½, lÆ°u trá»¯ vÃ  phÃ¢n phá»‘i thÃ´ng tin
  vá» mÃ´i trÆ°á»ng cho ngÆ°á»i sá»­ dá»¥ng trong má»™t mÃ´i trÆ°á»ng nháº¥t Ä‘á»‹nh.
  19. Háº¡n ngáº¡ch xáº£ nÆ°á»›c tháº£i lÃ  táº£i lÆ°á»£ng cá»§a tá»«ng thÃ´ng sá»‘ Ã´ nhiá»…m cÃ³
  thá»ƒ tiáº¿p tá»¥c xáº£ vÃ o mÃ´i trÆ°á»ng nÆ°á»›c.
  20. Nguá»“n Ã´ nhiá»…m Ä‘iá»ƒm lÃ  nguá»“n tháº£i trá»±c tiáº¿p cháº¥t Ã´ nhiá»…m vÃ o mÃ´i
  trÆ°á»ng pháº£i Ä‘Æ°á»£c xá»­ lÃ½ vÃ  cÃ³ tÃ­nh cháº¥t Ä‘Æ¡n láº», cÃ³ vá»‹ trÃ­ xÃ¡c Ä‘á»‹nh.
  21. Nguá»“n Ã´ nhiá»…m diá»‡n lÃ  nguá»“n tháº£i cháº¥t Ã´ nhiá»…m vÃ o mÃ´i trÆ°á»ng, cÃ³
  tÃ­nh cháº¥t phÃ¢n tÃ¡n, khÃ´ng cÃ³ vá»‹ trÃ­ xÃ¡c Ä‘á»‹nh.
  22. CÆ¡ sá»Ÿ thá»±c hiá»‡n dá»‹ch vá»¥ xá»­ lÃ½ cháº¥t tháº£i lÃ  cÆ¡ sá»Ÿ cÃ³ hoáº¡t Ä‘á»™ng xá»­ lÃ½
  cháº¥t tháº£i (bao gá»“m cáº£ hoáº¡t Ä‘á»™ng tÃ¡i cháº¿, Ä‘á»“ng xá»­ lÃ½ cháº¥t tháº£i) cho cÃ¡c há»™ gia
  Ä‘Ã¬nh, cÃ¡ nhÃ¢n, cÆ¡ quan, tá»• chá»©c, cÆ¡ sá»Ÿ sáº£n xuáº¥t, kinh doanh, dá»‹ch vá»¥, khu sáº£n
  xuáº¥t, kinh doanh, dá»‹ch vá»¥ táº­p trung, cá»¥m cÃ´ng nghiá»‡p.
  23. NÆ°á»›c tháº£i pháº£i xá»­ lÃ½ lÃ  nÆ°á»›c tháº£i náº¿u khÃ´ng xá»­ lÃ½ thÃ¬ khÃ´ng Ä‘Ã¡p
  á»©ng quy chuáº©n ká»¹ thuáº­t mÃ´i trÆ°á»ng, quy chuáº©n ká»¹ thuáº­t, hÆ°á»›ng dáº«n ká»¹ thuáº­t,quy Ä‘á»‹nh Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng khi Ä‘Ã¡p á»©ng yÃªu cáº§u vá» báº£o vá»‡ mÃ´i trÆ°á»ng hoáº·c quy Ä‘á»‹nh cá»§a chá»§ Ä‘áº§u tÆ° xÃ¢y dá»±ng vÃ  kinh doanh háº¡ táº§ng khu sáº£n xuáº¥t, kinh doanh, dá»‹ch vá»¥ táº­p trung, cá»¥m cÃ´ng nghiá»‡p, há»‡ thá»‘ng xá»­ lÃ½ nÆ°á»›c tháº£i táº­p trung cá»§a khu Ä‘Ã´ thá»‹, khu dÃ¢n cÆ° táº­p trung.
  24. Nguá»“n phÃ¡t sinh nÆ°á»›c tháº£i lÃ  há»‡ thá»‘ng, cÃ´ng trÃ¬nh, mÃ¡y mÃ³c, thiáº¿t bá»‹, cÃ´ng Ä‘oáº¡n hoáº·c hoáº¡t Ä‘á»™ng cÃ³ phÃ¡t sinh nÆ°á»›c tháº£i. Nguá»“n phÃ¡t sinh nÆ°á»›c tháº£i cÃ³ thá»ƒ bao gá»“m nhiá»u há»‡ thá»‘ng, cÃ´ng trÃ¬nh, mÃ¡y mÃ³c, thiáº¿t bá»‹, cÃ´ng Ä‘oáº¡n hoáº·c hoáº¡t Ä‘á»™ng cÃ³ phÃ¡t sinh nÆ°á»›c tháº£i cÃ¹ng tÃ­nh cháº¥t vÃ  cÃ¹ng khu vá»±c.
  25. DÃ²ng nÆ°á»›c tháº£i lÃ  nÆ°á»›c tháº£i sau xá»­ lÃ½ hoáº·c pháº£i Ä‘Æ°á»£c kiá»ƒm soÃ¡t trÆ°á»›c khi xáº£ ra nguá»“n tiáº¿p nháº­n nÆ°á»›c tháº£i táº¡i má»™t vá»‹ trÃ­ xáº£ tháº£i xÃ¡c Ä‘á»‹nh.
  26. Nguá»“n tiáº¿p nháº­n nÆ°á»›c tháº£i (cÃ²n gá»i lÃ  nguá»“n nÆ°á»›c tiáº¿p nháº­n) lÃ  cÃ¡c dáº¡ng tÃ­ch tá»¥ nÆ°á»›c tá»± nhiÃªn, nhÃ¢n táº¡o cÃ³ má»¥c Ä‘Ã­ch sá»­ dá»¥ng xÃ¡c Ä‘á»‹nh do cÆ¡ quan nhÃ  nÆ°á»›c cÃ³ tháº©m quyá»n quy Ä‘á»‹nh. CÃ¡c dáº¡ng tÃ­ch tá»¥ nÆ°á»›c tá»± nhiÃªn bao gá»“m sÃ´ng, suá»‘i, kÃªnh, mÆ°Æ¡ng, ráº¡ch, há»“, ao, Ä‘áº§m, phÃ¡ vÃ  cÃ¡c dáº¡ng tÃ­ch tá»¥ nÆ°á»›c khÃ¡c Ä‘Æ°á»£c hÃ¬nh thÃ nh tá»± nhiÃªn. CÃ¡c dáº¡ng tÃ­ch tá»¥ nÆ°á»›c nhÃ¢n táº¡o, bao gá»“m: Há»“ chá»©a thá»§y Ä‘iá»‡n, thá»§y lá»£i, sÃ´ng, kÃªnh, mÆ°Æ¡ng, ráº¡ch, há»“, ao, Ä‘áº§m vÃ  cÃ¡c dáº¡ng tÃ­ch tá»¥ nÆ°á»›c khÃ¡c do con ngÆ°á»i táº¡o ra.
  TrÆ°á»ng há»£p nguá»“n nÆ°á»›c táº¡i vá»‹ trÃ­ xáº£ nÆ°á»›c tháº£i chÆ°a Ä‘Æ°á»£c cÆ¡ quan nhÃ  nÆ°á»›c cÃ³ tháº©m quyá»n xÃ¡c Ä‘á»‹nh má»¥c Ä‘Ã­ch sá»­ dá»¥ng thÃ¬ nguá»“n tiáº¿p nháº­n nÆ°á»›c tháº£i lÃ  nguá»“n nÆ°á»›c liá»n thÃ´ng gáº§n nháº¥t Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh má»¥c Ä‘Ã­ch sá»­ dá»¥ng.
  27. Bá»¥i, khÃ­ tháº£i pháº£i xá»­ lÃ½ lÃ  bá»¥i, khÃ­ tháº£i náº¿u khÃ´ng xá»­ lÃ½ thÃ¬ khÃ´ng Ä‘Ã¡p á»©ng quy chuáº©n ká»¹ thuáº­t mÃ´i trÆ°á»ng.
  28. Nguá»“n phÃ¡t sinh bá»¥i, khÃ­ tháº£i (sau Ä‘Ã¢y gá»i chung lÃ  nguá»“n phÃ¡t sinh khÃ­ tháº£i) lÃ  há»‡ thá»‘ng, cÃ´ng trÃ¬nh, mÃ¡y mÃ³c, thiáº¿t bá»‹, cÃ´ng Ä‘oáº¡n hoáº·c hoáº¡t Ä‘á»™ng cÃ³ phÃ¡t sinh bá»¥i, khÃ­ tháº£i vÃ  cÃ³ vá»‹ trÃ­ xÃ¡c Ä‘á»‹nh. TrÆ°á»ng há»£p nhiá»u há»‡ thá»‘ng, cÃ´ng trÃ¬nh, mÃ¡y mÃ³c, thiáº¿t bá»‹ táº¡i cÃ¹ng má»™t khu vá»±c cÃ³ phÃ¡t sinh bá»¥i, khÃ­ tháº£i cÃ³ cÃ¹ng tÃ­nh cháº¥t vÃ  Ä‘Æ°á»£c thu gom, xá»­ lÃ½ chung táº¡i má»™t há»‡ thá»‘ng xá»­ lÃ½ khÃ­ tháº£i thÃ¬ Ä‘Æ°á»£c coi lÃ  má»™t nguá»“n khÃ­ tháº£i.

  29.DÃ²ng khÃ­ tháº£i lÃ  khÃ­ tháº£i sau khi xá»­ lÃ½ Ä‘Æ°á»£c xáº£ vÃ o mÃ´i trÆ°á»ng khÃ´ng khÃ­ thÃ´ng qua á»‘ng khÃ³i, á»‘ng tháº£i.
  30.Hoáº¡t Ä‘á»™ng sáº£n xuáº¥t, kinh doanh, dá»‹ch vá»¥ lÃ  hoáº¡t Ä‘á»™ng cá»§a tá»• chá»©c, cÃ¡ nhÃ¢n thá»±c hiá»‡n Ä‘á»ƒ sáº£n xuáº¥t, kinh doanh, dá»‹ch vá»¥, khÃ´ng bao gá»“m hoáº¡t Ä‘á»™ng dá»‹ch vá»¥ hÃ nh chÃ­nh cÃ´ng khi xem xÃ©t cáº¥p giáº¥y phÃ©p mÃ´i trÆ°á»ng.
  31.Dá»± Ã¡n cÃ³ sá»­ dá»¥ng Ä‘áº¥t, Ä‘áº¥t cÃ³ máº·t nÆ°á»›c lÃ  dá»± Ã¡n Ä‘Æ°á»£c giao Ä‘áº¥t, cho thuÃª Ä‘áº¥t theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» Ä‘áº¥t Ä‘ai hoáº·c dá»± Ã¡n Ä‘Æ°á»£c triá»ƒn khai trÃªn Ä‘áº¥t, Ä‘áº¥t cÃ³ máº·t nÆ°á»›c theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t cÃ³ liÃªn quan.
  32.BÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng mÃ´i trÆ°á»ng Ä‘Ã£ Ä‘Æ°á»£c phÃª duyá»‡t káº¿t quáº£ tháº©m Ä‘á»‹nh lÃ :
  a) BÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng mÃ´i trÆ°á»ng Ä‘Ã£ Ä‘Æ°á»£c cÆ¡ quan cÃ³ tháº©m quyá»n ra quyáº¿t Ä‘á»‹nh phÃª duyá»‡t káº¿t quáº£ tháº©m Ä‘á»‹nh, trá»« trÆ°á»ng há»£p Ä‘Æ°á»£c quy Ä‘á»‹nh táº¡i Ä‘iá»ƒm b khoáº£n nÃ y;
  b) BÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng mÃ´i trÆ°á»ng Ä‘Ã£ Ä‘Æ°á»£c chá»‰nh sá»­a, bá»• sung theo ná»™i dung, yÃªu cáº§u vá» báº£o vá»‡ mÃ´i trÆ°á»ng Ä‘Æ°á»£c nÃªu trong quyáº¿t Ä‘á»‹nh phÃª duyá»‡t káº¿t quáº£ tháº©m Ä‘á»‹nh bÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng mÃ´i trÆ°á»ng theo quy Ä‘á»‹nh táº¡i khoáº£n 1 Äiá»u 37 Luáº­t Báº£o vá»‡ mÃ´i trÆ°á»ng."""
    },
  {
  "Äiá»u": "Äiá»u 4. Ná»™i dung káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t",
  "ChÆ°Æ¡ng": "ChÆ°Æ¡ng II Báº¢O Vá»† CÃC THÃ€NH PHáº¦N MÃ”I TRÆ¯á»œNG VÃ€ DI Sáº¢N THIÃŠN NHIÃŠN",
  "Má»¥c": "Má»¥c 1 Báº¢O Vá»† MÃ”I TRÆ¯á»œNG NÆ¯á»šC",
  "Pages": "6,7,8,9",
  "Text": """Ná»™i dung chÃ­nh cá»§a káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng nÆ°á»›c máº·t Ä‘Æ°á»£c quy Ä‘á»‹nh táº¡i khoáº£n 2 Äiá»u 9 Luáº­t Báº£o vá»‡ mÃ´i trÆ°á»ng. Má»™t sá»‘ ná»™i dung Ä‘Æ°á»£c quy Ä‘á»‹nh chi tiáº¿t nhÆ° sau:
        1. Vá» Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t; xÃ¡c Ä‘á»‹nh vÃ¹ng báº£o há»™
vá»‡ sinh khu vá»±c láº¥y nÆ°á»›c sinh hoáº¡t, hÃ nh lang báº£o vá»‡ nguá»“n nÆ°á»›c máº·t; xÃ¡c
Ä‘á»‹nh khu vá»±c sinh thá»§y:
a) Hiá»‡n tráº¡ng, diá»…n biáº¿n cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i sÃ´ng,
há»“ giai Ä‘oáº¡n tá»‘i thiá»ƒu 03 nÄƒm gáº§n nháº¥t;
b) Tá»•ng há»£p hiá»‡n tráº¡ng cÃ¡c vÃ¹ng báº£o há»™ vá»‡ sinh khu vá»±c láº¥y nÆ°á»›c sinh
hoáº¡t, hÃ nh lang báº£o vá»‡ nguá»“n nÆ°á»›c máº·t, nguá»“n sinh thá»§y Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh
theo quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» tÃ i nguyÃªn nÆ°á»›c.
2. Vá» loáº¡i vÃ  tá»•ng lÆ°á»£ng cháº¥t Ã´ nhiá»…m tháº£i vÃ o mÃ´i trÆ°á»ng nÆ°á»›c máº·t:
a) Káº¿t quáº£ tá»•ng há»£p, Ä‘Ã¡nh giÃ¡ tá»•ng táº£i lÆ°á»£ng cá»§a tá»«ng cháº¥t Ã´ nhiá»…m
Ä‘Æ°á»£c lá»±a chá»n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng chá»‹u táº£i Ä‘á»‘i vá»›i mÃ´i trÆ°á»ng nÆ°á»›c máº·t tá»«
cÃ¡c nguá»“n Ã´ nhiá»…m Ä‘iá»ƒm, nguá»“n Ã´ nhiá»…m diá»‡n Ä‘Ã£ Ä‘Æ°á»£c Ä‘iá»u tra, Ä‘Ã¡nh giÃ¡ theo
quy Ä‘á»‹nh táº¡i Ä‘iá»ƒm b khoáº£n 2 Äiá»u 9 Luáº­t Báº£o vá»‡ mÃ´i trÆ°á»ng;
b) Dá»± bÃ¡o tÃ¬nh hÃ¬nh phÃ¡t sinh táº£i lÆ°á»£ng Ã´ nhiá»…m tá»« cÃ¡c nguá»“n Ã´ nhiá»…m
Ä‘iá»ƒm, nguá»“n Ã´ nhiá»…m diá»‡n trong thá»i ká»³ cá»§a káº¿ hoáº¡ch.
3. Vá» Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng chá»‹u táº£i, phÃ¢n vÃ¹ng xáº£ tháº£i, háº¡n ngáº¡ch xáº£ nÆ°á»›c
tháº£i:
a) Tá»•ng há»£p káº¿t quáº£ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng chá»‹u táº£i cá»§a mÃ´i trÆ°á»ng nÆ°á»›c máº·t
trÃªn cÆ¡ sá»Ÿ cÃ¡c káº¿t quáº£ Ä‘Ã£ cÃ³ trong vÃ²ng tá»‘i Ä‘a 03 nÄƒm gáº§n nháº¥t vÃ  káº¿t quáº£ Ä‘iá»u
tra, Ä‘Ã¡nh giÃ¡ bá»• sung; xÃ¡c Ä‘á»‹nh lá»™ trÃ¬nh Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng chá»‹u táº£i cá»§a mÃ´i
trÆ°á»ng nÆ°á»›c máº·t trong giai Ä‘oáº¡n thá»±c hiá»‡n káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i
trÆ°á»ng nÆ°á»›c máº·t;
b) PhÃ¢n vÃ¹ng xáº£ tháº£i theo má»¥c Ä‘Ã­ch báº£o vá»‡ vÃ  cáº£i thiá»‡n cháº¥t lÆ°á»£ng mÃ´i
trÆ°á»ng nÆ°á»›c máº·t trÃªn cÆ¡ sá»Ÿ káº¿t quáº£ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng chá»‹u táº£i cá»§a mÃ´i trÆ°á»ng
nÆ°á»›c máº·t vÃ  phÃ¢n vÃ¹ng mÃ´i trÆ°á»ng (náº¿u cÃ³);
c) XÃ¡c Ä‘á»‹nh háº¡n ngáº¡ch xáº£ nÆ°á»›c tháº£i Ä‘á»‘i vá»›i tá»«ng Ä‘oáº¡n sÃ´ng, há»“ trÃªn cÆ¡
sá»Ÿ káº¿t quáº£ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng chá»‹u táº£i cá»§a mÃ´i trÆ°á»ng nÆ°á»›c máº·t vÃ  viá»‡c phÃ¢n
vÃ¹ng xáº£ tháº£i.
4. Dá»± bÃ¡o xu hÆ°á»›ng diá»…n biáº¿n cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t trÃªn cÆ¡
sá»Ÿ cÃ¡c ná»™i dung sau:
a) Dá»± bÃ¡o tÃ¬nh hÃ¬nh phÃ¡t sinh táº£i lÆ°á»£ng Ã´ nhiá»…m tá»« cÃ¡c nguá»“n Ã´ nhiá»…m
Ä‘iá»ƒm, Ã´ nhiá»…m diá»‡n trong giai Ä‘oáº¡n 05 nÄƒm tiáº¿p theo;
b) Káº¿t quáº£ thá»±c hiá»‡n cÃ¡c ná»™i dung quy Ä‘á»‹nh táº¡i cÃ¡c khoáº£n 1, 2 vÃ  3
Äiá»u nÃ y.
5. Vá» cÃ¡c má»¥c tiÃªu, chá»‰ tiÃªu cá»§a káº¿ hoáº¡ch:
a) Má»¥c tiÃªu, chá»‰ tiÃªu vá» cháº¥t lÆ°á»£ng nÆ°á»›c máº·t cáº§n Ä‘áº¡t Ä‘Æ°á»£c cho giai Ä‘oáº¡n
05 nÄƒm Ä‘á»‘i vá»›i tá»«ng Ä‘oáº¡n sÃ´ng, há»“ cÄƒn cá»© nhu cáº§u thá»±c tiá»…n vá» phÃ¡t triá»ƒn kinh
táº¿ - xÃ£ há»™i, báº£o vá»‡ mÃ´i trÆ°á»ng; má»¥c tiÃªu cháº¥t lÆ°á»£ng nÆ°á»›c cá»§a sÃ´ng, há»“ ná»™i tá»‰nh
pháº£i phÃ¹ há»£p vá»›i má»¥c tiÃªu cháº¥t lÆ°á»£ng nÆ°á»›c cá»§a sÃ´ng, há»“ liÃªn tá»‰nh;
b) Má»¥c tiÃªu vÃ  lá»™ trÃ¬nh giáº£m xáº£ tháº£i vÃ o cÃ¡c Ä‘oáº¡n sÃ´ng, há»“ khÃ´ng cÃ²n
kháº£ nÄƒng chá»‹u táº£i nháº±m má»¥c tiÃªu cáº£i thiá»‡n cháº¥t lÆ°á»£ng nÆ°á»›c, cá»¥ thá»ƒ: tá»•ng táº£i
lÆ°á»£ng Ã´ nhiá»…m cáº§n giáº£m Ä‘á»‘i vá»›i tá»«ng thÃ´ng sá»‘ Ã´ nhiá»…m mÃ  mÃ´i trÆ°á»ng nÆ°á»›c
máº·t khÃ´ng cÃ²n kháº£ nÄƒng chá»‹u táº£i; phÃ¢n bá»• táº£i lÆ°á»£ng cáº§n giáº£m theo nhÃ³m
nguá»“n Ã´ nhiá»…m vÃ  lá»™ trÃ¬nh thá»±c hiá»‡n.
6. Vá» biá»‡n phÃ¡p phÃ²ng ngá»«a vÃ  giáº£m thiá»ƒu Ã´ nhiá»…m mÃ´i trÆ°á»ng nÆ°á»›c
máº·t; giáº£i phÃ¡p há»£p tÃ¡c, chia sáº» thÃ´ng tin vÃ  quáº£n lÃ½ Ã´ nhiá»…m nÆ°á»›c máº·t xuyÃªn
biÃªn giá»›i:
a) CÃ¡c biá»‡n phÃ¡p quy Ä‘á»‹nh táº¡i khoáº£n 2 Äiá»u 7 Luáº­t Báº£o vá»‡ mÃ´i trÆ°á»ng
Ä‘á»‘i vá»›i Ä‘oáº¡n sÃ´ng, há»“ khÃ´ng cÃ²n kháº£ nÄƒng chá»‹u táº£i;
b) CÃ¡c biá»‡n phÃ¡p, giáº£i phÃ¡p báº£o vá»‡ cÃ¡c vÃ¹ng báº£o há»™ vá»‡ sinh khu vá»±c láº¥y
nÆ°á»›c sinh hoáº¡t, hÃ nh lang báº£o vá»‡ nguá»“n nÆ°á»›c máº·t, nguá»“n sinh thá»§y theo quy
Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» tÃ i nguyÃªn nÆ°á»›c;
c)13 CÃ¡c biá»‡n phÃ¡p, giáº£i phÃ¡p vá» cÆ¡ cháº¿, chÃ­nh sÃ¡ch Ä‘á»ƒ thá»±c hiá»‡n lá»™ trÃ¬nh
quy Ä‘á»‹nh táº¡i khoáº£n 5 Äiá»u nÃ y;
d) CÃ¡c biá»‡n phÃ¡p, giáº£i phÃ¡p kiá»ƒm soÃ¡t cÃ¡c nguá»“n xáº£ tháº£i vÃ o mÃ´i trÆ°á»ng
nÆ°á»›c máº·t;
Ä‘) Thiáº¿t láº­p há»‡ thá»‘ng quan tráº¯c, cáº£nh bÃ¡o diá»…n biáº¿n cháº¥t lÆ°á»£ng mÃ´i
trÆ°á»ng nÆ°á»›c máº·t, bao gá»“m cáº£ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t xuyÃªn biÃªn
giá»›i, phÃ¹ há»£p vá»›i quy hoáº¡ch tá»•ng thá»ƒ quan tráº¯c mÃ´i trÆ°á»ng quá»‘c gia vÃ  ná»™i
dung quan tráº¯c mÃ´i trÆ°á»ng trong quy hoáº¡ch vÃ¹ng, quy hoáº¡ch tá»‰nh;
e) CÃ¡c biá»‡n phÃ¡p, giáº£i phÃ¡p há»£p tÃ¡c, chia sáº» thÃ´ng tin vá» cháº¥t lÆ°á»£ng mÃ´i
trÆ°á»ng nÆ°á»›c máº·t xuyÃªn biÃªn giá»›i;
g) CÃ¡c biá»‡n phÃ¡p, giáº£i phÃ¡p khÃ¡c.
7. Vá» giáº£i phÃ¡p báº£o vá»‡, cáº£i thiá»‡n cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t:
a) CÃ¡c giáº£i phÃ¡p vá» khoa há»c, cÃ´ng nghá»‡ xá»­ lÃ½, cáº£i thiá»‡n cháº¥t lÆ°á»£ng mÃ´i
trÆ°á»ng nÆ°á»›c máº·t;
b) CÃ¡c giáº£i phÃ¡p vá» cÆ¡ cháº¿, chÃ­nh sÃ¡ch;
c) CÃ¡c giáº£i phÃ¡p vá» tá»• chá»©c, huy Ä‘á»™ng sá»± tham gia cá»§a cÆ¡ quan, tá»•
chá»©c, cá»™ng Ä‘á»“ng;
d) CÃ¡c giáº£i phÃ¡p cÃ´ng trÃ¬nh, phi cÃ´ng trÃ¬nh khÃ¡c.
8. Tá»• chá»©c thá»±c hiá»‡n:
a) PhÃ¢n cÃ´ng trÃ¡ch nhiá»‡m Ä‘á»‘i vá»›i cÆ¡ quan chá»§ trÃ¬ vÃ  cÃ¡c cÆ¡ quan phá»‘i
há»£p thá»±c hiá»‡n káº¿ hoáº¡ch;
b) CÆ¡ cháº¿ giÃ¡m sÃ¡t, bÃ¡o cÃ¡o, Ä‘Ã´n Ä‘á»‘c thá»±c hiá»‡n;
c) Danh má»¥c cÃ¡c dá»± Ã¡n, nhiá»‡m vá»¥ Æ°u tiÃªn Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c má»¥c tiÃªu cá»§a
káº¿ hoáº¡ch;
d) CÆ¡ cháº¿ phÃ¢n bá»• nguá»“n lá»±c thá»±c hiá»‡n.
"""
  },
{ "Äiá»u": "Äiá»u 5. TrÃ¬nh tá»±, thá»§ tá»¥c ban hÃ nh káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t",
  "ChÆ°Æ¡ng": "ChÆ°Æ¡ng II Báº¢O Vá»† CÃC THÃ€NH PHáº¦N MÃ”I TRÆ¯á»œNG VÃ€ DI Sáº¢N THIÃŠN NHIÃŠN",
  "Má»¥c": "Má»¥c 1 Báº¢O Vá»† MÃ”I TRÆ¯á»œNG NÆ¯á»šC",
  "Pages": "9,10",
  "Text": """1. Káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i cÃ¡c sÃ´ng,
há»“ liÃªn tá»‰nh cÃ³ vai trÃ² quan trá»ng vá»›i phÃ¡t triá»ƒn kinh táº¿ - xÃ£ há»™i, báº£o vá»‡ mÃ´i
trÆ°á»ng Ä‘Æ°á»£c ban hÃ nh Ä‘á»‘i vá»›i tá»«ng sÃ´ng, há»“ liÃªn tá»‰nh theo quy Ä‘á»‹nh sau:
a) Bá»™ TÃ i nguyÃªn vÃ  MÃ´i trÆ°á»ng chá»§ trÃ¬, phá»‘i há»£p vá»›i cÃ¡c bá»™, cÆ¡ quan
ngang bá»™, á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh cÃ³ liÃªn quan láº­p, phÃª duyá»‡t, triá»ƒn khai Ä‘á»
Ã¡n Ä‘iá»u tra, Ä‘Ã¡nh giÃ¡, xÃ¢y dá»±ng dá»± tháº£o káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i
trÆ°á»ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i tá»«ng sÃ´ng, há»“ liÃªn tá»‰nh;
b) Bá»™ TÃ i nguyÃªn vÃ  MÃ´i trÆ°á»ng gá»­i dá»± tháº£o káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i tá»«ng sÃ´ng, há»“ liÃªn tá»‰nh Ä‘áº¿n á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh vÃ  cÃ¡c bá»™, cÆ¡ quan ngang bá»™ cÃ³ liÃªn quan Ä‘á»ƒ láº¥y Ã½ kiáº¿n báº±ng vÄƒn báº£n; nghiÃªn cá»©u, tiáº¿p thu, giáº£i trÃ¬nh cÃ¡c Ã½ kiáº¿n gÃ³p Ã½, hoÃ n thiá»‡n dá»± tháº£o káº¿ hoáº¡ch, trÃ¬nh Thá»§ tÆ°á»›ng ChÃ­nh phá»§ xem xÃ©t, ban hÃ nh. Há»“ sÆ¡ trÃ¬nh Thá»§ tÆ°á»›ng
ChÃ­nh phá»§ bao gá»“m: tá» trÃ¬nh; dá»± tháº£o káº¿ hoáº¡ch; dá»± tháº£o quyáº¿t Ä‘á»‹nh ban hÃ nh káº¿ hoáº¡ch; bÃ¡o cÃ¡o giáº£i trÃ¬nh, tiáº¿p thu cÃ¡c Ã½ kiáº¿n gÃ³p Ã½; vÄƒn báº£n gÃ³p Ã½ cá»§a cÃ¡c cÆ¡ quan cÃ³ liÃªn quan;
c) CÄƒn cá»© yÃªu cáº§u quáº£n lÃ½ nhÃ  nÆ°á»›c vÃ  Ä‘á» xuáº¥t cá»§a á»¦y ban nhÃ¢n dÃ¢n
cáº¥p tá»‰nh, Bá»™ TÃ i nguyÃªn vÃ  MÃ´i trÆ°á»ng xem xÃ©t, quyáº¿t Ä‘á»‹nh viá»‡c giao nhiá»‡m
vá»¥ xÃ¢y dá»±ng káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i tá»«ng sÃ´ng, há»“ liÃªn
tá»‰nh cho á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh chá»§ trÃ¬, phá»‘i há»£p vá»›i cÃ¡c Ä‘á»‹a phÆ°Æ¡ng, cÆ¡
quan cÃ³ liÃªn quan thá»±c hiá»‡n.
á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh Ä‘Æ°á»£c giao nhiá»‡m vá»¥ chá»§ trÃ¬ thá»±c hiá»‡n trÃ¡ch
nhiá»‡m cá»§a Bá»™ TÃ i nguyÃªn vÃ  MÃ´i trÆ°á»ng trong viá»‡c xÃ¢y dá»±ng, láº¥y Ã½ kiáº¿n vÃ 
hoÃ n thiá»‡n dá»± tháº£o káº¿ hoáº¡ch theo quy Ä‘á»‹nh táº¡i Ä‘iá»ƒm a vÃ  Ä‘iá»ƒm b khoáº£n nÃ y;
gá»­i há»“ sÆ¡ theo quy Ä‘á»‹nh táº¡i Ä‘iá»ƒm b khoáº£n nÃ y Ä‘áº¿n Bá»™ TÃ i nguyÃªn vÃ  MÃ´i
trÆ°á»ng Ä‘á»ƒ xem xÃ©t, trÃ¬nh Thá»§ tÆ°á»›ng ChÃ­nh phá»§ ban hÃ nh.
2. Káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i sÃ´ng, há»“
ná»™i tá»‰nh cÃ³ vai trÃ² quan trá»ng vá»›i phÃ¡t triá»ƒn kinh táº¿ - xÃ£ há»™i, báº£o vá»‡ mÃ´i
trÆ°á»ng Ä‘Æ°á»£c xÃ¢y dá»±ng chung cho toÃ n bá»™ sÃ´ng, há»“ ná»™i tá»‰nh hoáº·c riÃªng cho
tá»«ng sÃ´ng, há»“ ná»™i tá»‰nh vÃ  theo quy Ä‘á»‹nh sau:
a) CÆ¡ quan chuyÃªn mÃ´n vá» báº£o vá»‡ mÃ´i trÆ°á»ng cáº¥p tá»‰nh chá»§ trÃ¬, phá»‘i há»£p
vá»›i cÃ¡c sá»Ÿ, ban, ngÃ nh, á»¦y ban nhÃ¢n dÃ¢n cáº¥p huyá»‡n cÃ³ liÃªn quan láº­p, phÃª
duyá»‡t vÃ  thá»±c hiá»‡n Ä‘á» Ã¡n Ä‘iá»u tra, Ä‘Ã¡nh giÃ¡, xÃ¢y dá»±ng dá»± tháº£o káº¿ hoáº¡ch quáº£n
lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t sÃ´ng, há»“ ná»™i tá»‰nh;
b) CÆ¡ quan chuyÃªn mÃ´n vá» báº£o vá»‡ mÃ´i trÆ°á»ng cáº¥p tá»‰nh gá»­i dá»± tháº£o káº¿
hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t sÃ´ng, há»“ ná»™i tá»‰nh Ä‘áº¿n cÃ¡c á»¦y
ban nhÃ¢n dÃ¢n cáº¥p huyá»‡n, cÃ¡c sá»Ÿ, ban, ngÃ nh liÃªn quan vÃ  cÆ¡ quan chuyÃªn mÃ´n
vá» báº£o vá»‡ mÃ´i trÆ°á»ng cáº¥p tá»‰nh cá»§a cÃ¡c tá»‰nh, thÃ nh phá»‘ trá»±c thuá»™c trung Æ°Æ¡ng
giÃ¡p ranh Ä‘á»ƒ láº¥y Ã½ kiáº¿n báº±ng vÄƒn báº£n; nghiÃªn cá»©u, tiáº¿p thu, giáº£i trÃ¬nh cÃ¡c Ã½
kiáº¿n gÃ³p Ã½, hoÃ n thiá»‡n dá»± tháº£o káº¿ hoáº¡ch, trÃ¬nh á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh xem
xÃ©t, ban hÃ nh. Há»“ sÆ¡ trÃ¬nh á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh bao gá»“m: tá» trÃ¬nh; dá»±
tháº£o káº¿ hoáº¡ch; dá»± tháº£o quyáº¿t Ä‘á»‹nh ban hÃ nh káº¿ hoáº¡ch; bÃ¡o cÃ¡o giáº£i trÃ¬nh, tiáº¿p
thu cÃ¡c Ã½ kiáº¿n gÃ³p Ã½; vÄƒn báº£n gÃ³p Ã½ cá»§a cÃ¡c cÆ¡ quan cÃ³ liÃªn quan.
3. Viá»‡c xÃ¡c Ä‘á»‹nh sÃ´ng, há»“ cÃ³ vai trÃ² quan trá»ng vá»›i phÃ¡t triá»ƒn kinh táº¿ -
xÃ£ há»™i, báº£o vá»‡ mÃ´i trÆ°á»ng Ä‘Æ°á»£c cÄƒn cá»© vÃ o hiá»‡n tráº¡ng cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng
nÆ°á»›c máº·t, hiá»‡n tráº¡ng nguá»“n tháº£i, nhu cáº§u sá»­ dá»¥ng nguá»“n nÆ°á»›c cho cÃ¡c má»¥c
Ä‘Ã­ch phÃ¡t triá»ƒn kinh táº¿ - xÃ£ há»™i, má»¥c tiÃªu báº£o vá»‡ vÃ  cáº£i thiá»‡n cháº¥t lÆ°á»£ng mÃ´i
trÆ°á»ng nÆ°á»›c máº·t vÃ  cÃ¡c yÃªu cáº§u quáº£n lÃ½ nhÃ  nÆ°á»›c vá» báº£o vá»‡ mÃ´i trÆ°á»ng khÃ¡c.
4. Káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i cÃ¡c sÃ´ng,
há»“ liÃªn tá»‰nh pháº£i phÃ¹ há»£p vá»›i quy hoáº¡ch báº£o vá»‡ mÃ´i trÆ°á»ng quá»‘c gia. TrÆ°á»ng
há»£p quy hoáº¡ch báº£o vá»‡ mÃ´i trÆ°á»ng quá»‘c gia chÆ°a Ä‘Æ°á»£c ban hÃ nh, káº¿ hoáº¡ch
quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i cÃ¡c sÃ´ng, há»“ liÃªn tá»‰nh pháº£i
phÃ¹ há»£p vá»›i yÃªu cáº§u quáº£n lÃ½ nhÃ  nÆ°á»›c vÃ  pháº£i Ä‘Æ°á»£c rÃ  soÃ¡t, cáº­p nháº­t phÃ¹ há»£p
vá»›i quy hoáº¡ch báº£o vá»‡ mÃ´i trÆ°á»ng quá»‘c gia khi Ä‘Æ°á»£c ban hÃ nh.
5. Káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i cÃ¡c sÃ´ng,
há»“ ná»™i tá»‰nh pháº£i phÃ¹ há»£p vá»›i quy hoáº¡ch báº£o vá»‡ mÃ´i trÆ°á»ng quá»‘c gia, ná»™i dung
báº£o vá»‡ mÃ´i trÆ°á»ng trong quy hoáº¡ch vÃ¹ng, quy hoáº¡ch tá»‰nh. TrÆ°á»ng há»£p quy
hoáº¡ch báº£o vá»‡ mÃ´i trÆ°á»ng quá»‘c gia, ná»™i dung báº£o vá»‡ mÃ´i trÆ°á»ng trong quy
hoáº¡ch vÃ¹ng, quy hoáº¡ch tá»‰nh chÆ°a Ä‘Æ°á»£c ban hÃ nh, káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng
mÃ´i trÆ°á»ng nÆ°á»›c máº·t Ä‘á»‘i vá»›i cÃ¡c sÃ´ng, há»“ ná»™i tá»‰nh pháº£i phÃ¹ há»£p vá»›i yÃªu cáº§u
quáº£n lÃ½ nhÃ  nÆ°á»›c vÃ  pháº£i Ä‘Æ°á»£c rÃ  soÃ¡t, cáº­p nháº­t phÃ¹ há»£p vá»›i quy hoáº¡ch báº£o
vá»‡ mÃ´i trÆ°á»ng quá»‘c gia, quy hoáº¡ch vÃ¹ng, quy hoáº¡ch tá»‰nh khi Ä‘Æ°á»£c ban hÃ nh.
6. Káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng nÆ°á»›c máº·t quy Ä‘á»‹nh táº¡i khoáº£n 1
vÃ  khoáº£n 2 Äiá»u nÃ y pháº£i Ä‘Æ°á»£c xÃ¢y dá»±ng phÃ¹ há»£p vá»›i káº¿ hoáº¡ch phÃ¡t triá»ƒn
kinh táº¿ - xÃ£ há»™i 05 nÄƒm. TrÆ°á»›c ngÃ y 30 thÃ¡ng 6 nÄƒm thá»© tÆ° cá»§a káº¿ hoáº¡ch Ä‘áº§u
tÆ° cÃ´ng trung háº¡n giai Ä‘oáº¡n trÆ°á»›c, cÆ¡ quan phÃª duyá»‡t káº¿ hoáº¡ch chá»‰ Ä‘áº¡o tá»•
chá»©c tá»•ng káº¿t, Ä‘Ã¡nh giÃ¡ viá»‡c thá»±c hiá»‡n káº¿ hoáº¡ch ká»³ trÆ°á»›c, xÃ¢y dá»±ng, phÃª duyá»‡t
káº¿ hoáº¡ch cho giai Ä‘oáº¡n tiáº¿p theo Ä‘á»ƒ lÃ m cÆ¡ sá»Ÿ Ä‘á» xuáº¥t káº¿ hoáº¡ch Ä‘áº§u tÆ° cÃ´ng
trung háº¡n."""
},

{ "Äiá»u": "Äiá»u 6. Ná»™i dung káº¿ hoáº¡ch quá»‘c gia vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­",
  "ChÆ°Æ¡ng": "ChÆ°Æ¡ng II Báº¢O Vá»† CÃC THÃ€NH PHáº¦N MÃ”I TRÆ¯á»œNG VÃ€ DI Sáº¢N THIÃŠN NHIÃŠN",
  "Má»¥c": "Má»¥c 2 Báº¢O Vá»† MÃ”I TRÆ¯á»œNG KHÃ”NG KHÃ",
  "Pages": "10,11,12",
  "Text": """Ná»™i dung chÃ­nh cá»§a káº¿ hoáº¡ch quá»‘c gia vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i
trÆ°á»ng khÃ´ng khÃ­ Ä‘Æ°á»£c quy Ä‘á»‹nh táº¡i khoáº£n 3 Äiá»u 13 Luáº­t Báº£o vá»‡ mÃ´i trÆ°á»ng.
Má»™t sá»‘ ná»™i dung Ä‘Æ°á»£c quy Ä‘á»‹nh chi tiáº¿t nhÆ° sau:
1. Vá» Ä‘Ã¡nh giÃ¡ cÃ´ng tÃ¡c quáº£n lÃ½, kiá»ƒm soÃ¡t Ã´ nhiá»…m khÃ´ng khÃ­ cáº¥p quá»‘c
gia; nháº­n Ä‘á»‹nh cÃ¡c nguyÃªn nhÃ¢n chÃ­nh gÃ¢y Ã´ nhiá»…m mÃ´i trÆ°á»ng khÃ´ng khÃ­:
a) Hiá»‡n tráº¡ng, diá»…n biáº¿n cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ quá»‘c gia
trong giai Ä‘oáº¡n tá»‘i thiá»ƒu 03 nÄƒm gáº§n nháº¥t; tá»•ng lÆ°á»£ng phÃ¡t tháº£i gÃ¢y Ã´ nhiá»…m
mÃ´i trÆ°á»ng khÃ´ng khÃ­ vÃ  phÃ¢n bá»‘ phÃ¡t tháº£i theo khÃ´ng gian tá»« cÃ¡c nguá»“n Ã´
nhiá»…m Ä‘iá»ƒm, nguá»“n Ã´ nhiá»…m di Ä‘á»™ng, nguá»“n Ã´ nhiá»…m diá»‡n; áº£nh hÆ°á»Ÿng cá»§a Ã´
nhiá»…m mÃ´i trÆ°á»ng khÃ´ng khÃ­ tá»›i sá»©c khá»e cá»™ng Ä‘á»“ng;
b) Káº¿t quáº£ thá»±c hiá»‡n cÃ¡c chÆ°Æ¡ng trÃ¬nh quan tráº¯c cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng
khÃ´ng khÃ­, cÃ¡c tráº¡m quan tráº¯c tá»± Ä‘á»™ng, liÃªn tá»¥c cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng
khÃ­ vÃ  khÃ­ tháº£i cÃ´ng nghiá»‡p; viá»‡c sá»­ dá»¥ng sá»‘ liá»‡u quan tráº¯c phá»¥c vá»¥ cÃ´ng tÃ¡c
Ä‘Ã¡nh giÃ¡ diá»…n biáº¿n vÃ  quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ trong giai
Ä‘oáº¡n tá»‘i thiá»ƒu 03 nÄƒm gáº§n nháº¥t;
c) Hiá»‡n tráº¡ng cÃ´ng tÃ¡c quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ cáº¥p
quá»‘c gia giai Ä‘oáº¡n tá»‘i thiá»ƒu 03 nÄƒm gáº§n nháº¥t; cÃ¡c váº¥n Ä‘á» báº¥t cáº­p, tá»“n táº¡i trong
cÃ´ng tÃ¡c quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­;
d) Nháº­n Ä‘á»‹nh cÃ¡c nguyÃªn nhÃ¢n chÃ­nh gÃ¢y Ã´ nhiá»…m mÃ´i trÆ°á»ng khÃ´ng khÃ­.
2. Má»¥c tiÃªu quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­:
a) Má»¥c tiÃªu tá»•ng thá»ƒ: tÄƒng cÆ°á»ng hiá»‡u lá»±c, hiá»‡u quáº£ quáº£n lÃ½ cháº¥t lÆ°á»£ng
mÃ´i trÆ°á»ng khÃ´ng khÃ­ phÃ¹ há»£p vá»›i káº¿ hoáº¡ch phÃ¡t triá»ƒn kinh táº¿ - xÃ£ há»™i, báº£o vá»‡
mÃ´i trÆ°á»ng theo ká»³ káº¿ hoáº¡ch;
b) Má»¥c tiÃªu cá»¥ thá»ƒ: Ä‘á»‹nh lÆ°á»£ng cÃ¡c chá»‰ tiÃªu nháº±m giáº£m thiá»ƒu tá»•ng lÆ°á»£ng
khÃ­ tháº£i phÃ¡t sinh tá»« cÃ¡c nguá»“n tháº£i chÃ­nh; cáº£i thiá»‡n cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng
khÃ´ng khÃ­.
3. Nhiá»‡m vá»¥ vÃ  giáº£i phÃ¡p quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­:
a) Vá» cÆ¡ cháº¿, chÃ­nh sÃ¡ch;
b) Vá» khoa há»c, cÃ´ng nghá»‡ nháº±m cáº£i thiá»‡n cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng
khÃ´ng khÃ­;
c) Vá» quáº£n lÃ½, kiá»ƒm soÃ¡t cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­.
4. ChÆ°Æ¡ng trÃ¬nh, dá»± Ã¡n Æ°u tiÃªn Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c nhiá»‡m vá»¥, giáº£i phÃ¡p
quy Ä‘á»‹nh táº¡i khoáº£n 3 Äiá»u nÃ y.
5. Quy cháº¿ phá»‘i há»£p, biá»‡n phÃ¡p quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng
khÃ­ liÃªn vÃ¹ng, liÃªn tá»‰nh pháº£i thá»ƒ hiá»‡n Ä‘áº§y Ä‘á»§ cÃ¡c ná»™i dung, biá»‡n phÃ¡p phá»‘i há»£p
xá»­ lÃ½, quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­; trÃ¡ch nhiá»‡m cá»§a cÃ¡c cÆ¡ quan,
tá»• chá»©c cÃ³ liÃªn quan trong cÃ´ng tÃ¡c quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­
liÃªn vÃ¹ng, liÃªn tá»‰nh, thu tháº­p vÃ  bÃ¡o cÃ¡o, cÃ´ng bá»‘ thÃ´ng tin trong trÆ°á»ng há»£p
cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ bá»‹ Ã´ nhiá»…m.
6. Tá»• chá»©c thá»±c hiá»‡n káº¿ hoáº¡ch quá»‘c gia vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i
trÆ°á»ng khÃ´ng khÃ­, bao gá»“m:
a) PhÃ¢n cÃ´ng trÃ¡ch nhiá»‡m cá»§a cÆ¡ quan chá»§ trÃ¬ vÃ  cÃ¡c cÆ¡ quan phá»‘i há»£p
trong viá»‡c thá»±c hiá»‡n káº¿ hoáº¡ch;
b) CÆ¡ cháº¿ giÃ¡m sÃ¡t, bÃ¡o cÃ¡o, Ä‘Ã´n Ä‘á»‘c thá»±c hiá»‡n;
c) Danh má»¥c cÃ¡c chÆ°Æ¡ng trÃ¬nh, dá»± Ã¡n Æ°u tiÃªn Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c nhiá»‡m
vá»¥, giáº£i phÃ¡p cá»§a káº¿ hoáº¡ch;
d) CÆ¡ cháº¿ phÃ¢n bá»• nguá»“n lá»±c thá»±c hiá»‡n."""
},
 {"Äiá»u": "Äiá»u 7. TrÃ¬nh tá»±, thá»§ tá»¥c ban hÃ nh káº¿ hoáº¡ch quá»‘c gia vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­",
  "ChÆ°Æ¡ng": "ChÆ°Æ¡ng II Báº¢O Vá»† CÃC THÃ€NH PHáº¦N MÃ”I TRÆ¯á»œNG VÃ€ DI Sáº¢N THIÃŠN NHIÃŠN",
  "Má»¥c": "Má»¥c 2 Báº¢O Vá»† MÃ”I TRÆ¯á»œNG KHÃ”NG KHÃ",
  "Pages": "12",
  "Text": """1. Káº¿ hoáº¡ch quá»‘c gia vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ Ä‘Æ°á»£c
ban hÃ nh theo quy Ä‘á»‹nh sau:
a) Bá»™ TÃ i nguyÃªn vÃ  MÃ´i trÆ°á»ng chá»§ trÃ¬, phá»‘i há»£p vá»›i cÃ¡c bá»™, cÆ¡ quan
ngang bá»™, á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh cÃ³ liÃªn quan tá»• chá»©c láº­p, phÃª duyá»‡t, triá»ƒn
khai Ä‘á» Ã¡n Ä‘iá»u tra, Ä‘Ã¡nh giÃ¡, xÃ¢y dá»±ng dá»± tháº£o káº¿ hoáº¡ch quá»‘c gia vá» quáº£n lÃ½
cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­;
b) Bá»™ TÃ i nguyÃªn vÃ  MÃ´i trÆ°á»ng gá»­i dá»± tháº£o káº¿ hoáº¡ch quá»‘c gia vá» quáº£n
lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ Ä‘áº¿n á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh vÃ  cÃ¡c bá»™,
cÆ¡ quan ngang bá»™ cÃ³ liÃªn quan Ä‘á»ƒ láº¥y Ã½ kiáº¿n gÃ³p Ã½ báº±ng vÄƒn báº£n; nghiÃªn cá»©u,
tiáº¿p thu, giáº£i trÃ¬nh cÃ¡c Ã½ kiáº¿n gÃ³p Ã½, hoÃ n thiá»‡n dá»± tháº£o káº¿ hoáº¡ch, trÃ¬nh Thá»§
tÆ°á»›ng ChÃ­nh phá»§ xem xÃ©t, ban hÃ nh. Há»“ sÆ¡ trÃ¬nh Thá»§ tÆ°á»›ng ChÃ­nh phá»§ bao
gá»“m: tá» trÃ¬nh, dá»± tháº£o káº¿ hoáº¡ch, dá»± tháº£o quyáº¿t Ä‘á»‹nh ban hÃ nh káº¿ hoáº¡ch; bÃ¡o
cÃ¡o tá»•ng há»£p, giáº£i trÃ¬nh tiáº¿p thu dá»± tháº£o káº¿ hoáº¡ch; vÄƒn báº£n gÃ³p Ã½ cá»§a cÃ¡c cÆ¡
quan cÃ³ liÃªn quan.
2. Káº¿ hoáº¡ch quá»‘c gia vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ pháº£i
phÃ¹ há»£p vá»›i quy hoáº¡ch báº£o vá»‡ mÃ´i trÆ°á»ng quá»‘c gia. TrÆ°á»ng há»£p quy hoáº¡ch
báº£o vá»‡ mÃ´i trÆ°á»ng quá»‘c gia chÆ°a Ä‘Æ°á»£c ban hÃ nh, káº¿ hoáº¡ch quá»‘c gia vá» quáº£n
lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ pháº£i phÃ¹ há»£p vá»›i yÃªu cáº§u quáº£n lÃ½ nhÃ 
nÆ°á»›c vá» báº£o vá»‡ mÃ´i trÆ°á»ng vÃ  pháº£i Ä‘Æ°á»£c rÃ  soÃ¡t, cáº­p nháº­t phÃ¹ há»£p vá»›i quy
hoáº¡ch báº£o vá»‡ mÃ´i trÆ°á»ng quá»‘c gia khi Ä‘Æ°á»£c ban hÃ nh.
3. Káº¿ hoáº¡ch quá»‘c gia vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ Ä‘Æ°á»£c
xÃ¢y dá»±ng phÃ¹ há»£p vá»›i káº¿ hoáº¡ch phÃ¡t triá»ƒn kinh táº¿ - xÃ£ há»™i 05 nÄƒm. TrÆ°á»›c ngÃ y
30 thÃ¡ng 6 nÄƒm thá»© tÆ° cá»§a káº¿ hoáº¡ch Ä‘áº§u tÆ° cÃ´ng trung háº¡n giai Ä‘oáº¡n trÆ°á»›c, cÆ¡
quan phÃª duyá»‡t káº¿ hoáº¡ch chá»‰ Ä‘áº¡o tá»• chá»©c tá»•ng káº¿t, Ä‘Ã¡nh giÃ¡ viá»‡c thá»±c hiá»‡n káº¿
hoáº¡ch ká»³ trÆ°á»›c, xÃ¢y dá»±ng, phÃª duyá»‡t káº¿ hoáº¡ch cho giai Ä‘oáº¡n tiáº¿p theo Ä‘á»ƒ lÃ m
cÆ¡ sá»Ÿ Ä‘á» xuáº¥t káº¿ hoáº¡ch Ä‘áº§u tÆ° cÃ´ng trung háº¡n."""
},
{"Äiá»u": "Äiá»u 8. Ná»™i dung káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ cáº¥p tá»‰nh",
  "ChÆ°Æ¡ng": "ChÆ°Æ¡ng II Báº¢O Vá»† CÃC THÃ€NH PHáº¦N MÃ”I TRÆ¯á»œNG VÃ€ DI Sáº¢N THIÃŠN NHIÃŠN",
  "Má»¥c": "Má»¥c 2 Báº¢O Vá»† MÃ”I TRÆ¯á»œNG KHÃ”NG KHÃ",
  "Pages": "12,13",
  "Text": """Ná»™i dung chÃ­nh cá»§a káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­
cáº¥p tá»‰nh Ä‘Æ°á»£c quy Ä‘á»‹nh táº¡i khoáº£n 4 Äiá»u 13 Luáº­t Báº£o vá»‡ mÃ´i trÆ°á»ng. Má»™t sá»‘
ná»™i dung Ä‘Æ°á»£c quy Ä‘á»‹nh chi tiáº¿t nhÆ° sau:
1. Vá» Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ á»Ÿ Ä‘á»‹a phÆ°Æ¡ng: hiá»‡n
tráº¡ng cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ khu vá»±c Ä‘Ã´ thá»‹, nÃ´ng thÃ´n vÃ  cÃ¡c khu
vá»±c khÃ¡c.
2. Vá» Ä‘Ã¡nh giÃ¡ cÃ´ng tÃ¡c quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­; quan
tráº¯c mÃ´i trÆ°á»ng khÃ´ng khÃ­; xÃ¡c Ä‘á»‹nh vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c nguá»“n phÃ¡t tháº£i khÃ­ tháº£i
chÃ­nh; kiá»ƒm kÃª phÃ¡t tháº£i; mÃ´ hÃ¬nh hÃ³a cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­; thá»±c
tráº¡ng vÃ  hiá»‡u quáº£ cá»§a cÃ¡c giáº£i phÃ¡p quáº£n lÃ½ cháº¥t lÆ°á»£ng khÃ´ng khÃ­ Ä‘ang thá»±c
hiá»‡n; hiá»‡n tráº¡ng cÃ¡c chÆ°Æ¡ng trÃ¬nh, há»‡ thá»‘ng quan tráº¯c; tá»•ng há»£p, xÃ¡c Ä‘á»‹nh,
Ä‘Ã¡nh giÃ¡ cÃ¡c nguá»“n phÃ¡t tháº£i chÃ­nh (nguá»“n Ã´ nhiá»…m Ä‘iá»ƒm, nguá»“n Ã´ nhiá»…m di
Ä‘á»™ng, nguá»“n Ã´ nhiá»…m diá»‡n); thá»±c hiá»‡n kiá»ƒm kÃª cÃ¡c nguá»“n phÃ¡t tháº£i chÃ­nh vÃ 
mÃ´ hÃ¬nh hÃ³a cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­.
3. PhÃ¢n tÃ­ch, nháº­n Ä‘á»‹nh nguyÃªn nhÃ¢n gÃ¢y Ã´ nhiá»…m mÃ´i trÆ°á»ng khÃ´ng
khÃ­: nguyÃªn nhÃ¢n khÃ¡ch quan tá»« cÃ¡c yáº¿u tá»‘ khÃ­ tÆ°á»£ng, thá»i tiáº¿t, khÃ­ háº­u theo
mÃ¹a, cÃ¡c váº¥n Ä‘á» Ã´ nhiá»…m liÃªn tá»‰nh, xuyÃªn biÃªn giá»›i (náº¿u cÃ³); nguyÃªn nhÃ¢n chá»§
quan tá»« hoáº¡t Ä‘á»™ng phÃ¡t triá»ƒn kinh táº¿ - xÃ£ há»™i lÃ m phÃ¡t sinh cÃ¡c nguá»“n khÃ­ tháº£i
gÃ¢y Ã´ nhiá»…m khÃ´ng khÃ­ (nguá»“n Ã´ nhiá»…m Ä‘iá»ƒm, nguá»“n Ã´ nhiá»…m di Ä‘á»™ng,
nguá»“n Ã´ nhiá»…m diá»‡n).
4 Vá» Ä‘Ã¡nh giÃ¡ áº£nh hÆ°á»Ÿng cá»§a Ã´ nhiá»…m khÃ´ng khÃ­ Ä‘áº¿n sá»©c khá»e cá»™ng Ä‘á»“ng:
thÃ´ng tin, sá»‘ liá»‡u vá» sá»‘ ca bá»‡nh do áº£nh hÆ°á»Ÿng cá»§a Ã´ nhiá»…m khÃ´ng khÃ­ (náº¿u cÃ³); káº¿t
quáº£ Ä‘Ã¡nh giÃ¡ áº£nh hÆ°á»Ÿng cá»§a Ã´ nhiá»…m khÃ´ng khÃ­ tá»›i sá»©c khá»e ngÆ°á»i dÃ¢n táº¡i Ä‘á»‹a
phÆ°Æ¡ng.
5. Má»¥c tiÃªu vÃ  pháº¡m vi quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­: hiá»‡n
tráº¡ng vÃ  diá»…n biáº¿n cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­, hiá»‡n tráº¡ng cÃ´ng tÃ¡c quáº£n
lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ á»Ÿ Ä‘á»‹a phÆ°Æ¡ng.
6. Nhiá»‡m vá»¥ vÃ  giáº£i phÃ¡p quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­:
a) Vá» cÆ¡ cháº¿, chÃ­nh sÃ¡ch;
b) Vá» khoa há»c, cÃ´ng nghá»‡ nháº±m cáº£i thiá»‡n cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng
khÃ´ng khÃ­;
c) Vá» quáº£n lÃ½, kiá»ƒm soÃ¡t cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­.
7. Tá»• chá»©c thá»±c hiá»‡n káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng
khÃ­ cáº¥p tá»‰nh, bao gá»“m:
a) PhÃ¢n cÃ´ng trÃ¡ch nhiá»‡m cá»§a cÆ¡ quan chá»§ trÃ¬ vÃ  cÃ¡c cÆ¡ quan phá»‘i há»£p
trong viá»‡c thá»±c hiá»‡n káº¿ hoáº¡ch;
b) CÆ¡ cháº¿ giÃ¡m sÃ¡t, bÃ¡o cÃ¡o, Ä‘Ã´n Ä‘á»‘c thá»±c hiá»‡n;
c) CÆ¡ cháº¿ phÃ¢n bá»• nguá»“n lá»±c thá»±c hiá»‡n.
8. á»¦y ban nhÃ¢n dÃ¢n cáº¥p tá»‰nh tá»• chá»©c xÃ¢y dá»±ng káº¿ hoáº¡ch quáº£n lÃ½ cháº¥t
lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­ cáº¥p tá»‰nh theo hÆ°á»›ng dáº«n ká»¹ thuáº­t cá»§a Bá»™ TÃ i
nguyÃªn vÃ  MÃ´i trÆ°á»ng."""
    },

    ]
}

import json
import re
from typing import Dict, Any, Optional


def extract_number(prefix: str, text: str) -> Optional[int]:
    """Generic function to extract number or Roman numeral after prefix (e.g., Äiá»u 1, ChÆ°Æ¡ng II, Má»¥c 3)"""
    match = re.search(fr'{prefix}\s+([IVXLCDM\d]+)', text, re.IGNORECASE)
    if not match:
        return None

    value = match.group(1).strip().upper()

    # Roman numeral lookup (extend as needed)
    roman_to_int = {
        'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5,
        'VI': 6, 'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10,
        'XI': 11, 'XII': 12, 'XIII': 13, 'XIV': 14, 'XV': 15,
        'XVI': 16, 'XVII': 17, 'XVIII': 18, 'XIX': 19, 'XX': 20
    }

    # Prioritize Roman numeral check
    if value in roman_to_int:
        return roman_to_int[value]

    # Otherwise, try integer conversion
    if value.isdigit():
        return int(value)

    # Fallback if neither
    return None

def extract_content(prefix: str, text: str) -> str:
    """
    Extract clean content after 'ChÆ°Æ¡ng X' or 'Má»¥c 1' etc.
    Removes the prefix and number even if there is no dot.
    """
    # Remove prefix and number part (e.g., 'ChÆ°Æ¡ng II', 'Má»¥c 1', 'Äiá»u 3')
    content = re.sub(fr'^{prefix}\s+[IVXLCDM\d]+\.?\s*', '', text.strip(), flags=re.IGNORECASE)
    return content.strip()

def transform_data(input_data: Any) -> Dict[str, Any]:
    """Transform JSON data by splitting Äiá»u, ChÆ°Æ¡ng, and Má»¥c"""
    # Handle different input types
    if isinstance(input_data, str):
        try:
            data = json.loads(input_data)
        except json.JSONDecodeError:
            with open(input_data, 'r', encoding='utf-8') as f:
                data = json.load(f)
    else:
        data = input_data

    # Transform the meta array
    if 'meta' in data and isinstance(data['meta'], list):
        transformed_meta = []

        for item in data['meta']:
            transformed_item = {}

            # --- Äiá»u ---
            if 'Äiá»u' in item:
                transformed_item['Äiá»u'] = extract_number('Äiá»u', item['Äiá»u'])
                transformed_item['Äiá»u_Content'] = extract_content('Äiá»u', item['Äiá»u'])

            # --- ChÆ°Æ¡ng ---
            if 'ChÆ°Æ¡ng' in item:
                transformed_item['ChÆ°Æ¡ng'] = extract_number('ChÆ°Æ¡ng', item['ChÆ°Æ¡ng'])
                transformed_item['ChÆ°Æ¡ng_Content'] = extract_content('ChÆ°Æ¡ng', item['ChÆ°Æ¡ng'])

            # --- Má»¥c ---
            if 'Má»¥c' in item:
                transformed_item['Má»¥c'] = extract_number('Má»¥c', item['Má»¥c'])
                transformed_item['Má»¥c_Content'] = extract_content('Má»¥c', item['Má»¥c'])

            # Other fields
            if 'Pages' in item:
                transformed_item['Pages'] = item['Pages']
            if 'Text' in item:
                transformed_item['Text'] = item['Text']

            transformed_meta.append(transformed_item)

        data['meta'] = transformed_meta

    return data


def save_transformed_data(output_path: str, transformed_data: Dict[str, Any], indent: int = 2):
    """Save transformed data to JSON file"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(transformed_data, f, ensure_ascii=False, indent=indent)


# Transform the legal data
print("ğŸ“Š Transforming legal document data...")
transformed_data = transform_data(data)
print(f"âœ… Transformed {len(transformed_data.get('meta', []))} legal articles")

# Example usage (for standalone testing)
# if __name__ == "__main__":
#     print("=== TRANSFORMED JSON ===")
#     print(json.dumps(transformed_data, ensure_ascii=False, indent=2))
#
#     if transformed_data.get('meta'):
#         first = transformed_data['meta'][0]
#         print("\n=== EXAMPLE ACCESS ===")
#         print(f"Äiá»u: {first.get('Äiá»u')} - {first.get('Äiá»u_Content')}")
#         print(f"ChÆ°Æ¡ng: {first.get('ChÆ°Æ¡ng')} - {first.get('ChÆ°Æ¡ng_Content')}")
#         print(f"Má»¥c: {first.get('Má»¥c')} - {first.get('Má»¥c_Content')}")


from langchain_core.documents import Document
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# --- Prompt template ---
query_str = """HÃ£y cung cáº¥p má»™t báº£n tÃ³m táº¯t chi tiáº¿t báº±ng tiáº¿ng Viá»‡t vá» quy Ä‘á»‹nh phÃ¡p luáº­t Viá»‡t Nam nÃ y, bao gá»“m:
- CÃ¡c yÃªu cáº§u hoáº·c quy Ä‘á»‹nh phÃ¡p lÃ½ chÃ­nh Ä‘Æ°á»£c nÃªu ra
- Nhá»¯ng cÃ¡ nhÃ¢n, tá»• chá»©c hoáº·c Ä‘á»‘i tÆ°á»£ng nÃ o chá»‹u sá»± Ä‘iá»u chá»‰nh cá»§a quy Ä‘á»‹nh nÃ y
- CÃ¡c nghÄ©a vá»¥, quyá»n hoáº·c thá»§ tá»¥c quan trá»ng Ä‘Æ°á»£c quy Ä‘á»‹nh
- CÃ¡c Ä‘iá»u kiá»‡n, ngoáº¡i lá»‡ hoáº·c yÃªu cáº§u cá»¥ thá»ƒ Ä‘Ã¡ng chÃº Ã½ (náº¿u cÃ³)
- Má»¥c Ä‘Ã­ch hoáº·c pháº¡m vi tá»•ng thá»ƒ cá»§a quy Ä‘á»‹nh phÃ¡p luáº­t nÃ y

Vui lÃ²ng trÃ¬nh bÃ y báº£n tÃ³m táº¯t thÃ nh 3-4 Ä‘oáº¡n vÄƒn báº±ng tiáº¿ng Viá»‡t, báº£o Ä‘áº£m vá»«a Ä‘áº§y Ä‘á»§ vá»«a dá»… Ä‘á»c.
"""

# --- Convert transformed JSON into Document objects ---
docs = []
for item in transformed_data["meta"]:
    metadata = {
        "Äiá»u": item.get("Äiá»u", ""),
        "Äiá»u_Name": item.get("Äiá»u_Content", ""),
        "ChÆ°Æ¡ng": item.get("ChÆ°Æ¡ng", ""),
        "ChÆ°Æ¡ng_Name": (item.get("ChÆ°Æ¡ng_Content", "")).lower(),
        "Má»¥c": item.get("Má»¥c", ""),
        "Má»¥c_Name": (item.get("Má»¥c_Content", "")).lower(),
        "Pages": item.get("Pages", "")
    }

    doc = Document(
        page_content=item.get("Text", ""),
        metadata=metadata
    )
    docs.append(doc)

# --- Chain definition ---
chain = (
    {"doc": lambda x: x.page_content}
    | ChatPromptTemplate.from_template(f"{query_str}\n\nNá»™i dung vÄƒn báº£n:\n\n{{doc}}")
    | ChatOpenAI(model="gpt-3.5-turbo", temperature=0.4, max_retries=1)
    | StrOutputParser()
)

# --- Batch process documents ---
print("ğŸ“„ Generating document summaries...")
summaries = chain.batch(docs, {"max_concurrency": 5})
print(f"âœ… Generated {len(summaries)} document summaries")

# --- Display results (commented out for cleaner import) ---
# for doc, summary in zip(docs, summaries):
#     print(f"\n{'='*80}")
#     print(f"ChÆ°Æ¡ng: {doc.metadata['ChÆ°Æ¡ng']} - {doc.metadata['ChÆ°Æ¡ng_Name']}")
#     print(f"Má»¥c: {doc.metadata['Má»¥c']} - {doc.metadata['Má»¥c_Name']}")
#     print(f"Äiá»u: {doc.metadata['Äiá»u']} - {doc.metadata['Äiá»u_Name']}")
#     print(f"\nğŸ“˜ TÃ³m táº¯t chi tiáº¿t:\n{summary}")
#     print('='*80)


from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams
import uuid

# --- Step 1: Normalize metadata field names ---
def normalize_metadata(meta: dict):
    rename_map = {
        "ChÆ°Æ¡ng": "Chuong",
        "ChÆ°Æ¡ng_Name": "Chuong_Name",
        "Má»¥c": "Muc",
        "Má»¥c_Name": "Muc_Name",
        "Äiá»u": "Dieu",
        "Äiá»u_Name": "Dieu_Name",
    }
    new_meta = {}
    for k, v in meta.items():
        new_key = rename_map.get(k, k)
        new_meta[new_key] = v
    return new_meta


# --- Step 2: Prepare summarized documents ---
vector_docs = []
for doc, summary in zip(docs, summaries):
    vector_doc = Document(
        page_content=summary,  # DÃ¹ng summary lÃ m ná»™i dung
        metadata=normalize_metadata(doc.metadata)  # âœ… dÃ¹ng metadata Ä‘Ã£ chuáº©n hÃ³a
    )
    vector_docs.append(vector_doc)


# --- Step 3: Initialize LLMs ---
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
llm_creative = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)


# --- Step 4: Initialize embeddings ---
# embeddings = OpenAIEmbeddings()

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# --- Step 5: Create Qdrant vector store (Cloud or Local) ---
if USE_QDRANT_CLOUD and QDRANT_CLOUD_URL and QDRANT_API_KEY:
    # Use Qdrant Cloud for law collection
    print("ğŸ“¡ Using Qdrant Cloud for law collection...")
    vectorstore_fix = QdrantVectorStore.from_existing_collection(
        embedding=embeddings,
        collection_name="law_collection",
        url=QDRANT_CLOUD_URL,
        api_key=QDRANT_API_KEY,
    )
    print("âœ… Connected to law_collection on Qdrant Cloud")
else:
    # Use local/in-memory Qdrant for law collection
    print("ğŸ“ Using local Qdrant for law collection...")
    vectorstore_fix = QdrantVectorStore.from_documents(
        documents=vector_docs,
        embedding=embeddings,
        collection_name="legal_documents",
        location=":memory:"  # In-memory mode (no server needed)
    )
    print("âœ… Qdrant vector store created successfully with", len(vector_docs), "documents.")

from langchain.chains.query_constructor.ir import Comparator, Operator
from langchain.retrievers.self_query.qdrant import QdrantTranslator

# --- MÃ´ táº£ tá»•ng quÃ¡t vá» cáº¥u trÃºc ---
mo_ta_van_ban = """VÄƒn báº£n phÃ¡p luáº­t Viá»‡t Nam cÃ³ cáº¥u trÃºc phÃ¢n cáº¥p:
- ÄIá»€U (Dieu): Quy Ä‘á»‹nh chi tiáº¿t (vÃ­ dá»¥: "Äiá»u 9. Pháº¡m vi Ä‘iá»u chá»‰nh")
- CHÆ¯Æ NG (Chuong): Pháº¡m vi rá»™ng nháº¥t - LUÃ”N dÃ¹ng Sá» LA MÃƒ (vÃ­ dá»¥: "ChÆ°Æ¡ng I", "ChÆ°Æ¡ng II", "ChÆ°Æ¡ng III", "ChÆ°Æ¡ng IV"...)
- Má»¤C (Muc): Chá»§ Ä‘á» cá»¥ thá»ƒ - dÃ¹ng sá»‘ áº¢ Ráº­p (vÃ­ dá»¥: "Má»¥c 1", "Má»¥c 2", "Má»¥c 3"...)

âš ï¸ QUAN TRá»ŒNG - Äá»‹nh dáº¡ng ChÆ°Æ¡ng:
- ChÆ°Æ¡ng LUÃ”N dÃ¹ng Sá» LA MÃƒ: I, II, III, IV, V, VI, VII, VIII, IX, X, XI, XII, XIII
- VÃ Dá»¤ CHUYá»‚N Äá»”I:
  * "chÆ°Æ¡ng 1" hoáº·c "ChÆ°Æ¡ng 1" â†’ "ChÆ°Æ¡ng I"
  * "chÆ°Æ¡ng 2" hoáº·c "ChÆ°Æ¡ng 2" â†’ "ChÆ°Æ¡ng II"
  * "chÆ°Æ¡ng 3" hoáº·c "ChÆ°Æ¡ng 3" â†’ "ChÆ°Æ¡ng III"
  * "chÆ°Æ¡ng 10" hoáº·c "ChÆ°Æ¡ng 10" â†’ "ChÆ°Æ¡ng X"
- Viáº¿t hoa chá»¯ 'C': "ChÆ°Æ¡ng" (KHÃ”NG pháº£i "chÆ°Æ¡ng")

Khi tÃ¬m kiáº¿m:
- Sá» ÄIá»€U (vÃ­ dá»¥: "Äiá»u 9") â†’ dÃ¹ng Dieu_Number vá»›i eq: eq("Dieu_Number", 9)
- CHÆ¯Æ NG (vÃ­ dá»¥: "chÆ°Æ¡ng 2", "ChÆ°Æ¡ng II") â†’ chuyá»ƒn sang Sá» LA MÃƒ VÃ€ viáº¿t hoa, dÃ¹ng LIKE: like("Chuong", "ChÆ°Æ¡ng II")
- Má»¤C (vÃ­ dá»¥: "má»¥c 2", "Má»¥c 2") â†’ viáº¿t hoa chá»¯ 'M', dÃ¹ng LIKE: like("Muc", "Má»¥c 2")
- Káº¿t há»£p Má»¤C vÃ  CHÆ¯Æ NG â†’ dÃ¹ng AND: and(like("Muc", "Má»¥c 2"), like("Chuong", "ChÆ°Æ¡ng II"))
"""

metadata_fields = [
    AttributeInfo(
        name="Dieu_Number",
        description="Sá»‘ Ä‘iá»u (integer, vÃ­ dá»¥: 9 cho Äiá»u 9)",
        type="integer",
    ),
    AttributeInfo(
        name="Dieu",
        description="TÃªn Ä‘áº§y Ä‘á»§ cá»§a Ä‘iá»u (vÃ­ dá»¥: 'Äiá»u 9. Pháº¡m vi Ä‘iá»u chá»‰nh')",
        type="string",
    ),
    AttributeInfo(
        name="Chuong",
        description="TÃªn chÆ°Æ¡ng (vÃ­ dá»¥: 'ChÆ°Æ¡ng I. NHá»®NG QUY Äá»ŠNH CHUNG')",
        type="string",
    ),
    AttributeInfo(
        name="Muc",
        description="TÃªn má»¥c (vÃ­ dá»¥: 'Má»¥c 1 Báº¢O Vá»† MÃ”I TRÆ¯á»œNG NÆ¯á»šC')",
        type="string",
    ),
]

# --- Khá»Ÿi táº¡o LLM ---
llm_query = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# --- Táº¡o prompt constructor vá»›i allowed_operators ---
prompt_truy_van_phap_luat = get_query_constructor_prompt(
    mo_ta_van_ban,
    metadata_fields,
    allowed_comparators=[
        Comparator.EQ,
        Comparator.LT,
        Comparator.LTE,
        Comparator.GT,
        Comparator.GTE,
        Comparator.LIKE,
    ],
    allowed_operators=[Operator.AND, Operator.OR],  # Enable AND and OR
    examples=[
        # TÃ¬m theo sá»‘ Ä‘iá»u
        ("Äiá»u 6 quy Ä‘á»‹nh gÃ¬?", {"query": "ná»™i dung Ä‘iá»u 6", "filter": 'eq("Dieu_Number", 6)'}),
        ("Cho tÃ´i há»i vá» Äiá»u 9?", {"query": "vá» Ä‘iá»u 9", "filter": 'eq("Dieu_Number", 9)'}),

        # TÃ¬m theo chÆ°Æ¡ng (chuyá»ƒn Ä‘á»•i sang sá»‘ La MÃ£)
        ("ChÆ°Æ¡ng 1 quy Ä‘á»‹nh gÃ¬?", {"query": "chÆ°Æ¡ng 1", "filter": 'like("Chuong", "ChÆ°Æ¡ng I")'}),
        ("ChÆ°Æ¡ng 2 quy Ä‘á»‹nh gÃ¬?", {"query": "chÆ°Æ¡ng 2", "filter": 'like("Chuong", "ChÆ°Æ¡ng II")'}),
        ("chÆ°Æ¡ng II quy Ä‘á»‹nh gÃ¬?", {"query": "chÆ°Æ¡ng II", "filter": 'like("Chuong", "ChÆ°Æ¡ng II")'}),
        ("ChÆ°Æ¡ng III vá» gÃ¬?", {"query": "chÆ°Æ¡ng III", "filter": 'like("Chuong", "ChÆ°Æ¡ng III")'}),

        # TÃ¬m theo má»¥c (viáº¿t hoa chá»¯ M)
        ("má»¥c 1 vá» gÃ¬?", {"query": "má»¥c 1", "filter": 'like("Muc", "Má»¥c 1")'}),
        ("Má»¥c 2 vá» gÃ¬?", {"query": "má»¥c 2", "filter": 'like("Muc", "Má»¥c 2")'}),

        # Káº¿t há»£p má»¥c vÃ  chÆ°Æ¡ng (chuyá»ƒn Ä‘á»•i sá»‘ sang La MÃ£, viáº¿t hoa)
        ("Má»¥c 2 cá»§a chÆ°Æ¡ng 2 quy Ä‘á»‹nh gÃ¬?", {"query": "má»¥c 2 chÆ°Æ¡ng 2", "filter": 'and(like("Muc", "Má»¥c 2"), like("Chuong", "ChÆ°Æ¡ng II"))'}),
        ("Cho tÃ´i há»i vá» Má»¥c 1 cá»§a chÆ°Æ¡ng 1?", {"query": "má»¥c 1 chÆ°Æ¡ng 1", "filter": 'and(like("Muc", "Má»¥c 1"), like("Chuong", "ChÆ°Æ¡ng I"))'}),
        ("Má»¥c 3 ChÆ°Æ¡ng IV quy Ä‘á»‹nh gÃ¬?", {"query": "má»¥c 3 chÆ°Æ¡ng IV", "filter": 'and(like("Muc", "Má»¥c 3"), like("Chuong", "ChÆ°Æ¡ng IV"))'}),

        # TÃ¬m theo ná»™i dung
        ("Quy Ä‘á»‹nh vá» mÃ´i trÆ°á»ng khÃ´ng khÃ­", {"query": "mÃ´i trÆ°á»ng khÃ´ng khÃ­", "filter": 'like("Dieu", "mÃ´i trÆ°á»ng khÃ´ng khÃ­")'}),
        ("ChÆ°Æ¡ng nÃ o vá» báº£o vá»‡ mÃ´i trÆ°á»ng", {"query": "báº£o vá»‡ mÃ´i trÆ°á»ng", "filter": 'like("Chuong", "báº£o vá»‡ mÃ´i trÆ°á»ng")'}),

        # Nhiá»u Ä‘iá»u
        ("Äiá»u 5 hoáº·c Äiá»u 6", {"query": "Ä‘iá»u 5 Ä‘iá»u 6", "filter": 'or(eq("Dieu_Number", 5), eq("Dieu_Number", 6))'}),

        # KhÃ´ng cÃ³ filter cá»¥ thá»ƒ
        ("TrÃ¡ch nhiá»‡m cá»§a tá»• chá»©c sáº£n xuáº¥t", {"query": "trÃ¡ch nhiá»‡m tá»• chá»©c sáº£n xuáº¥t", "filter": None}),
    ],
)

# --- Khá»Ÿi táº¡o parser ---
parser_phap_luat = StructuredQueryOutputParser.from_components(
    allowed_comparators=[
        Comparator.EQ,
        Comparator.LT,
        Comparator.LTE,
        Comparator.GT,
        Comparator.GTE,
        Comparator.LIKE,
    ],
    allowed_operators=[Operator.AND, Operator.OR],  # Enable AND and OR
)

# --- Káº¿t há»£p prompt vÃ  LLM ---
llm_constructor_phap_luat = prompt_truy_van_phap_luat | llm_query | parser_phap_luat

# --- Táº¡o SelfQueryRetriever ---
retriever_phap_luat = SelfQueryRetriever(
    query_constructor=llm_constructor_phap_luat,
    vectorstore=vectorstore_fix,
    structured_query_translator=QdrantTranslator(metadata_key="metadata"),
    verbose=True,
    search_kwargs={"k": 5}
)

print("âœ… SelfQueryRetriever Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng!")

from langchain.retrievers.self_query.qdrant import QdrantTranslator
from qdrant_client.models import Filter

class FallbackLegalRetriever:
    """
    Retriever with fallback: if filtered search returns nothing, try without filter
    """

    def __init__(self, vectorstore, query_constructor, k=5):
        self.vectorstore = vectorstore
        self.query_constructor = query_constructor
        self.k = k
        # âœ… Create translator to convert LangChain filters to Qdrant format
        self.translator = QdrantTranslator(metadata_key="metadata")

    def invoke(self, query: str):
        """Get documents with fallback strategy"""
        print(f"\n{'='*80}")
        print(f"ğŸ” FALLBACK RETRIEVER")
        print(f"{'='*80}")
        print(f"Query: {query}")

        # Step 1: Construct structured query
        structured_query = self.query_constructor.invoke({"query": query})

        print(f"Structured query:")
        print(f"  Query: {structured_query.query}")
        print(f"  Filter: {structured_query.filter}")

        # Step 2: Try with filter first
        if structured_query.filter:
            print(f"\nğŸ” Searching WITH filter...")

            # âœ… Translate LangChain filter to Qdrant filter
            try:
                result = self.translator.visit_structured_query(structured_query)

                # Extract filter from the result (it returns a tuple/dict)
                if isinstance(result, tuple):
                    # Result is (query, filter_dict)
                    _, filter_dict = result
                    qdrant_filter = filter_dict.get('filter') if isinstance(filter_dict, dict) else filter_dict
                elif isinstance(result, dict):
                    # Result is {'filter': Filter(...)}
                    qdrant_filter = result.get('filter', result)
                else:
                    # Result is directly the filter
                    qdrant_filter = result

                print(f"   Using Qdrant filter: {qdrant_filter}")

                docs = self.vectorstore.similarity_search(
                    structured_query.query,
                    k=self.k,
                    filter=qdrant_filter  # âœ… Use translated filter
                )

                if docs:
                    print(f"âœ… Found {len(docs)} documents with filter")
                    print(f"{'='*80}\n")
                    return docs
                else:
                    print(f"âš ï¸  No results with filter, trying without filter...")
            except Exception as e:
                print(f"âš ï¸  Error with filter: {e}")
                print(f"   Trying without filter...")

        # Step 3: Fallback to search without filter
        print(f"\nğŸ” Searching WITHOUT filter...")
        docs = self.vectorstore.similarity_search(
            structured_query.query,
            k=self.k
        )

        print(f"âœ… Found {len(docs)} documents without filter")
        print(f"{'='*80}\n")

        return docs


# âœ… Create fallback retriever
fallback_retriever = FallbackLegalRetriever(
    vectorstore=vectorstore_fix,
    query_constructor=llm_constructor_phap_luat,
    k=5
)

print("âœ… Fallback retriever created!")

# Test (commented out for module import)
# query = "NÃ³i rÃµ cÃ¡c Ä‘iá»u vá» tÃ¡i cháº¿ trong Luáº­t Báº£o vá»‡ mÃ´i trÆ°á»ng ra?"
# results = fallback_retriever.invoke(query)
# print(f"\nğŸ“Š RESULTS: {len(results)} documents")
# for i, doc in enumerate(results, 1):
#     print(f"\n{i}. Äiá»u {doc.metadata.get('Dieu')}: {doc.metadata.get('Dieu_Name')}")
#     print(f"   Content: {doc.page_content[:100]}...")


from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate

# Data model
class GradeDocuments(BaseModel):
    """ÄÃ¡nh giÃ¡ nhá»‹ phÃ¢n vá» má»©c Ä‘á»™ liÃªn quan cá»§a tÃ i liá»‡u Ä‘Ã£ truy xuáº¥t."""

    binary_score: str = Field(
        description="TÃ i liá»‡u cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i hay khÃ´ng, 'cÃ³' hoáº·c 'khÃ´ng'"
    )

# LLM with function call
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
structured_llm_grader = llm.with_structured_output(GradeDocuments)

# Enhanced Prompt
system = """Báº¡n lÃ  bá»™ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ liÃªn quan cá»§a tÃ i liá»‡u Ä‘Æ°á»£c truy xuáº¥t Ä‘á»‘i vá»›i cÃ¢u há»i ngÆ°á»i dÃ¹ng.

ğŸ¯ Má»¤C TIÃŠU:
XÃ¡c Ä‘á»‹nh xem tÃ i liá»‡u cÃ³ thá»ƒ GIÃšP TRáº¢ Lá»œI cÃ¢u há»i hay khÃ´ng (ká»ƒ cáº£ khi cÃ¢u tráº£ lá»i lÃ  "KHÃ”NG").

ğŸ“‹ QUY Táº®C ÄÃNH GIÃ:

âœ… ÄÃNH GIÃ "CÃ“" (tÃ i liá»‡u LIÃŠN QUAN) KHI:

1. **CÃ¢u há»i vá» Äiá»u/ChÆ°Æ¡ng/Má»¥c cá»¥ thá»ƒ**
   - CÃ¢u há»i: "Äiá»u 7 cÃ³ nÃ³i vá» X khÃ´ng?"
   - TÃ i liá»‡u: Chá»©a thÃ´ng tin vá» Äiá»u 7
   - â†’ "CÃ“" (dÃ¹ tÃ i liá»‡u khÃ´ng nháº¯c Ä‘áº¿n X, vÃ¬ cÃ³ thá»ƒ tráº£ lá»i "KHÃ”NG")

2. **CÃ¢u há»i vá» chá»§ Ä‘á»**
   - CÃ¢u há»i: "Quy Ä‘á»‹nh vá» tÃ¡i cháº¿ lÃ  gÃ¬?"
   - TÃ i liá»‡u: Chá»©a thÃ´ng tin vá» tÃ¡i cháº¿
   - â†’ "CÃ“"

3. **Tá»« khÃ³a hoáº·c ngá»¯ nghÄ©a liÃªn quan**
   - CÃ¢u há»i: "TrÃ¡ch nhiá»‡m cá»§a nhÃ  sáº£n xuáº¥t?"
   - TÃ i liá»‡u: NÃ³i vá» trÃ¡ch nhiá»‡m sáº£n xuáº¥t, EPR
   - â†’ "CÃ“"

âŒ ÄÃNH GIÃ "KHÃ”NG" (tÃ i liá»‡u KHÃ”NG LIÃŠN QUAN) CHá»ˆ KHI:

1. **Sai hoÃ n toÃ n Äiá»u/ChÆ°Æ¡ng/Má»¥c**
   - CÃ¢u há»i: "Äiá»u 7 nÃ³i gÃ¬?"
   - TÃ i liá»‡u: Chá»‰ vá» Äiá»u 99
   - â†’ "KHÃ”NG"

2. **Chá»§ Ä‘á» hoÃ n toÃ n khÃ¡c**
   - CÃ¢u há»i: "Quy Ä‘á»‹nh vá» tÃ¡i cháº¿?"
   - TÃ i liá»‡u: Chá»‰ vá» xÃ¢y dá»±ng, y táº¿, khÃ´ng liÃªn quan mÃ´i trÆ°á»ng
   - â†’ "KHÃ”NG"

ğŸ” TRÆ¯á»œNG Há»¢P Äáº¶C BIá»†T:

**CÃ¢u há»i dáº¡ng "Äiá»u X cÃ³ nÃ³i vá» Y khÃ´ng?"**
- Náº¿u tÃ i liá»‡u CÃ“ Äiá»u X â†’ "CÃ“" (vÃ¬ cÃ³ thá»ƒ tráº£ lá»i "cÃ³" hoáº·c "khÃ´ng")
- Náº¿u tÃ i liá»‡u KHÃ”NG CÃ“ Äiá»u X â†’ "KHÃ”NG"

VÃ Dá»¤:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

CÃ¢u há»i: "Äiá»u 7 cÃ³ nÃ³i vá» lá»‘p xe khÃ´ng?"
TÃ i liá»‡u: [Metadata: Äiá»u 7, Ná»™i dung: Quy Ä‘á»‹nh vá» cháº¥t lÆ°á»£ng khÃ´ng khÃ­...]
â†’ "CÃ“" âœ… (VÃ¬ cÃ³ Äiá»u 7, cÃ³ thá»ƒ tráº£ lá»i "KHÃ”NG, Äiá»u 7 khÃ´ng nÃ³i vá» lá»‘p xe")

CÃ¢u há»i: "Äiá»u 7 cÃ³ nÃ³i vá» lá»‘p xe khÃ´ng?"
TÃ i liá»‡u: [Metadata: Äiá»u 99, Ná»™i dung: Quy Ä‘á»‹nh vá»...]
â†’ "KHÃ”NG" âŒ (VÃ¬ tÃ i liá»‡u khÃ´ng pháº£i Äiá»u 7)

CÃ¢u há»i: "Quy Ä‘á»‹nh vá» tÃ¡i cháº¿?"
TÃ i liá»‡u: [Ná»™i dung: TrÃ¡ch nhiá»‡m tÃ¡i cháº¿ sáº£n pháº©m...]
â†’ "CÃ“" âœ…

CÃ¢u há»i: "Quy Ä‘á»‹nh vá» tÃ¡i cháº¿?"
TÃ i liá»‡u: [Ná»™i dung: Quy Ä‘á»‹nh vá» xÃ¢y dá»±ng nhÃ  á»Ÿ...]
â†’ "KHÃ”NG" âŒ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš–ï¸ NGUYÃŠN Táº®C:
Má»¥c tiÃªu lÃ  GIá»® Láº I tÃ i liá»‡u cÃ³ thá»ƒ giÃºp tráº£ lá»i (ká»ƒ cáº£ tráº£ lá»i "khÃ´ng").
Chá»‰ loáº¡i bá» tÃ i liá»‡u HOÃ€N TOÃ€N KHÃ”NG LIÃŠN QUAN.

HÃ£y Ä‘Æ°a ra Ä‘iá»ƒm nhá»‹ phÃ¢n: 'cÃ³' hoáº·c 'khÃ´ng'"""

grade_prompt = ChatPromptTemplate.from_messages([
    ("system", system),
    ("human", """TÃ i liá»‡u Ä‘Ã£ truy xuáº¥t:
{document}

CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng:
{question}

TÃ i liá»‡u nÃ y cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i khÃ´ng? ('cÃ³' hoáº·c 'khÃ´ng')"""),
])

retrieval_grader = grade_prompt | structured_llm_grader



def grade_documents(state):
    """
    XÃ¡c Ä‘á»‹nh xem cÃ¡c tÃ i liá»‡u Ä‘Ã£ truy xuáº¥t cÃ³ liÃªn quan Ä‘áº¿n cÃ¢u há»i hay khÃ´ng.

    Args:
        state (dict): Tráº¡ng thÃ¡i hiá»‡n táº¡i cá»§a Ä‘á»“ thá»‹

    Returns:
        state (dict): Cáº­p nháº­t khÃ³a documents chá»‰ vá»›i cÃ¡c tÃ i liá»‡u liÃªn quan Ä‘Ã£ Ä‘Æ°á»£c lá»c
    """

    print("---CHECK DOCUMENT RELEVANCE TO QUESTION---")
    question = state["question"]
    documents = state["documents"]

    # Score each doc
    filtered_docs = []
    for d in documents:
        # Combine metadata with content
        doc_txt_with_metadata = f"""
Metadata:
- Äiá»u {d.metadata.get('Dieu', 'N/A')}: {d.metadata.get('Dieu_Name', '')}
- ChÆ°Æ¡ng {d.metadata.get('Chuong', 'N/A')}: {d.metadata.get('Chuong_Name', '')}
- Má»¥c {d.metadata.get('Muc', 'N/A')}: {d.metadata.get('Muc_Name', '')}

Ná»™i dung:
{d.page_content}
"""

        score = retrieval_grader.invoke({"question": question, "document": doc_txt_with_metadata})
        grade = score.binary_score
        if grade == "cÃ³":
            print("---GRADE: DOCUMENT RELEVANT---")
            filtered_docs.append(d)
        else:
            print("---GRADE: DOCUMENT NOT RELEVANT---")
            continue

    return {"documents": filtered_docs, "question": question}

# ========== ROUTE QUERY MODEL FOR LEGAL DOCUMENTS ==========
class LegalRouteQuery(BaseModel):
    """PhÃ¢n loáº¡i cÃ¢u há»i ngÆ°á»i dÃ¹ng tá»›i nguá»“n dá»¯ liá»‡u phÃ¹ há»£p"""
    datasource: Literal["vectorstore","chitchat"] = Field(
        ...,
        description="vectorstore (vÄƒn báº£n phÃ¡p luáº­t), chitchat (giao tiáº¿p thÃ¢n thiá»‡n)"
    )

# ========== INITIALIZE LLM ROUTER ==========
llm_router = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
structured_llm_router = llm_router.with_structured_output(LegalRouteQuery)

# ========== SYSTEM PROMPT ==========
router_system = """Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n loáº¡i cÃ¢u há»i ngÆ°á»i dÃ¹ng tá»›i nguá»“n dá»¯ liá»‡u phÃ¹ há»£p.

Báº¡n cÃ³ quyá»n truy cáº­p 2 nguá»“n:
1. **vectorstore** - VÄƒn báº£n phÃ¡p luáº­t Viá»‡t Nam (luáº­t, nghá»‹ Ä‘á»‹nh, Ä‘iá»u khoáº£n)
q. **chitchat** - Giao tiáº¿p thÃ¢n thiá»‡n, há»i thÄƒm, cáº£m Æ¡n, chÃ o há»i

## QUY Táº®C Æ¯U TIÃŠN QUAN TRá»ŒNG (kiá»ƒm tra theo thá»© tá»±):

### 1. Chuyá»ƒn tá»›i **chitchat** náº¿u:
- Lá»i chÃ o: "Xin chÃ o", "ChÃ o báº¡n", "Hi", "Good morning"
- Giá»›i thiá»‡u: "TÃ´i tÃªn lÃ ...", "MÃ¬nh lÃ ..."
- Cáº£m Æ¡n: "Cáº£m Æ¡n", "Thanks"
- Táº¡m biá»‡t: "Táº¡m biá»‡t", "Bye", "Goodbye"
- Há»i thÄƒm / nÃ³i chuyá»‡n thÃ¢n thiá»‡n: "Báº¡n cÃ³ khá»e khÃ´ng?", "HÃ´m nay tháº¿ nÃ o?"
- CÃ¡c cÃ¢u há»i vá» trá»£ lÃ½: "Báº¡n nhá»› tÃ´i khÃ´ng?", "TÃªn tÃ´i lÃ  gÃ¬?"
- **LÆ°u Ã½:** Náº¿u cÃ¢u báº¯t Ä‘áº§u báº±ng lá»i chÃ o, luÃ´n lÃ  chitchat, ngay cáº£ khi cÃ³ nháº¯c Ä‘áº¿n luáº­t.

### 2. Chuyá»ƒn tá»›i **vectorstore** náº¿u khÃ´ng pháº£i chitchat vÃ :
- Há»i vá» luáº­t / Ä‘iá»u khoáº£n cá»¥ thá»ƒ: "Äiá»u kiá»‡n cáº¥p giáº¥y phÃ©p mÃ´i trÆ°á»ng", "Quyá»n vÃ  nghÄ©a vá»¥ cá»§a tá»• chá»©c sáº£n xuáº¥t"
- Tra cá»©u ná»™i dung Äiá»u / Má»¥c / ChÆ°Æ¡ng
- So sÃ¡nh quy Ä‘á»‹nh: "So sÃ¡nh Äiá»u 5 vÃ  Äiá»u 6 cá»§a Luáº­t BVMT"
- Pháº¡m vi Ã¡p dá»¥ng: "Pháº¡m vi Ã¡p dá»¥ng cá»§a Luáº­t BVMT lÃ  gÃ¬?"
- YÃªu cáº§u tÃ³m táº¯t hoáº·c giáº£i thÃ­ch vÄƒn báº£n phÃ¡p luáº­t


## VÃ­ dá»¥:

"Xin chÃ o! TÃ´i muá»‘n há»i vá» luáº­t mÃ´i trÆ°á»ng" â†’ **chitchat** (lá»i chÃ o + cÃ¢u há»i)
"Cáº£m Æ¡n báº¡n Ä‘Ã£ giÃºp tÃ´i!" â†’ **chitchat**
"Äiá»u kiá»‡n cáº¥p giáº¥y phÃ©p mÃ´i trÆ°á»ng lÃ  gÃ¬?" â†’ **vectorstore**
"Quyá»n vÃ  nghÄ©a vá»¥ cá»§a doanh nghiá»‡p vá» cháº¥t tháº£i?" â†’ **vectorstore**



## CÃ¢u há»i hiá»‡n táº¡i:
{question}

PhÃ¢n loáº¡i cÃ¢u há»i dá»±a trÃªn quy táº¯c Æ°u tiÃªn trÃªn."""

# ========== CREATE ROUTER PROMPT ==========
route_prompt = ChatPromptTemplate.from_messages([
    ("system", router_system),
    ("human", "{question}")
])

# ========== COMBINE PROMPT WITH STRUCTURED LLM ==========
question_router = route_prompt | structured_llm_router

print("âœ“ Legal question router created successfully!")

def route_question_law(state):
    """PhÃ¢n luá»“ng cÃ¢u há»i vá»›i xá»­ lÃ½ ngá»¯ cáº£nh cáº£i tiáº¿n"""
    print("---PHÃ‚N LUá»’NG CÃ‚U Há»I (Vá»šI NGá»® Cáº¢NH)---")

    question = state["question"]
    # Láº¥y lá»‹ch sá»­ há»™i thoáº¡i Ä‘áº§y Ä‘á»§
    chat_history = get_full_chat_history()  # hÃ m báº¡n Ä‘Ã£ Ä‘á»‹nh nghÄ©a Ä‘á»ƒ load memory

    print(f"Lá»‹ch sá»­ há»™i thoáº¡i:\n{chat_history}\n")
    print(f"CÃ¢u há»i hiá»‡n táº¡i: {question}")

    # Gá»i LLM router Ä‘á»ƒ quyáº¿t Ä‘á»‹nh nguá»“n dá»¯ liá»‡u
    source = question_router.invoke({
        "question": question,
        "chat_history": chat_history
    })

    # Láº¥y datasource
    if isinstance(source, dict):
        datasource = source.get("datasource")
    else:
        datasource = getattr(source, "datasource", None)

    print(f"---PHÃ‚N LUá»’NG Tá»šI: {datasource.upper() if datasource else 'UNKNOWN'}---")

    # Map datasource sang cÃ¡c hÃ m cá»§a pipeline phÃ¡p luáº­t
    if datasource == 'vectorstore':
        return "vectorstore"  # Truy xuáº¥t Äiá»u â€“ Má»¥c â€“ ChÆ°Æ¡ng
    # elif datasource == 'websearch':
    #     return "websearch"  # TÃ¬m kiáº¿m trÃªn web phÃ¡p luáº­t
    elif datasource == 'chitchat':
        return "chitchat"  # TrÃ² chuyá»‡n thÃ¢n thiá»‡n"

def retrieve(state):
    print("---RETRIEVING LAW---")

    question = state["question"]
    original_question = state.get("original_question", question)

    try:
        # documents = retriever_phap_luat.invoke(question)
        documents = fallback_retriever.invoke(question)
    except Exception as e:
        print(f"  âš ï¸ Lá»—i khi retrieve vá»›i filter: {e}")
        print(f"  ğŸ”„ Fallback: semantic search khÃ´ng filter")

        # Fallback to simple semantic search
        documents = vectorstore_fix.similarity_search(question, k=5)

    print(f"  ğŸ“Š TÃ¬m tháº¥y {len(documents)} tÃ i liá»‡u")

    if documents:
        for i, doc in enumerate(documents, 1):
            print(f"  ğŸ“„ Doc {i}: {doc.page_content[:150]}...")

    return {
        **state,
        "documents": documents,
        "original_question": original_question
    }

### Generate

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

# Custom detailed prompt for Vietnamese legal RAG
prompt_template = """Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» phÃ¡p luáº­t EPR (Extended Producer Responsibility - TrÃ¡ch nhiá»‡m má»Ÿ rá»™ng cá»§a nhÃ  sáº£n xuáº¥t) táº¡i Viá»‡t Nam.

NHIá»†M Vá»¤ Cá»¦A Báº N:
1. Tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng dá»±a HOÃ€N TOÃ€N trÃªn cÃ¡c vÄƒn báº£n phÃ¡p luáº­t Ä‘Æ°á»£c cung cáº¥p bÃªn dÆ°á»›i
2. TrÃ­ch dáº«n cá»¥ thá»ƒ sá»‘ Äiá»u, ChÆ°Æ¡ng, Má»¥c khi tráº£ lá»i
3. Giáº£i thÃ­ch rÃµ rÃ ng, dá»… hiá»ƒu báº±ng tiáº¿ng Viá»‡t
4. Náº¿u thÃ´ng tin khÃ´ng cÃ³ trong tÃ i liá»‡u, hÃ£y nÃ³i rÃµ "ThÃ´ng tin nÃ y khÃ´ng cÃ³ trong tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p"

QUY Táº®C TRáº¢ Lá»œI:
- KHÃ”NG bá»‹a Ä‘áº·t hoáº·c thÃªm thÃ´ng tin khÃ´ng cÃ³ trong tÃ i liá»‡u
- KHÃ”NG suy diá»…n ra ngoÃ i pháº¡m vi cá»§a tÃ i liá»‡u
- LuÃ´n trÃ­ch dáº«n nguá»“n (Äiá»u, ChÆ°Æ¡ng, Má»¥c) khi cÃ³ thá»ƒ
- KHÃ”NG sá»­ dá»¥ng cá»¥m tá»« "TÃ i liá»‡u 1", "TÃ i liá»‡u 2" - CHá»ˆ dÃ¹ng "Äiá»u X", "ChÆ°Æ¡ng Y", "Má»¥c Z"
- Sá»­ dá»¥ng ngÃ´n ngá»¯ phÃ¡p lÃ½ chÃ­nh xÃ¡c nhÆ°ng dá»… hiá»ƒu
- Tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch nhÆ°ng Ä‘áº§y Ä‘á»§ thÃ´ng tin

Äá»ŠNH Dáº NG TRáº¢ Lá»œI MáºªU:
"Theo Äiá»u X (TÃªn Ä‘iá»u), [ná»™i dung chÃ­nh]. Cá»¥ thá»ƒ, [giáº£i thÃ­ch chi tiáº¿t]..."

Náº¿u cÃ³ nhiá»u Ä‘iá»u liÃªn quan:
"Vá» váº¥n Ä‘á» nÃ y:
- Theo Äiá»u X (TÃªn Ä‘iá»u): [ná»™i dung]
- Theo Äiá»u Y (TÃªn Ä‘iá»u): [ná»™i dung]"

Äáº¶C BIá»†T CHÃš Ã:
- Náº¿u cÃ¢u há»i dáº¡ng "Äiá»u X cÃ³ nÃ³i vá» Y khÃ´ng?":
  * Náº¿u tÃ i liá»‡u cÃ³ Äiá»u X nhÆ°ng KHÃ”NG Ä‘á» cáº­p Y â†’ Tráº£ lá»i rÃµ rÃ ng: "KHÃ”NG, Äiá»u X khÃ´ng Ä‘á» cáº­p Ä‘áº¿n Y. Äiá»u X quy Ä‘á»‹nh vá»..."
  * Náº¿u tÃ i liá»‡u cÃ³ Äiá»u X vÃ  CÃ“ Ä‘á» cáº­p Y â†’ Tráº£ lá»i: "CÃ“, Äiá»u X cÃ³ quy Ä‘á»‹nh vá» Y. Cá»¥ thá»ƒ..."
  * KHÃ”NG nÃ³i "khÃ´ng tÃ¬m tháº¥y trong cÆ¡ sá»Ÿ dá»¯ liá»‡u" náº¿u Ä‘Ã£ cÃ³ tÃ i liá»‡u vá» Äiá»u X

VÃ Dá»¤:
CÃ¢u há»i: "Äiá»u 7 cÃ³ nÃ³i vá» lá»‘p xe khÃ´ng?"
TÃ i liá»‡u: [Äiá»u 7: Quy Ä‘á»‹nh vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng khÃ´ng khÃ­...]
âœ… ÄÃºng: "KHÃ”NG, Äiá»u 7 khÃ´ng Ä‘á» cáº­p Ä‘áº¿n lá»‘p xe. Äiá»u 7 quy Ä‘á»‹nh vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­..."
âŒ Sai: "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin trong cÆ¡ sá»Ÿ dá»¯ liá»‡u"

CÃ¢u há»i: "Äiá»u 7 quy Ä‘á»‹nh gÃ¬?"
âœ… ÄÃšNG: "Äiá»u 7 quy Ä‘á»‹nh vá» trÃ¬nh tá»±, thá»§ tá»¥c ban hÃ nh káº¿ hoáº¡ch quá»‘c gia vá» quáº£n lÃ½ cháº¥t lÆ°á»£ng mÃ´i trÆ°á»ng khÃ´ng khÃ­..."
âŒ SAI: "KHÃ”NG, Äiá»u 7 khÃ´ng nÃ³i vá» lá»‘p xe..." (ÄÃ¢y lÃ  tráº£ lá»i cÃ¢u há»i khÃ¡c!)

===============================================
TÃ€I LIá»†U PHÃP LUáº¬T THAM KHáº¢O:

{context}

===============================================
CÃ‚U Há»I: {question}

TRáº¢ Lá»œI:"""


prompt = ChatPromptTemplate.from_template(prompt_template)

# LLM
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)


def format_docs(docs, max_docs: int = 5, max_tokens_per_doc: int = 800):
    """
    Format documents with metadata for LLM context with token limits

    Args:
        docs: List of documents to format
        max_docs: Maximum number of documents to include (default: 5)
        max_tokens_per_doc: Maximum tokens per document content (default: 800)

    Returns:
        Formatted string with document content
    """
    if not docs:
        return "KhÃ´ng cÃ³ tÃ i liá»‡u liÃªn quan."

    # Limit number of documents
    docs_to_use = docs[:max_docs]

    formatted_parts = []
    for i, doc in enumerate(docs_to_use, 1):
        metadata = doc.metadata

        # Build citation label from metadata
        citation_parts = []
        if metadata.get('Dieu'):
            citation_parts.append(f"Äiá»u {metadata.get('Dieu')}")
        if metadata.get('Muc'):
            citation_parts.append(f"Má»¥c {metadata.get('Muc')}")
        if metadata.get('Chuong'):
            citation_parts.append(f"ChÆ°Æ¡ng {metadata.get('Chuong')}")

        # Create citation label
        if citation_parts:
            citation = ", ".join(citation_parts)
        else:
            citation = f"TÃ i liá»‡u {i}"

        # Truncate document content to fit token limit
        content = truncate_text(doc.page_content, max_tokens=max_tokens_per_doc)

        # Include metadata in the formatted output
        doc_with_meta = f"""[{citation}]
TÃªn Äiá»u: {metadata.get('Dieu_Name', 'N/A')}
TÃªn ChÆ°Æ¡ng: {metadata.get('Chuong_Name', 'N/A')}
TÃªn Má»¥c: {metadata.get('Muc_Name', 'N/A')}

Ná»™i dung:
{content}
"""
        formatted_parts.append(doc_with_meta)

    return "\n\n---\n\n".join(formatted_parts)
# Chain
rag_chain = prompt | llm | StrOutputParser()

# Generate function
def generate(state):
    """Generate answer using RAG with detailed prompt"""
    print("---GENERATE---")
    question = state["question"]
    documents = state["documents"]
    retries = state.get("retries", 0)

    if not documents:
        print("   âš ï¸ No documents available")


    else:
        # Format documents with metadata
        context = format_docs(documents)
        print(f"   ğŸ“„ Generating from {len(documents)} documents")

        # Generate answer
        generation = rag_chain.invoke({"context": context, "question": question})

    return {
        "documents": documents,
        "question": question,
        "generation": generation,
        "retries": retries
    }

def decide_to_generate(state):
    """
    Determines whether to generate an answer, or re-generate a question.
    Implements retry logic - allows up to 3 query transformations before giving up.

    Args:
        state (dict): The current graph state

    Returns:
        str: Binary decision for next node to call
    """

    print("---ASSESS GRADED DOCUMENTS---")
    question = state["question"]
    filtered_documents = state["documents"]
    retries = state.get("retries", 0)  # Get current retries from state
    max_retries = 3

    print(f"   Current retries: {retries}/{max_retries}")
    print(f"   Filtered documents: {len(filtered_documents)}")

    if not filtered_documents:
        # All documents have been filtered check_relevance

        if retries < max_retries:
            # Still have retries left - transform query
            print(f"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY (Attempt {retries + 1}/{max_retries})---")
            state["retries"] = retries + 1  # Increment retries
            return "transform_query"
        else:
            # Max retries reached - give up
            print(f"---DECISION: MAX RETRIES ({max_retries}) REACHED, GENERATING ANSWER WITH NO RELEVANT DOCUMENTS---")
            return "web_search"
    else:
        # We have relevant documents, so generate answer
        print(f"---DECISION: GENERATE WITH {len(filtered_documents)} RELEVANT DOCUMENTS---")
        return "generate"

### Web Search - Return Links Only

from langchain_community.tools.tavily_search import TavilySearchResults
import os

# Initialize web search tool with error handling
try:
    tavily_api_key = os.getenv("TAVILY_API_KEY")
    if not tavily_api_key or tavily_api_key == "your-tavily-api-key-here":
        print("âš ï¸ WARNING: TAVILY_API_KEY not configured. Web search will not work.")
        print("   Please set TAVILY_API_KEY in your .env file to enable web search.")
        web_search_tool = None
    else:
        web_search_tool = TavilySearchResults(k=3)
        print("âœ… Tavily web search tool initialized successfully!")
except Exception as e:
    print(f"âš ï¸ WARNING: Failed to initialize Tavily web search: {e}")
    web_search_tool = None

def web_search(state):
    """
    Perform web search and store results in web_urls
    Does NOT generate final response - that's done by generate_web

    Args:
        state (dict): The current graph state

    Returns:
        state (dict): Updates web_urls with search results
    """
    print("---WEB SEARCH FOR ADDITIONAL RESOURCES---")
    question = state["question"]

    # Check if web search tool is available
    if web_search_tool is None:
        print("   âš ï¸ Web search tool not available (TAVILY_API_KEY not configured)")
        links_text = f"""CÃ¢u há»i "{question}" khÃ´ng tÃ¬m tháº¥y trong cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¡p luáº­t EPR.

âš ï¸ THÃ”NG BÃO:
TÃ­nh nÄƒng tÃ¬m kiáº¿m web chÆ°a Ä‘Æ°á»£c kÃ­ch hoáº¡t. Äá»ƒ sá»­ dá»¥ng tÃ­nh nÄƒng nÃ y:
1. ÄÄƒng kÃ½ tÃ i khoáº£n táº¡i https://tavily.com
2. Láº¥y API key
3. ThÃªm TAVILY_API_KEY vÃ o file .env

ğŸ’¡ Gá»¢I Ã:
- Thá»­ Ä‘áº·t cÃ¢u há»i khÃ¡c hoáº·c cá»¥ thá»ƒ hÆ¡n
- Kiá»ƒm tra chÃ­nh táº£ vÃ  tá»« khÃ³a
- LiÃªn há»‡ chuyÃªn gia phÃ¡p lÃ½ Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n trá»±c tiáº¿p
"""
        return {
            "question": question,
            "web_urls": links_text,
        }

    try:
        # Perform web search
        print(f"   ğŸ” Searching web for: {question}")
        search_results = web_search_tool.invoke({"query": question})

        # Format results as links
        if search_results:
            links_text = f"""CÃ¢u há»i "{question}" khÃ´ng tÃ¬m tháº¥y trong cÆ¡ sá»Ÿ dá»¯ liá»‡u phÃ¡p luáº­t EPR.

ğŸ“š CÃC NGUá»’N THAM KHáº¢O Tá»ª WEB:

"""
            for i, result in enumerate(search_results, 1):
                title = result.get("title", "KhÃ´ng cÃ³ tiÃªu Ä‘á»")
                url = result.get("url", "")
                snippet = result.get("content", "")[:200] + "..." if result.get("content") else ""

                links_text += f"{i}. {title}\n"
                links_text += f"   ğŸ”— {url}\n"
                if snippet:
                    links_text += f"   ğŸ“ {snippet}\n"
                links_text += "\n"

            links_text += """
âš ï¸ LÆ¯U Ã:
- CÃ¡c nguá»“n trÃªn tá»« Internet, chÆ°a Ä‘Æ°á»£c kiá»ƒm chá»©ng
- Vui lÃ²ng xÃ¡c minh Ä‘á»™ chÃ­nh xÃ¡c tá»« cÆ¡ quan cÃ³ tháº©m quyá»n
- Äá»ƒ Ä‘Æ°á»£c tÆ° váº¥n chÃ­nh xÃ¡c, liÃªn há»‡ luáº­t sÆ° chuyÃªn ngÃ nh
"""
            print(f"   âœ… Found {len(search_results)} web results")
        else:
            links_text = f"KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ tÃ¬m kiáº¿m web vá» '{question}'."
            print(f"   âš ï¸  No web results found")

    except Exception as e:
        print(f"   âŒ Web search error: {e}")
        import traceback
        print(f"   Error details: {traceback.format_exc()}")
        links_text = f"""KhÃ´ng thá»ƒ thá»±c hiá»‡n tÃ¬m kiáº¿m web cho cÃ¢u há»i "{question}".

âŒ Lá»–I: {str(e)}

ğŸ’¡ Gá»¢I Ã:
- Kiá»ƒm tra káº¿t ná»‘i Internet
- Kiá»ƒm tra TAVILY_API_KEY trong file .env
- Thá»­ láº¡i sau vÃ i phÃºt
- LiÃªn há»‡ quáº£n trá»‹ viÃªn náº¿u lá»—i váº«n tiáº¿p diá»…n
"""

    return {
        "question": question,
        "web_urls": links_text,
    }

### Generate Web - Separate Function for Web Search Results

def generate_web(state):
    """
    Generate response from web search results

    Args:
        state (dict): The current graph state

    Returns:
        dict: Updated state with web search results as generation
    """
    print("---GENERATE WEB RESPONSE---")

    question = state["question"]
    web_urls = state.get("web_urls", "")

    if web_urls:
        print(f"   ğŸŒ Formatting web search results")
        generation = web_urls
    else:
        print(f"   âš ï¸  No web URLs found")
        generation = f"Xin lá»—i, khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» '{question}'"

    print(f"   âœ… Generated web response")

    return {
        "question": question,
        "generation": generation,
        "web_urls": web_urls
    }

### Hallucination Grader - Kiá»ƒm tra áº£o giÃ¡c

from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate

# Data model
class GradeHallucinations(BaseModel):
    """ÄÃ¡nh giÃ¡ nhá»‹ phÃ¢n xem cÃ¢u tráº£ lá»i cÃ³ dá»±a trÃªn tÃ i liá»‡u hay khÃ´ng."""

    binary_score: str = Field(
        description="CÃ¢u tráº£ lá»i cÃ³ dá»±a trÃªn tÃ i liá»‡u khÃ´ng, 'cÃ³' hoáº·c 'khÃ´ng'"
    )

# LLM with function call
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
structured_llm_grader = llm.with_structured_output(GradeHallucinations)

# Prompt
system = """Báº¡n lÃ  chuyÃªn gia Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i AI trong lÄ©nh vá»±c phÃ¡p luáº­t EPR Viá»‡t Nam.

ğŸ¯ Má»¤C TIÃŠU:
XÃ¡c Ä‘á»‹nh xem cÃ¢u tráº£ lá»i cá»§a AI cÃ³ HOÃ€N TOÃ€N dá»±a trÃªn cÃ¡c tÃ i liá»‡u phÃ¡p luáº­t Ä‘Æ°á»£c cung cáº¥p hay khÃ´ng.

ğŸ“‹ TIÃŠU CHÃ ÄÃNH GIÃ 'CÃ“' (cÃ¢u tráº£ lá»i tá»‘t):
âœ“ Má»i thÃ´ng tin trong cÃ¢u tráº£ lá»i Ä‘á»u cÃ³ trong tÃ i liá»‡u
âœ“ Sá»‘ Äiá»u, ChÆ°Æ¡ng, Má»¥c Ä‘Æ°á»£c trÃ­ch dáº«n CHÃNH XÃC khá»›p vá»›i tÃ i liá»‡u
âœ“ CÃ¢u tráº£ lá»i cÃ³ thá»ƒ tÃ³m táº¯t hoáº·c diá»…n giáº£i tÃ i liá»‡u
âœ“ NgÃ´n ngá»¯ khÃ¡c nhau nhÆ°ng Ã½ nghÄ©a giá»‘ng tÃ i liá»‡u

âŒ TIÃŠU CHÃ ÄÃNH GIÃ 'KHÃ”NG' (cÃ¢u tráº£ lá»i cÃ³ váº¥n Ä‘á»):
âœ— CÃ¢u tráº£ lá»i cÃ³ thÃ´ng tin KHÃ”NG CÃ“ trong tÃ i liá»‡u
âœ— Sá»‘ Äiá»u, ChÆ°Æ¡ng, Má»¥c SAI hoáº·c khÃ´ng khá»›p
âœ— CÃ¢u tráº£ lá»i thÃªm chi tiáº¿t khÃ´ng cÃ³ trong tÃ i liá»‡u
âœ— CÃ¢u tráº£ lá»i Ä‘Æ°a ra Ã½ kiáº¿n cÃ¡ nhÃ¢n khÃ´ng cÃ³ cÆ¡ sá»Ÿ
âœ— CÃ¢u tráº£ lá»i suy luáº­n thÃ´ng tin khÃ´ng Ä‘Æ°á»£c tÃ i liá»‡u há»— trá»£

ğŸ” Äáº¶C BIá»†T CHÃš Ã:
- Kiá»ƒm tra ká»¹ cÃ¡c con sá»‘: sá»‘ Äiá»u, Khoáº£n, Má»¥c, ChÆ°Æ¡ng, nÄƒm
- Kiá»ƒm tra tÃªn chÃ­nh xÃ¡c cá»§a cÃ¡c Ä‘iá»u luáº­t
- KhÃ´ng cháº¥p nháº­n thÃ´ng tin "gáº§n Ä‘Ãºng" hoáº·c "cÃ³ thá»ƒ suy ra"

âš–ï¸ Káº¾T LUáº¬N:
Tráº£ lá»i 'cÃ³' chá»‰ khi cÃ¢u tráº£ lá»i HOÃ€N TOÃ€N dá»±a trÃªn tÃ i liá»‡u.
Tráº£ lá»i 'khÃ´ng' náº¿u cÃ³ Báº¤T Ká»² thÃ´ng tin nÃ o khÃ´ng Ä‘Æ°á»£c tÃ i liá»‡u há»— trá»£.

HÃ£y Ä‘Æ°a ra Ä‘Ã¡nh giÃ¡: 'cÃ³' hoáº·c 'khÃ´ng'"""

hallucination_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system),
        ("human", "TÃ i liá»‡u phÃ¡p luáº­t: \n\n {documents} \n\n CÃ¢u tráº£ lá»i cá»§a AI: {generation}"),
    ]
)

hallucination_grader = hallucination_prompt | structured_llm_grader

print("âœ… Hallucination grader Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng!")

### Answer Grader - ÄÃ¡nh giÃ¡ cÃ¢u tráº£ lá»i cÃ³ giáº£i quyáº¿t cÃ¢u há»i khÃ´ng

from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate

# Data model
class GradeAnswer(BaseModel):
    """ÄÃ¡nh giÃ¡ nhá»‹ phÃ¢n xem cÃ¢u tráº£ lá»i cÃ³ giáº£i quyáº¿t Ä‘Æ°á»£c cÃ¢u há»i hay khÃ´ng."""

    binary_score: str = Field(
        description="CÃ¢u tráº£ lá»i cÃ³ giáº£i quyáº¿t cÃ¢u há»i khÃ´ng, 'cÃ³' hoáº·c 'khÃ´ng'"
    )

# LLM with function call
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
structured_llm_grader = llm.with_structured_output(GradeAnswer)

# Prompt
system = """Báº¡n lÃ  bá»™ Ä‘Ã¡nh giÃ¡ xem cÃ¢u tráº£ lá»i cá»§a AI cÃ³ giáº£i quyáº¿t/tráº£ lá»i Ä‘Æ°á»£c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng hay khÃ´ng.

NHIá»†M Vá»¤:
ÄÃ¡nh giÃ¡ xem cÃ¢u tráº£ lá»i cÃ³ GIáº¢I QUYáº¾T TRá»°C TIáº¾P cÃ¢u há»i hay khÃ´ng.

QUY Táº®C ÄÃNH GIÃ 'CÃ“':
âœ“ CÃ¢u tráº£ lá»i cung cáº¥p thÃ´ng tin mÃ  ngÆ°á»i dÃ¹ng Ä‘ang tÃ¬m kiáº¿m
âœ“ CÃ¢u tráº£ lá»i tráº£ lá»i Ä‘Ãºng trá»ng tÃ¢m cÃ¢u há»i
âœ“ NgÆ°á»i dÃ¹ng cÃ³ thá»ƒ hiá»ƒu vÃ  sá»­ dá»¥ng Ä‘Æ°á»£c thÃ´ng tin trong cÃ¢u tráº£ lá»i
âœ“ CÃ¢u tráº£ lá»i cÃ³ thá»ƒ dÃ i hoáº·c ngáº¯n, nhÆ°ng pháº£i ÄÃšNG TRá»ŒNG TÃ‚M

QUY Táº®C ÄÃNH GIÃ 'KHÃ”NG':
âœ— CÃ¢u tráº£ lá»i khÃ´ng liÃªn quan Ä‘áº¿n cÃ¢u há»i
âœ— CÃ¢u tráº£ lá»i nÃ© trÃ¡nh hoáº·c khÃ´ng tráº£ lá»i trá»±c tiáº¿p
âœ— CÃ¢u tráº£ lá»i quÃ¡ chung chung, khÃ´ng cung cáº¥p thÃ´ng tin cá»¥ thá»ƒ
âœ— CÃ¢u tráº£ lá»i nÃ³i "khÃ´ng cÃ³ thÃ´ng tin" khi ngÆ°á»i dÃ¹ng há»i cÃ¢u há»i cá»¥ thá»ƒ

HÃ£y Ä‘Æ°a ra Ä‘Ã¡nh giÃ¡: 'cÃ³' hoáº·c 'khÃ´ng'"""

answer_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system),
        ("human", "CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: \n\n {question} \n\n CÃ¢u tráº£ lá»i cá»§a AI: {generation}"),
    ]
)

answer_grader = answer_prompt | structured_llm_grader

print("âœ… Answer grader Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng!")

def grade_generation_v_documents_and_question(state):
    """Grade generation quality"""
    print("---KIá»‚M TRA CHáº¤T LÆ¯á»¢NG CÃ‚U TRáº¢ Lá»œI---")
    
    question = state["question"]
    documents = state["documents"]
    generation = state["generation"]
    generation_retries = int(state.get("generation_retries") or 0)
    max_generation_retries = 3
    
    print(f"   Generation retries: {generation_retries}/{max_generation_retries}")
    
    
    # Determine grade_result and new_generation_retries
    grade_result = "useful"  # default
    new_generation_retries = generation_retries  # default
    
    if not documents:
        print("   âš ï¸  KhÃ´ng cÃ³ tÃ i liá»‡u, bá» qua grading")
        grade_result = "useful"
    else:
        formatted_docs = format_docs(documents)
        
        print("---BÆ¯á»šC 1: KIá»‚M TRA áº¢O GIÃC---")
        hallucination_score = hallucination_grader.invoke({
            "documents": formatted_docs,
            "generation": generation
        })
        hallucination_grade = hallucination_score.binary_score

        if hallucination_grade == "cÃ³":
            print("   âœ… PASS: Dá»±a trÃªn tÃ i liá»‡u")
            
            print("---BÆ¯á»šC 2: KIá»‚M TRA CÃ‚U TRáº¢ Lá»œI---")
            answer_score = answer_grader.invoke({
                "question": question,
                "generation": generation
            })
            answer_grade = answer_score.binary_score
            
            if answer_grade == "cÃ³":
                print("   âœ… PASS: Giáº£i quyáº¿t cÃ¢u há»i")
                print("---QUYáº¾T Äá»ŠNH: USEFUL---")
                grade_result = "useful"
                # Don't increment
            else:
                print("   âŒ FAIL: KhÃ´ng giáº£i quyáº¿t cÃ¢u há»i")
                
                if generation_retries < max_generation_retries:
                    print(f"---Táº O Láº I: Láº§n {generation_retries + 1}/{max_generation_retries}---")
                    grade_result = "not useful"
                    new_generation_retries = generation_retries + 1  # âœ… INCREMENT
                else:
                    print(f"---Háº¾T Láº¦N THá»¬: CHUYá»‚N WEB SEARCH---")
                    grade_result = "web_search"
        else:
            print("   âŒ FAIL: CÃ³ áº£o giÃ¡c")
            
            if generation_retries < max_generation_retries:
                print(f"---Táº O Láº I: Láº§n {generation_retries + 1}/{max_generation_retries}---")
                grade_result = "not supported"
                new_generation_retries = generation_retries + 1  # âœ… INCREMENT
            else:
                print(f"---Háº¾T Láº¦N THá»¬: CHUYá»‚N WEB SEARCH---")
                grade_result = "web_search"
    
    print(f"\nğŸ” RETURNING STATE:")
    print(f"   grade_result: {grade_result}")
    print(f"   generation_retries: {new_generation_retries} (was {generation_retries})")
    
    # âœ… Return ALL state fields
    return {
        "question": state.get("question"),
        "original_question": state.get("original_question"),
        "chat_history": state.get("chat_history", ""),
        "generation": state.get("generation"),
        "documents": state.get("documents", []),
        "retries": state.get("retries", 0),
        "generation_retries": new_generation_retries,  # âœ… Updated value
        "grade_result": grade_result,  # âœ… Updated value
        "hallucination_detected": hallucination_grade == "khÃ´ng" if documents else False
    }

# 

def decide_after_grade_generation(state):
    """Decide next step"""
    print(f"\n{'='*80}")
    print(f"ğŸ” ROUTING FUNCTION - FULL DEBUG")
    print(f"{'='*80}")
    
    # Print EVERYTHING
    print("Full state received:")
    for key, val in state.items():
        if key not in ["documents", "chat_history"]:
            print(f"  {key}: {repr(val)}")
    
    grade_result = state.get("grade_result", "useful")
    
    print(f"\nExtracted:")
    print(f"  grade_result: {repr(grade_result)}")
    print(f"  Type: {type(grade_result)}")
    print(f"  Is 'not supported': {grade_result == 'not supported'}")
    print(f"  Is 'useful': {grade_result == 'useful'}")
    
    print(f"\nğŸ”€ ROUTING DECISION: {grade_result}")
    print(f"{'='*80}\n")
    
    if grade_result == "not supported":
        print("  â†’ Routing to 'not supported' (regenerate)")
        return "not supported"
    elif grade_result == "useful":
        print("  â†’ Routing to 'useful' (END)")
        return "useful"
    elif grade_result == "not useful":
        print("  â†’ Routing to 'not useful' (transform)")
        return "not useful"
    elif grade_result == "web_search":
        print("  â†’ Routing to 'web_search'")
        return "web_search"
    else:
        print(f"  â†’ Unknown value, defaulting to 'useful'")
        return "useful"

from langgraph.graph import END, StateGraph
from typing import TypedDict, List

class GraphState(TypedDict):
    question: str
    generation: str
    documents: List[str]
    
    original_question: str
    chat_history: str
    retries: int
    generation_retries: int
    grade_result: str 
    hallucination_detected: bool 
    web_urls: str

# ========== BUILD WORKFLOW ==========

workflow = StateGraph(GraphState)

# Add initial routing node (no transformation - just routes)
def initial_route_node(state):
    """Initial routing node - passes question through without transformation"""
    print("---INITIAL ROUTING NODE---")
    question = state["question"]
    chat_history = get_full_chat_history()

    # Save original question and chat history at the very beginning
    if "original_question" not in state or not state.get("original_question"):
        print(f"  ğŸ’¾ Saving original question: {question}")
        state["original_question"] = question

    if "original_chat_history" not in state or not state.get("original_chat_history"):
        print(f"  ğŸ’¾ Saving chat history snapshot ({len(chat_history)} chars)")
        state["original_chat_history"] = chat_history

    # Just return state without transformation
    return {
        **state,
        "question": question,
        "chat_history": chat_history
    }

# Add nodes
workflow.add_node("initial_route", initial_route_node)
workflow.add_node("retrieve_faq", retrieve_faq_node)

workflow.add_node("generate_faq", generate_faq_node)
workflow.add_node("retrieve", retrieve)
workflow.add_node("generate", generate)

workflow.add_node("transform_query1", transform_query)
workflow.add_node("transform_query2", transform_query)
workflow.add_node("transform_query3", transform_query)

workflow.add_node("grade_documents", grade_documents)
workflow.add_node("grade_generation", grade_generation_v_documents_and_question)

workflow.add_node("chitchat1", chitchat)
workflow.add_node("chitchat2", chitchat)
workflow.add_node("web_search1", web_search) # web search
workflow.add_node("generate_web1", generate_web) # generatae

workflow.add_node("web_search2", web_search) # web search
workflow.add_node("generate_web2", generate_web) # generatae

workflow.add_node("new_round_router", new_round_router)

# Set entry point with routing BEFORE transformation
workflow.set_entry_point("initial_route")
workflow.add_conditional_edges(
    "initial_route",
    route_question_faq,
    {
        "vectorstore_faq": "transform_query1",  # Transform only for FAQ path
        "chitchat": "chitchat1",  # No transformation for chitchat
    },
)

# After transforming FAQ queries, retrieve
workflow.add_edge("transform_query1", "retrieve_faq")

# Add edges
workflow.add_edge("chitchat1", END)

# Conditional edges from grade_faq_documents
workflow.add_conditional_edges(
    "retrieve_faq",
    decide_after_retrieve_faq,
    {
        "generate_faq": "generate_faq",
        "new_round_router": "new_round_router",
    },
)

# Transform query loops back to retrieve
workflow.add_edge("generate_faq", END)

workflow.add_edge("new_round_router", "transform_query2")

workflow.add_conditional_edges(
    "transform_query2",
    route_question_law,
    {
        "vectorstore": "retrieve",
        "chitchat": "chitchat2",
    },
)

workflow.add_edge("chitchat2", END)
workflow.add_edge("retrieve", "grade_documents")
workflow.add_conditional_edges(
    "grade_documents",
    decide_to_generate,
    {
        "transform_query": "transform_query3",
        "generate": "generate",
        "web_search":"web_search1"
    },
)
workflow.add_edge("transform_query3", "retrieve")



workflow.add_edge("web_search1","generate_web1")

workflow.add_edge("generate_web1",END)

workflow.add_edge("generate", "grade_generation")

workflow.add_conditional_edges(
    "grade_generation",
    decide_after_grade_generation,
    {
        "useful": END,              # Good answer
        "not useful": "transform_query3",   # Regenerate with same docs
        "not supported": "generate", # Regenerate (hallucination)
        "web_search": "web_search2"  # Max retries, go to web search
    }
)
workflow.add_edge("web_search2","generate_web2")
workflow.add_edge("generate_web2",END)



# Compile the graph
app = workflow.compile()

print("âœ… Workflow compiled successfully!")



def get_full_chat_history(max_exchanges=3):
    """
    Get recent chat history from memory

    Args:
        max_exchanges: Number of recent conversation pairs to keep (default: 3)
        Each exchange = 1 user message + 1 assistant message = 2 messages total
        Reduced from 5 to 3 to prevent context overflow

    Returns:
        Formatted chat history string
    """
    try:
        memory_vars = conversation_memory.load_memory_variables({})
        if "chat_history" in memory_vars:
            messages = memory_vars["chat_history"]

            if messages:
                # Keep only last N exchanges (N*2 messages)
                recent_messages = messages[-(max_exchanges * 2):]

                formatted = []
                for msg in recent_messages:
                    if hasattr(msg, 'type'):
                        role = "User" if msg.type == "human" else "Assistant"
                        content = msg.content
                        # Truncate individual messages to prevent overflow
                        content = truncate_text(content, max_tokens=500)
                        formatted.append(f"{role}: {content}")
                    else:
                        formatted.append(str(msg))

                chat_history = "\n".join(formatted)

                # Ensure total chat history doesn't exceed limit
                return truncate_text(chat_history, max_tokens=2000)
    except Exception as e:
        print(f"  âš ï¸ Error loading history: {e}")
    return ""

print("âœ“ get_full_chat_history with limit created")

def clear_memory():
    """XÃ³a toÃ n bá»™ bá»™ nhá»› há»™i thoáº¡i"""
    conversation_memory.clear()
    print("âœ¨ ÄÃ£ xÃ³a toÃ n bá»™ bá»™ nhá»› há»™i thoáº¡i thÃ nh cÃ´ng!")


# === Test 11: Clear memory ===
print("\nğŸ“ TEST 11: CLEAR MEMORY")
clear_memory()

def test_graph(question: str):
    """Test graph with proper initialization"""
    print("\n" + "#"*80)
    print("ğŸ¤– TESTING GRAPH")
    print("#"*80)
    print(f"Question: {question}")

    real_chat_history = get_full_chat_history(max_exchanges=5)

    initial_state = {
        "question": question,
        "generation": "",
        "documents": [],
        "original_question": question,
        "chat_history": real_chat_history,
        "retries": 0,
        "generation_retries": 0,  # âœ… CRITICAL: Initialize to 0, not None
        "original_chat_history": "",
        "web_urls": "",
        "hallucination_detected": False,
        "answer_quality": "",
        "grade_result": ""
    }

    final_state = app.invoke(initial_state)

    print("\n" + "#"*80)
    print("âœ… COMPLETE")
    print(f"Answer: {final_state.get('generation', '')}")
    print(f"Query retries used: {final_state.get('retries', 0)}")
    print(f"Generation retries used: {final_state.get('generation_retries', 0)}")
    print("#"*80 + "\n")

    return final_state

# ========== RUN TESTS (COMMENTED OUT FOR MODULE IMPORT) ==========
# Uncomment below to run standalone tests

# if __name__ == "__main__":
#     print("\n" + "="*80)
#     print("ğŸ§ª TESTING WITH REAL MEMORY")
#     print("="*80)
#
#     test_cases = [
#         "báº¡n lÃ m Ä‘Æ°á»£c gÃ¬?",
#         "báº¡n biáº¿t Ä‘Æ°á»£c bao nhiÃªu Ä‘iá»u luáº­t",
#         "ká»ƒ vá» Ä‘iá»u 1 vÃ  2",
#         "náº¿u bÃ¢y giá» tÃ´i muá»‘n lÃ m 2 Ä‘iá»u Ä‘Ã³, tÃ´i cáº§n lÃ m nhá»¯ng gÃ¬ á»Ÿ tá»«ng Ä‘iá»u luáº­t?",
#         "hÆ°á»›ng dáº«n tÆ°Æ¡ng tá»± cho Ä‘iá»u 4",
#         "cÃ¡ch náº¥u mÃ¬ xÃ o ngon?",
#     ]
#
#     for question in test_cases:
#         result = test_graph(question)
#
#         try:
#             conversation_memory.save_context(
#                 {"input": question},
#                 {"generation": result.get('generation', 'No response')}
#             )
#             print(f"ğŸ’¾ Saved to memory: Q='{question[:30]}...' A='{result.get('generation', '')[:30]}...'\n")
#         except Exception as e:
#             print(f"âš ï¸  Could not save to memory: {e}\n")
#
#     print("="*80)
#     print("âœ… All tests complete!")
#     print("="*80)
#
#     print("\n" + "="*80)
#     print("ğŸ“š FINAL MEMORY STATE")
#     print("="*80)
#     final_history = get_full_chat_history(max_exchanges=10)
#     print(f"Total history: {len(final_history)} chars\n")
#     print(final_history)
#     print("="*80)

print("âœ… EPR Chatbot Core Module Loaded Successfully!")


# ============================================================================
# ğŸš€ PERFORMANCE OPTIMIZATIONS: ASYNC + STREAMING
# ============================================================================

import asyncio
from typing import AsyncIterator, Dict, Any

print("\n" + "="*80)
print("ğŸš€ Loading Performance Optimizations...")
print("="*80)

# ========== ASYNC PARALLEL RETRIEVAL ==========

async def retrieve_faq_async(query: str, score_threshold: float = 0.6):
    """Async version of FAQ retrieval"""
    print("  ğŸ” [ASYNC] Retrieving FAQ...")

    # Run synchronous retrieval in thread pool
    loop = asyncio.get_event_loop()
    documents = await loop.run_in_executor(
        None,
        retrieve_faq_top1,
        query,
        score_threshold
    )

    print(f"  âœ… [ASYNC] FAQ retrieval done: {len(documents)} docs")
    return documents


async def retrieve_legal_async(question: str):
    """Async version of legal document retrieval"""
    print("  ğŸ“š [ASYNC] Retrieving legal docs...")

    # Run synchronous retrieval in thread pool
    loop = asyncio.get_event_loop()

    try:
        documents = await loop.run_in_executor(
            None,
            fallback_retriever.invoke,
            question
        )
    except Exception as e:
        print(f"  âš ï¸ [ASYNC] Error: {e}, falling back to similarity search")
        documents = await loop.run_in_executor(
            None,
            vectorstore_fix.similarity_search,
            question,
            5
        )

    print(f"  âœ… [ASYNC] Legal retrieval done: {len(documents)} docs")
    return documents


async def parallel_retrieve(query: str, faq_threshold: float = 0.6):
    """
    Retrieve FAQ and legal documents in parallel for maximum speed

    Args:
        query: User's question
        faq_threshold: Minimum score for FAQ match

    Returns:
        dict: {
            'faq_docs': list of FAQ documents,
            'legal_docs': list of legal documents,
            'faq_time': float (seconds),
            'legal_time': float (seconds)
        }
    """
    import time

    print("\n" + "="*80)
    print("âš¡ PARALLEL RETRIEVAL")
    print("="*80)
    print(f"Query: {query}")

    start_time = time.time()

    # Run both retrievals in parallel
    faq_docs, legal_docs = await asyncio.gather(
        retrieve_faq_async(query, faq_threshold),
        retrieve_legal_async(query),
        return_exceptions=True
    )

    total_time = time.time() - start_time

    # Handle exceptions
    if isinstance(faq_docs, Exception):
        print(f"  âš ï¸ FAQ retrieval failed: {faq_docs}")
        faq_docs = []

    if isinstance(legal_docs, Exception):
        print(f"  âš ï¸ Legal retrieval failed: {legal_docs}")
        legal_docs = []

    print(f"  âš¡ Total parallel retrieval time: {total_time:.2f}s")
    print(f"  ğŸ“Š Results: FAQ={len(faq_docs)}, Legal={len(legal_docs)}")
    print("="*80)

    return {
        'faq_docs': faq_docs,
        'legal_docs': legal_docs,
        'total_time': total_time
    }


# ========== STREAMING LLM GENERATION ==========

def create_streaming_llm():
    """Create an LLM instance configured for streaming"""
    return ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0,
        streaming=True
    )

streaming_llm = create_streaming_llm()


# async def generate_answer_streaming(query: str, documents: list, source_type: str = "faq") -> AsyncIterator[str]:
#     """
#     Generate answer with streaming for real-time display

#     Args:
#         query: User question
#         documents: Retrieved documents
#         source_type: "faq" or "legal"

#     Yields:
#         str: Chunks of the generated response
#     """
#     if not documents:
#         yield "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p. Báº¡n cÃ³ thá»ƒ há»i chi tiáº¿t hÆ¡n khÃ´ng?"
#         return

#     # GPT-3.5-turbo context limit
#     MAX_CONTEXT_TOKENS = 15000  # Leave buffer for response

#     # Create appropriate prompt based on source
#     if source_type == "faq":
#         doc = documents[0]
#         faq_question = doc.metadata.get("CÃ¢u_há»i", "")
#         faq_answer = doc.page_content

#         # Truncate FAQ answer if too long
#         faq_answer = truncate_text(faq_answer, max_tokens=2000)

#         prompt = ChatPromptTemplate.from_messages([
#             ("system", """Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» luáº­t EPR Viá»‡t Nam.
# Tráº£ lá»i dá»±a trÃªn FAQ, giá»¯ thÃ´ng tin chÃ­nh xÃ¡c, ngáº¯n gá»n vÃ  thÃ¢n thiá»‡n."""),
#             ("user", """CÃ¢u há»i FAQ: {faq_question}
# CÃ¢u tráº£ lá»i FAQ: {faq_answer}

# CÃ¢u há»i ngÆ°á»i dÃ¹ng: {user_question}

# Tráº£ lá»i:""")
#         ])

#         chain = prompt | streaming_llm

#         async for chunk in chain.astream({
#             "faq_question": faq_question,
#             "faq_answer": faq_answer,
#             "user_question": query
#         }):
#             if hasattr(chunk, 'content'):
#                 yield chunk.content

#     else:  # legal documents
#         # Limit documents to prevent context overflow
#         # Max 4 documents, each with max 1000 tokens
#         context = format_docs(documents, max_docs=4, max_tokens_per_doc=1000)

#         # Verify total context size
#         context_tokens = count_tokens(context)
#         query_tokens = count_tokens(query)
#         system_prompt_tokens = 100  # Rough estimate

#         total_input_tokens = context_tokens + query_tokens + system_prompt_tokens

#         print(f"   ğŸ“Š Context size: {context_tokens} tokens")
#         print(f"   ğŸ“Š Query size: {query_tokens} tokens")
#         print(f"   ğŸ“Š Total input: {total_input_tokens} tokens")

#         if total_input_tokens > MAX_CONTEXT_TOKENS:
#             print(f"   âš ï¸ Context too large ({total_input_tokens} tokens), further reducing...")
#             # Further reduce if still too large
#             context = format_docs(documents, max_docs=3, max_tokens_per_doc=600)
#             context_tokens = count_tokens(context)
#             print(f"   âœ… Reduced to {context_tokens} tokens")

#         prompt = ChatPromptTemplate.from_messages([
#             ("system", """Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» phÃ¡p luáº­t EPR Viá»‡t Nam.
# Tráº£ lá»i dá»±a HOÃ€N TOÃ€N trÃªn tÃ i liá»‡u, trÃ­ch dáº«n Äiá»u/ChÆ°Æ¡ng cá»¥ thá»ƒ."""),
#             ("user", """TÃ i liá»‡u phÃ¡p luáº­t:
# {context}

# CÃ¢u há»i: {question}

# Tráº£ lá»i:""")
#         ])

#         chain = prompt | streaming_llm

#         async for chunk in chain.astream({
#             "context": context,
#             "question": query
#         }):
#             if hasattr(chunk, 'content'):
#                 yield chunk.content
async def generate_answer_streaming(
    query: str, 
    documents: list, 
    source_type: str = "faq",
    response_style: str = "detailed",  # "detailed", "concise", "comprehensive"
    include_examples: bool = True,
    include_references: bool = True
) -> AsyncIterator[str]:
    """
    Generate answer with streaming for real-time display
    
    Args:
        query: User question
        documents: Retrieved documents
        source_type: "faq" or "legal"
        response_style: Level of detail in response
        include_examples: Whether to include practical examples
        include_references: Whether to include legal references
        
    Yields:
        str: Chunks of the generated response
    """
    if not documents:
        yield """Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p vá»›i cÃ¢u há»i cá»§a báº¡n trong cÆ¡ sá»Ÿ dá»¯ liá»‡u hiá»‡n táº¡i.

**Gá»£i Ã½ Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ há»— trá»£ báº¡n tá»‘t hÆ¡n:**
- HÃ£y thá»­ diá»…n Ä‘áº¡t cÃ¢u há»i theo cÃ¡ch khÃ¡c
- Cung cáº¥p thÃªm chi tiáº¿t vá» váº¥n Ä‘á» báº¡n quan tÃ¢m
- Cho biáº¿t báº¡n thuá»™c loáº¡i hÃ¬nh doanh nghiá»‡p nÃ o (sáº£n xuáº¥t, nháº­p kháº©u, phÃ¢n phá»‘i...)

Báº¡n cÃ³ thá»ƒ Ä‘áº·t cÃ¢u há»i láº¡i Ä‘Æ°á»£c khÃ´ng?"""
        return

    # GPT-3.5-turbo context limit
    MAX_CONTEXT_TOKENS = 15000

    if source_type == "faq":
        async for chunk in _generate_faq_answer(query, documents, response_style, include_examples):
            yield chunk
    else:
        async for chunk in _generate_legal_answer(
            query, documents, MAX_CONTEXT_TOKENS, 
            response_style, include_examples, include_references
        ):
            yield chunk


async def _generate_faq_answer(
    query: str, 
    documents: list, 
    response_style: str,
    include_examples: bool
) -> AsyncIterator[str]:
    """Generate detailed FAQ-based answer"""
    
    doc = documents[0]
    faq_question = doc.metadata.get("CÃ¢u_há»i", "")
    faq_answer = doc.page_content
    
    # Get additional related FAQs if available
    related_faqs = ""
    if len(documents) > 1:
        related_faqs = "\n".join([
            f"- {d.metadata.get('CÃ¢u_há»i', '')}: {truncate_text(d.page_content, 200)}"
            for d in documents[1:4]
        ])

    # Truncate FAQ answer if too long
    faq_answer = truncate_text(faq_answer, max_tokens=2500, model="gpt-3.5-turbo")
    
    system_prompt = """Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn gia vá» Luáº­t TrÃ¡ch nhiá»‡m má»Ÿ rá»™ng cá»§a nhÃ  sáº£n xuáº¥t (EPR) táº¡i Viá»‡t Nam.

**VAI TRÃ’ Cá»¦A Báº N:**
- Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c, Ä‘áº§y Ä‘á»§ vÃ  dá»… hiá»ƒu vá» EPR
- Giáº£i thÃ­ch cÃ¡c quy Ä‘á»‹nh phÃ¡p luáº­t má»™t cÃ¡ch thá»±c táº¿ vÃ  Ã¡p dá»¥ng Ä‘Æ°á»£c
- Há»— trá»£ doanh nghiá»‡p hiá»ƒu vÃ  tuÃ¢n thá»§ quy Ä‘á»‹nh EPR

**NGUYÃŠN Táº®C TRáº¢ Lá»œI:**
1. **ChÃ­nh xÃ¡c**: Dá»±a hoÃ n toÃ n trÃªn ná»™i dung FAQ Ä‘Æ°á»£c cung cáº¥p
2. **Chi tiáº¿t**: Giáº£i thÃ­ch Ä‘áº§y Ä‘á»§ cÃ¡c khÃ­a cáº¡nh cá»§a váº¥n Ä‘á»
3. **Thá»±c táº¿**: ÄÆ°a ra vÃ­ dá»¥ cá»¥ thá»ƒ khi phÃ¹ há»£p
4. **CÃ³ cáº¥u trÃºc**: Tá»• chá»©c cÃ¢u tráº£ lá»i logic, dá»… theo dÃµi
5. **ThÃ¢n thiá»‡n**: Sá»­ dá»¥ng ngÃ´n ngá»¯ dá»… hiá»ƒu, trÃ¡nh thuáº­t ngá»¯ phá»©c táº¡p khÃ´ng cáº§n thiáº¿t

**Cáº¤U TRÃšC CÃ‚U TRáº¢ Lá»œI NÃŠN BAO Gá»’M:**
- Tráº£ lá»i trá»±c tiáº¿p cÃ¢u há»i
- Giáº£i thÃ­ch chi tiáº¿t cÃ¡c Ä‘iá»ƒm quan trá»ng
- VÃ­ dá»¥ minh há»a (náº¿u phÃ¹ há»£p)
- LÆ°u Ã½ quan trá»ng hoáº·c ngoáº¡i lá»‡ (náº¿u cÃ³)
- Gá»£i Ã½ thÃªm hoáº·c thÃ´ng tin liÃªn quan"""

    user_prompt = f"""**CÃ‚U Há»I Gá»C TRONG FAQ:**
{faq_question}

**Ná»˜I DUNG TRáº¢ Lá»œI Tá»ª FAQ:**
{faq_answer}

{f"**CÃC FAQ LIÃŠN QUAN:**{chr(10)}{related_faqs}" if related_faqs else ""}

**CÃ‚U Há»I Cá»¦A NGÆ¯á»œI DÃ™NG:**
{query}

**YÃŠU Cáº¦U:**
HÃ£y tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch chi tiáº¿t vÃ  Ä‘áº§y Ä‘á»§, dá»±a trÃªn thÃ´ng tin FAQ á»Ÿ trÃªn. 

Cáº¥u trÃºc cÃ¢u tráº£ lá»i:
1. Báº¯t Ä‘áº§u báº±ng cÃ¢u tráº£ lá»i ngáº¯n gá»n, trá»±c tiáº¿p
2. Sau Ä‘Ã³ giáº£i thÃ­ch chi tiáº¿t cÃ¡c Ä‘iá»ƒm quan trá»ng
3. Náº¿u phÃ¹ há»£p, Ä‘Æ°a ra vÃ­ dá»¥ cá»¥ thá»ƒ Ä‘á»ƒ minh há»a
4. Káº¿t thÃºc báº±ng lÆ°u Ã½ quan trá»ng hoáº·c gá»£i Ã½ thÃªm

Tráº£ lá»i:"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_prompt)
    ])

    chain = prompt | streaming_llm

    async for chunk in chain.astream({
        "faq_question": faq_question,
        "faq_answer": faq_answer,
        "related_faqs": related_faqs,
        "user_question": query
    }):
        if hasattr(chunk, 'content'):
            yield chunk.content


async def _generate_legal_answer(
    query: str,
    documents: list,
    max_context_tokens: int,
    response_style: str,
    include_examples: bool,
    include_references: bool
) -> AsyncIterator[str]:
    """Generate comprehensive legal document-based answer"""
    
    # Limit documents to prevent context overflow
    context = format_docs(documents, max_docs=5, max_tokens_per_doc=1200)
    
    # Verify total context size
    context_tokens = count_tokens(context)
    query_tokens = count_tokens(query)
    system_prompt_tokens = 500  # Account for detailed system prompt
    
    total_input_tokens = context_tokens + query_tokens + system_prompt_tokens
    
    print(f"   ğŸ“Š Context size: {context_tokens} tokens")
    print(f"   ğŸ“Š Query size: {query_tokens} tokens")
    print(f"   ğŸ“Š Total input: {total_input_tokens} tokens")
    
    if total_input_tokens > max_context_tokens:
        print(f"   âš ï¸ Context too large ({total_input_tokens} tokens), reducing...")
        context = format_docs(documents, max_docs=3, max_tokens_per_doc=800)
        context_tokens = count_tokens(context)
        print(f"   âœ… Reduced to {context_tokens} tokens")

    system_prompt = """Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n phÃ¡p luáº­t vá» TrÃ¡ch nhiá»‡m má»Ÿ rá»™ng cá»§a nhÃ  sáº£n xuáº¥t (EPR) táº¡i Viá»‡t Nam.

**VAI TRÃ’:**
- PhÃ¢n tÃ­ch vÃ  giáº£i thÃ­ch cÃ¡c quy Ä‘á»‹nh phÃ¡p luáº­t EPR
- Cung cáº¥p hÆ°á»›ng dáº«n thá»±c thi cá»¥ thá»ƒ cho doanh nghiá»‡p
- TrÃ­ch dáº«n chÃ­nh xÃ¡c cÃ¡c Ä‘iá»u khoáº£n phÃ¡p luáº­t liÃªn quan

**NGUYÃŠN Táº®C TRáº¢ Lá»œI:**

1. **CÄƒn cá»© phÃ¡p lÃ½ rÃµ rÃ ng:**
   - LUÃ”N trÃ­ch dáº«n sá»‘ Äiá»u, Khoáº£n, Äiá»ƒm cá»¥ thá»ƒ
   - NÃªu tÃªn vÄƒn báº£n quy pháº¡m phÃ¡p luáº­t (Nghá»‹ Ä‘á»‹nh, ThÃ´ng tÆ°...)
   - KhÃ´ng Ä‘Æ°a ra thÃ´ng tin khÃ´ng cÃ³ trong tÃ i liá»‡u

2. **Giáº£i thÃ­ch chi tiáº¿t:**
   - PhÃ¢n tÃ­ch Ã½ nghÄ©a cá»§a quy Ä‘á»‹nh
   - Giáº£i thÃ­ch cÃ¡ch Ã¡p dá»¥ng trong thá»±c táº¿
   - NÃªu rÃµ Ä‘á»‘i tÆ°á»£ng Ã¡p dá»¥ng, pháº¡m vi, Ä‘iá»u kiá»‡n

3. **Cáº¥u trÃºc logic:**
   - Báº¯t Ä‘áº§u báº±ng tÃ³m táº¯t ngáº¯n gá»n
   - TrÃ¬nh bÃ y chi tiáº¿t theo thá»© tá»± logic
   - PhÃ¢n biá»‡t rÃµ cÃ¡c trÆ°á»ng há»£p khÃ¡c nhau (náº¿u cÃ³)

4. **Thá»±c tiá»…n Ã¡p dá»¥ng:**
   - ÄÆ°a ra vÃ­ dá»¥ cá»¥ thá»ƒ khi cáº§n thiáº¿t
   - NÃªu cÃ¡c bÆ°á»›c thá»±c hiá»‡n (náº¿u phÃ¹ há»£p)
   - Cáº£nh bÃ¡o vá» cÃ¡c lá»—i thÆ°á»ng gáº·p

5. **HoÃ n chá»‰nh vÃ  chuyÃªn nghiá»‡p:**
   - Tráº£ lá»i Ä‘áº§y Ä‘á»§ cÃ¡c khÃ­a cáº¡nh cá»§a cÃ¢u há»i
   - NÃªu cÃ¡c quy Ä‘á»‹nh liÃªn quan (náº¿u cÃ³)
   - Äá» xuáº¥t cÃ¡c váº¥n Ä‘á» cáº§n lÆ°u Ã½ thÃªm

**Äá»ŠNH Dáº NG TRáº¢ Lá»œI:**
- Sá»­ dá»¥ng Ä‘á» má»¥c rÃµ rÃ ng khi cáº§n thiáº¿t
- In Ä‘áº­m cÃ¡c Ä‘iá»ƒm quan trá»ng
- TrÃ­ch dáº«n phÃ¡p luáº­t trong ngoáº·c hoáº·c format rÃµ rÃ ng"""

    user_prompt = f"""**TÃ€I LIá»†U PHÃP LUáº¬T THAM KHáº¢O:**

{context}

**CÃ‚U Há»I Cá»¦A NGÆ¯á»œI DÃ™NG:**
{query}

**YÃŠU Cáº¦U TRáº¢ Lá»œI:**
HÃ£y tráº£ lá»i cÃ¢u há»i má»™t cÃ¡ch chi tiáº¿t, chuyÃªn nghiá»‡p dá»±a HOÃ€N TOÃ€N trÃªn tÃ i liá»‡u phÃ¡p luáº­t Ä‘Æ°á»£c cung cáº¥p.

Cáº¥u trÃºc cÃ¢u tráº£ lá»i nÃªn bao gá»“m:

1. **TÃ³m táº¯t cÃ¢u tráº£ lá»i** (2-3 cÃ¢u)
   - Tráº£ lá»i trá»±c tiáº¿p vÃ o váº¥n Ä‘á» chÃ­nh

2. **CÄƒn cá»© phÃ¡p lÃ½**
   - TrÃ­ch dáº«n cá»¥ thá»ƒ Äiá»u, Khoáº£n tá»« vÄƒn báº£n phÃ¡p luáº­t
   - Giáº£i thÃ­ch ná»™i dung quy Ä‘á»‹nh

3. **Giáº£i thÃ­ch chi tiáº¿t**
   - PhÃ¢n tÃ­ch cÃ¡c Ä‘iá»ƒm quan trá»ng
   - NÃªu rÃµ Ä‘iá»u kiá»‡n, pháº¡m vi Ã¡p dá»¥ng
   - PhÃ¢n biá»‡t cÃ¡c trÆ°á»ng há»£p (náº¿u cÃ³)

4. **HÆ°á»›ng dáº«n thá»±c hiá»‡n** (náº¿u phÃ¹ há»£p)
   - CÃ¡c bÆ°á»›c cá»¥ thá»ƒ
   - Thá»i háº¡n, há»“ sÆ¡ cáº§n thiáº¿t

5. **LÆ°u Ã½ quan trá»ng**
   - CÃ¡c ngoáº¡i lá»‡
   - Äiá»ƒm cáº§n chÃº Ã½
   - Cháº¿ tÃ i xá»­ pháº¡t (náº¿u cÃ³)

Tráº£ lá»i:"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_prompt)
    ])

    chain = prompt | streaming_llm

    async for chunk in chain.astream({
        "context": context,
        "question": query
    }):
        if hasattr(chunk, 'content'):
            yield chunk.content


# ========== OPTIMIZED CHATBOT PIPELINE ==========

async def optimized_chatbot_pipeline(
    query: str,
    chat_history: str = "",
    faq_threshold: float = 0.6,
    use_parallel: bool = True
) -> AsyncIterator[Dict[str, Any]]:
    """
    Optimized chatbot pipeline with parallel retrieval and streaming

    Args:
        query: User's question
        chat_history: Previous conversation context
        faq_threshold: Minimum FAQ match score
        use_parallel: If True, retrieve FAQ + legal docs in parallel

    Yields:
        dict: Status updates and response chunks
    """

    print("\n" + "ğŸ”¹"*40)
    print("ğŸš€ OPTIMIZED PIPELINE START")
    print("ğŸ”¹"*40)

    # Step 0a: Rewrite question based on chat history (if needed)
    original_query = query
    if chat_history:
        print("---REWRITING QUESTION BASED ON CHAT HISTORY---")
        print(f"  Original query: {original_query}")
        try:
            # Use the question rewriter to contextualize the question
            rewritten_query = question_rewriter_legal.invoke({
                "question": query,
                "chat_history": chat_history
            })
            print(f"  Rewritten query: {rewritten_query}")
            # Use the rewritten query for retrieval
            query = rewritten_query
        except Exception as e:
            print(f"  âš ï¸ Error in question rewriting: {e}")
            print(f"  â¡ï¸ Continuing with original query")
            # Continue with original query if rewriting fails
    else:
        print("---NO CHAT HISTORY - USING ORIGINAL QUESTION---")
        print(f"  Query: {query}")

    # Step 0b: Check if this is chitchat BEFORE any retrieval
    print("---CHECKING IF CHITCHAT---")
    try:
        # Use the FAQ router to check if this is chitchat
        route_result = question_router_faq.invoke({
            "question": query,
            "chat_history": chat_history
        })

        datasource = route_result.get("datasource") if isinstance(route_result, dict) else getattr(route_result, "datasource", None)
        print(f"   Routing decision: {datasource}")

        if datasource == 'chitchat':
            print("   âœ… Detected as chitchat - generating friendly response")
            yield {
                'type': 'status',
                'message': 'ğŸ’¬ Generating friendly response...',
                'stage': 'chitchat'
            }

            # Call chitchat function
            state = {
                "question": query,
                "chat_history": chat_history
            }
            result_state = chitchat(state)
            chitchat_response = result_state.get("generation", "Xin chÃ o!")

            # Stream the chitchat response
            yield {
                'type': 'response_chunk',
                'chunk': chitchat_response,
                'stage': 'streaming'
            }

            # Complete
            yield {
                'type': 'response_complete',
                'text': chitchat_response,
                'documents': [],
                'source': 'chitchat',
                'stage': 'complete'
            }

            print("ğŸ”¹"*40)
            print("âœ… CHITCHAT COMPLETE")
            print("ğŸ”¹"*40 + "\n")
            return
    except Exception as e:
        print(f"   âš ï¸ Error in chitchat routing: {e}")
        # Continue to retrieval if routing fails

    print("   â¡ï¸ Not chitchat - proceeding to document retrieval")

    # Step 1: Yield status - starting retrieval
    yield {
        'type': 'status',
        'message': 'ğŸ” Searching knowledge base...',
        'stage': 'retrieval'
    }

    # Step 2: Parallel retrieval
    if use_parallel:
        results = await parallel_retrieve(query, faq_threshold)
        faq_docs = results['faq_docs']
        legal_docs = results['legal_docs']
    else:
        # Sequential fallback
        faq_docs = await retrieve_faq_async(query, faq_threshold)
        legal_docs = []
        if not faq_docs:
            legal_docs = await retrieve_legal_async(query)

    # Step 3: Determine which documents to use
    documents_to_use = []
    source_type = None

    if faq_docs:
        documents_to_use = faq_docs
        source_type = "faq"
        yield {
            'type': 'status',
            'message': 'âœ… Found answer in FAQ',
            'stage': 'generation',
            'source': 'faq'
        }
    elif legal_docs:
        documents_to_use = legal_docs
        source_type = "legal"
        yield {
            'type': 'status',
            'message': 'âœ… Found relevant legal documents',
            'stage': 'generation',
            'source': 'legal'
        }
    else:
        # No documents found - try web search
        yield {
            'type': 'status',
            'message': 'ğŸŒ Searching web for additional information...',
            'stage': 'web_search'
        }

        # Call web search
        web_state = {
            "question": query
        }
        web_result = web_search(web_state)
        web_urls = web_result.get("web_urls", "")

        if web_urls:
            yield {
                'type': 'response_chunk',
                'chunk': web_urls,
                'stage': 'streaming'
            }

            yield {
                'type': 'response_complete',
                'text': web_urls,
                'documents': [],
                'source': 'web_search',
                'stage': 'complete'
            }
        else:
            yield {
                'type': 'response_complete',
                'text': 'Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p trong cÆ¡ sá»Ÿ dá»¯ liá»‡u hoáº·c trÃªn web.',
                'documents': [],
                'source': None,
                'stage': 'complete'
            }

        print("ğŸ”¹"*40)
        print("âœ… WEB SEARCH COMPLETE")
        print("ğŸ”¹"*40 + "\n")
        return

    # Step 4: Stream the response
    full_response = ""

    async for chunk in generate_answer_streaming(query, documents_to_use, source_type):
        full_response += chunk
        yield {
            'type': 'response_chunk',
            'chunk': chunk,
            'stage': 'streaming'
        }

    # Step 5: Final metadata
    yield {
        'type': 'response_complete',
        'text': full_response,
        'documents': documents_to_use,
        'source': source_type,
        'stage': 'complete'
    }

    print("ğŸ”¹"*40)
    print("âœ… OPTIMIZED PIPELINE COMPLETE")
    print("ğŸ”¹"*40 + "\n")


# ========== HELPER FUNCTION FOR STREAMLIT ==========

def run_optimized_chatbot(query: str, chat_history: str = ""):
    """
    Synchronous wrapper for Streamlit
    Returns an async generator that can be consumed by Streamlit
    """
    return optimized_chatbot_pipeline(query, chat_history)


print("âœ… Performance optimizations loaded!")
print("   - Async parallel retrieval")
print("   - Streaming LLM responses")
print("   - Optimized pipeline")
print("="*80 + "\n")



