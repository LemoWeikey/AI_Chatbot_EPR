#!/usr/bin/env python3
"""
Upload FAQ and Law data to Qdrant Cloud
This script reads data from faq (1).json and law.json and uploads to Qdrant Cloud
"""

import os
import json
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.documents import Document
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct, PayloadSchemaType
import uuid
from tqdm import tqdm

# Load environment variables
load_dotenv()

# Configuration
QDRANT_CLOUD_URL = os.getenv("QDRANT_CLOUD_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Check if credentials are set
if not QDRANT_CLOUD_URL or not QDRANT_API_KEY:
    print("‚ùå Error: Qdrant Cloud credentials not found!")
    print("Please set QDRANT_CLOUD_URL and QDRANT_API_KEY in your .env file")
    exit(1)

if not OPENAI_API_KEY:
    print("‚ùå Error: OpenAI API key not found!")
    print("Please set OPENAI_API_KEY in your .env file")
    exit(1)

print("üîß Initializing...")
print(f"üìç Qdrant Cloud URL: {QDRANT_CLOUD_URL}")

# Initialize embeddings and Qdrant client
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
client = QdrantClient(url=QDRANT_CLOUD_URL, api_key=QDRANT_API_KEY)

VECTOR_SIZE = 1536  # text-embedding-3-small produces 1536-dimensional vectors


# ========== HELPER FUNCTIONS ==========

def extract_dieu_number(dieu_text: str) -> int:
    """
    Extract article number from ƒêi·ªÅu text
    Example: "ƒêi·ªÅu 125. H√¨nh th·ª©c..." -> 125
    """
    import re
    match = re.search(r'ƒêi·ªÅu\s+(\d+)', dieu_text)
    if match:
        return int(match.group(1))
    return 0


def collection_exists(collection_name):
    """Check if a collection exists in Qdrant Cloud"""
    collections = client.get_collections().collections
    return any(col.name == collection_name for col in collections)


def delete_collection_if_exists(collection_name):
    """Delete collection if it exists"""
    if collection_exists(collection_name):
        print(f"üóëÔ∏è  Deleting existing collection '{collection_name}'...")
        client.delete_collection(collection_name=collection_name)
        print(f"‚úÖ Deleted collection '{collection_name}'")
        return True
    return False


def create_collection(collection_name):
    """Create a new collection"""
    print(f"üì¶ Creating collection '{collection_name}'...")
    client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE)
    )
    print(f"‚úÖ Created collection '{collection_name}'")


# ========== FAQ COLLECTION FUNCTION ==========

def recreate_faq_collection(force=False):
    """
    Create/Recreate FAQ collection with fresh embeddings in Qdrant Cloud

    Args:
        force: If True, delete existing collection and recreate

    Returns:
        bool: True if successful, False otherwise
    """
    print("\n" + "="*80)
    print("üîÑ FAQ COLLECTION SETUP")
    print("="*80)

    collection_name = "faq_collection"

    try:
        # Load FAQ data
        print("üìÇ Loading FAQ data from faq (1).json...")
        try:
            with open("faq (1).json", "r", encoding="utf-8") as f:
                faq_data = json.load(f)
        except FileNotFoundError:
            print("‚ùå Error: faq (1).json file not found!")
            print("Please ensure the file exists in the current directory")
            return False

        faq_items = faq_data.get("meta", [])
        print(f"‚úÖ Loaded {len(faq_items)} FAQ items")

        # Check if collection exists
        if collection_exists(collection_name):
            if force:
                delete_collection_if_exists(collection_name)
            else:
                print(f"‚úÖ Collection '{collection_name}' already exists")
                count = client.get_collection(collection_name).points_count
                print(f"   Points in collection: {count}")
                print("üí° Set force=True to recreate with fresh embeddings")
                print("="*80)
                return True

        # Create collection
        create_collection(collection_name)

        # Add FAQ documents with fresh embeddings
        print(f"üìÑ Adding {len(faq_items)} FAQ documents...")
        points = []

        for idx, item in enumerate(tqdm(faq_items, desc="Processing FAQ items")):
            question = item.get("C√¢u h·ªèi", "")
            answer = item.get("Tr·∫£ l·ªùi", "")

            if not question or not answer:
                continue

            # Combine question and answer for embedding
            combined_text = f"C√¢u h·ªèi: {question} Tr·∫£ l·ªùi: {answer}"

            # Generate embedding
            vector = embeddings.embed_query(question)

            # Create payload with Vietnamese characters (Qdrant Cloud supports them)
            payload = {
                "C√¢u_h·ªèi": question,
                "Tr·∫£_l·ªùi": answer,
                "combined_text": combined_text,
                "source": "faq"
            }

            point = PointStruct(
                id=str(uuid.uuid4()),
                vector=vector,
                payload=payload
            )
            points.append(point)

            # Upload in batches of 100
            if len(points) >= 100:
                client.upsert(collection_name=collection_name, points=points)
                points = []

        # Upload remaining points
        if points:
            client.upsert(collection_name=collection_name, points=points)

        # Verify
        count = client.get_collection(collection_name).points_count
        print(f"‚úÖ Verified: Collection has {count} points")
        print("="*80)

        return True

    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        print("="*80)
        return False


# ========== LAW COLLECTION FUNCTION ==========

def recreate_law_collection(force=False):
    """
    Create/Recreate law collection with fresh embeddings in Qdrant Cloud
    Uses GPT-3.5-turbo to generate summaries before embedding

    Args:
        force: If True, delete existing collection and recreate

    Returns:
        bool: True if successful, False otherwise
    """
    print("\n" + "="*80)
    print("üîÑ LAW COLLECTION SETUP")
    print("="*80)

    collection_name = "law_collection"

    try:
        # Load law data
        print("üìÇ Loading law data from law.json...")
        try:
            with open("law.json", "r", encoding="utf-8") as f:
                law_data = json.load(f)
        except FileNotFoundError:
            print("‚ùå Error: law.json file not found!")
            print("Please ensure the file exists in the current directory")
            return False

        law_items = law_data.get("meta", [])
        print(f"‚úÖ Loaded {len(law_items)} law articles")

        # Check if collection exists
        if collection_exists(collection_name):
            if force:
                delete_collection_if_exists(collection_name)
            else:
                print(f"‚úÖ Collection '{collection_name}' already exists")
                count = client.get_collection(collection_name).points_count
                print(f"   Points in collection: {count}")
                print("üí° Set force=True to recreate with fresh embeddings")
                print("="*80)
                return True

        # Step 1: Convert to Document objects
        print("üìÑ Converting to Document objects...")
        docs = []
        for item in law_items:
            dieu_text = item.get("ƒêi·ªÅu", "")
            metadata = {
                "Dieu": dieu_text,
                "Dieu_Number": extract_dieu_number(dieu_text),
                "Chuong": item.get("Ch∆∞∆°ng", ""),
                "Muc": item.get("M·ª•c", ""),
                "Pages": item.get("Pages", "")
            }

            doc = Document(
                page_content=item.get("Text", ""),
                metadata=metadata
            )
            docs.append(doc)

        print(f"‚úÖ Created {len(docs)} Document objects")

        # Step 2: Generate summaries using GPT-3.5-turbo
        print("ü§ñ Generating summaries with GPT-3.5-turbo (this may take a while)...")

        query_str = """H√£y cung c·∫•p m·ªôt b·∫£n t√≥m t·∫Øt chi ti·∫øt b·∫±ng ti·∫øng Vi·ªát v·ªÅ quy ƒë·ªãnh ph√°p lu·∫≠t Vi·ªát Nam n√†y, bao g·ªìm:
- C√°c y√™u c·∫ßu ho·∫∑c quy ƒë·ªãnh ph√°p l√Ω ch√≠nh ƒë∆∞·ª£c n√™u ra
- Nh·ªØng c√° nh√¢n, t·ªï ch·ª©c ho·∫∑c ƒë·ªëi t∆∞·ª£ng n√†o ch·ªãu s·ª± ƒëi·ªÅu ch·ªânh c·ªßa quy ƒë·ªãnh n√†y
- C√°c nghƒ©a v·ª•, quy·ªÅn ho·∫∑c th·ªß t·ª•c quan tr·ªçng ƒë∆∞·ª£c quy ƒë·ªãnh
- C√°c ƒëi·ªÅu ki·ªán, ngo·∫°i l·ªá ho·∫∑c y√™u c·∫ßu c·ª• th·ªÉ ƒë√°ng ch√∫ √Ω (n·∫øu c√≥)
- M·ª•c ƒë√≠ch ho·∫∑c ph·∫°m vi t·ªïng th·ªÉ c·ªßa quy ƒë·ªãnh ph√°p lu·∫≠t n√†y

Vui l√≤ng tr√¨nh b√†y b·∫£n t√≥m t·∫Øt th√†nh 3-4 ƒëo·∫°n vƒÉn b·∫±ng ti·∫øng Vi·ªát, b·∫£o ƒë·∫£m v·ª´a ƒë·∫ßy ƒë·ªß v·ª´a d·ªÖ ƒë·ªçc.
"""

        # Create chain for summarization
        chain = (
            {"doc": lambda x: x.page_content}
            | ChatPromptTemplate.from_template(f"{query_str}\n\nN·ªôi dung vƒÉn b·∫£n:\n\n{{doc}}")
            | ChatOpenAI(model="gpt-3.5-turbo", temperature=0.4, max_retries=1)
            | StrOutputParser()
        )

        # Batch process documents
        summaries = chain.batch(docs, {"max_concurrency": 5})
        print(f"‚úÖ Generated {len(summaries)} summaries")

        # Create collection
        create_collection(collection_name)

        # Create payload index for Dieu_Number to enable filtering
        print(f"üîß Creating payload index for metadata.Dieu_Number field...")
        try:
            client.create_payload_index(
                collection_name=collection_name,
                field_name="metadata.Dieu_Number",
                field_schema=PayloadSchemaType.INTEGER
            )
            print(f"‚úÖ Created integer index for metadata.Dieu_Number")
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Could not create index for metadata.Dieu_Number: {e}")

        # Create payload index for Muc (Section)
        print(f"üîß Creating payload index for metadata.Muc field...")
        try:
            client.create_payload_index(
                collection_name=collection_name,
                field_name="metadata.Muc",
                field_schema=PayloadSchemaType.TEXT
            )
            print(f"‚úÖ Created TEXT index for metadata.Muc")
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Could not create index for metadata.Muc: {e}")

        # Create payload index for Chuong (Chapter)
        print(f"üîß Creating payload index for metadata.Chuong field...")
        try:
            client.create_payload_index(
                collection_name=collection_name,
                field_name="metadata.Chuong",
                field_schema=PayloadSchemaType.TEXT
            )
            print(f"‚úÖ Created TEXT index for metadata.Chuong")
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Could not create index for metadata.Chuong: {e}")

        # Step 3: Create embeddings from summaries and upload
        print(f"üöÄ Creating embeddings from summaries and uploading...")
        points = []

        for doc, summary in tqdm(zip(docs, summaries), total=len(docs), desc="Processing documents"):
            if not summary or not summary.strip():
                print(f"‚ö†Ô∏è  Skipping empty summary for {doc.metadata.get('Dieu', 'unknown')}")
                continue

            # Generate embedding from summary (not original text)
            vector = embeddings.embed_query(summary)

            # Create payload with nested metadata structure to match app's query format
            # The app uses QdrantTranslator(metadata_key="metadata") so fields must be under "metadata"
            payload = {
                "metadata": {
                    "Dieu": doc.metadata.get("Dieu", ""),
                    "Dieu_Number": doc.metadata.get("Dieu_Number", 0),
                    "Chuong": doc.metadata.get("Chuong", ""),
                    "Muc": doc.metadata.get("Muc", ""),
                    "Pages": doc.metadata.get("Pages", "")
                },
                "page_content": doc.page_content,  # ‚úÖ REQUIRED: Main content for retrieval
                "source": "law",
                "original_text": doc.page_content,  # Keep original text for reference
                "summary": summary  # Full detailed summary
            }

            point = PointStruct(
                id=str(uuid.uuid4()),
                vector=vector,
                payload=payload
            )
            points.append(point)

            # Upload in batches of 100
            if len(points) >= 100:
                client.upsert(collection_name=collection_name, points=points)
                points = []

        # Upload remaining points
        if points:
            client.upsert(collection_name=collection_name, points=points)

        # Verify
        count = client.get_collection(collection_name).points_count
        print(f"‚úÖ Verified: Collection has {count} points")
        print("="*80)

        return True

    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        print("="*80)
        return False


# ========== MAIN EXECUTION ==========

if __name__ == "__main__":
    print("\n" + "="*80)
    print("üöÄ QDRANT CLOUD UPLOAD SCRIPT")
    print("="*80)
    print("\nThis script will upload FAQ and Law data to Qdrant Cloud")
    print("\nOptions:")
    print("1. Upload FAQ collection only")
    print("2. Upload Law collection only")
    print("3. Upload both collections")
    print("4. Recreate FAQ collection (force)")
    print("5. Recreate Law collection (force)")
    print("6. Recreate both collections (force)")
    print("\n" + "="*80)

    choice = input("\nEnter your choice (1-6): ").strip()

    if choice == "1":
        success = recreate_faq_collection(force=False)
        if success:
            print("\n‚úÖ FAQ collection setup complete!")

    elif choice == "2":
        success = recreate_law_collection(force=False)
        if success:
            print("\n‚úÖ Law collection setup complete!")

    elif choice == "3":
        success_faq = recreate_faq_collection(force=False)
        success_law = recreate_law_collection(force=False)
        if success_faq and success_law:
            print("\n‚úÖ Both collections setup complete!")
        else:
            print("\n‚ö†Ô∏è Some collections failed to setup")

    elif choice == "4":
        success = recreate_faq_collection(force=True)
        if success:
            print("\n‚úÖ FAQ collection recreated successfully!")

    elif choice == "5":
        success = recreate_law_collection(force=True)
        if success:
            print("\n‚úÖ Law collection recreated successfully!")

    elif choice == "6":
        success_faq = recreate_faq_collection(force=True)
        success_law = recreate_law_collection(force=True)
        if success_faq and success_law:
            print("\n‚úÖ Both collections recreated successfully!")
        else:
            print("\n‚ö†Ô∏è Some collections failed to recreate")

    else:
        print("‚ùå Invalid choice. Exiting.")
        exit(1)

    print("\n" + "="*80)
    print("üéâ UPLOAD COMPLETE!")
    print("="*80)
    print("\nüìä Summary:")

    # Show collection info
    try:
        if choice in ["1", "3", "4", "6"]:
            faq_info = client.get_collection("faq_collection")
            print(f"\nüìö FAQ Collection:")
            print(f"   - Points count: {faq_info.points_count}")
            print(f"   - Vector size: {faq_info.config.params.vectors.size}")

        if choice in ["2", "3", "5", "6"]:
            law_info = client.get_collection("law_collection")
            print(f"\n‚öñÔ∏è  Law Collection:")
            print(f"   - Points count: {law_info.points_count}")
            print(f"   - Vector size: {law_info.config.params.vectors.size}")
    except Exception as e:
        print(f"\n‚ö†Ô∏è  Could not retrieve collection info: {e}")

    print("\nüëâ You can now use the chatbot with data from Qdrant Cloud!")
    print("="*80 + "\n")
